import sys
import types
import importlib.abc
import importlib.machinery

MODULE_SPECS = {
    'slippy': {'source': 'import multiprocessing\nimport os\nimport numpy\n"""Top-level package for SlipPY."""\n\n__author__ = """Michael Watson"""\n__email__ = \'mike.watson@sheffield.ac.uk\'\n__version__ = \'0.5.2\'\n\ntry:\n    import cupy  # noqa: F401\n    CUDA = True\n    xp = cupy\nexcept ImportError:\n    CUDA = False\n    xp = numpy\n\n\ndef asnumpy(obj):\n    if CUDA:\n        return cupy.asnumpy(obj)\n    return numpy.asarray(obj)\n\n\nCUBIC_EPS = 1e-7\nCORES = multiprocessing.cpu_count()\nOUTPUT_DIR = os.getcwd()\nERROR_IF_MISSING_MODEL = True\nERROR_IF_MISSING_SUB_MODEL = True\nERROR_IN_DATA_CHECK = True\ndtype = \'float64\'\nmaterial_names = []\n\n\nclass OverRideCuda:\n    def __init__(self):\n        self.cuda = CUDA\n\n    def __enter__(self):\n        global CUDA\n        CUDA = False\n\n    def __exit__(self, err_type, value, traceback):\n        global CUDA\n        CUDA = self.cuda\n', 'is_package': True},
    'slippy.contact': {'source': 'r"""\n================================================\nContact mechanics models (:mod:`slippy.contact`)\n================================================\n\n.. currentmodule:: slippy.contact\n\nThis module contains functions and classes for making contact mechanics models. These models allow the user to model\ncomplex contacts including user defined behaviours for material deformations, wear, friction, fluid flow etc..\nFor users of abaqus the API will be somewhat familiar: a ContactModel object contains all the information about the\nmodel. Within this object there are Surface objects which contain the geometry information, these have Materials\nassigned to them which control how the surfaces deform under load. The actual solving is done by ModelSteps which are\nagain held within the ContactModel object. When the model is solved these steps are solved in order.\n\nThe Contact Model object\n========================\n\n.. autosummary::\n   :toctree: generated\n\n   ContactModel   -- A multi-step contact model\n\nModel Steps\n===========\n\nThere are ModelSteps for many different situations such as dry normal loading, mixed lubricated etc.. Some of these also\nrequire a Lubricant to be defined.\n\n.. autosummary::\n   :toctree: generated\n\n   StaticStep               -- A step for solving a single time point of a static model\n   QuasiStaticStep          -- A step for solving multiple time points with changes in load, location or geometry\n\n   IterSemiSystem           -- Iterative semi system lubrication step\n\nMaterials\n=========\n\nSlippy currently contains solvers for Elastic and Rigid materials, more materials will be added in future releases, it\nis also possible to add your own materials.\n\n.. autosummary::\n   :toctree: generated\n\n   Elastic        -- An elastic material\n   Rigid          -- The rigid material class\\*\n\n\\*note as the Rigid class has no options, an instance (rigid) is also provided for convenience\n\nLubricants\n==========\n\nLubricants in slippy are defined through the Lubricant object and lubricant sub models. A lubricant object is just a\ncontainer for the sub models which define the behaviour of the lubricant. Sub models must be added for the behaviours\nrequired by a particular solver. These can be constants as for a newtonian lubricant or they can depend on other\nvariables found during the solution eg pressure.\n\n.. autosummary::\n   :toctree: generated\n\n   Lubricant\n   lubricant_models\n\n\nSub models\n==========\n\nSlippy is quasi static, meaning that the normal contact problem is always solved for the static system. Transient\nbehaviour such as wear, temperature change, tribofilm growth, plastic deformation etc. is dealt with by sub models.\nThese are solved after the contact problem has been solved for each step.\n\n.. autosummary::\n   :toctree: generated\n\n   sub_models\n\nOutput requests for long simulations\n====================================\n\nBy default a contact model will return the final state when .solve() is called on it. However often this is not\nsufficient. Output requests allow the user to save all or part of the model state at set time points or after set steps.\nThe OutputReader allows the user to read these files back in conveniently.\n\n.. autosummary::\n   :toctree: generated\n\n   OutputRequest\n   OutputReader\n\nAnalytical solutions to common problems\n=======================================\n\nLastly slippy.contact also contains analytical solutions for common contacts. These are often useful as initial guesses\nto more complex contact problems.\n\n.. autosummary::\n   :toctree: generated\n\n   hertz_full\n   solve_hertz_line\n   solve_hertz_point\n\nExamples\n========\nExamples can be found in the examples folder on github:\nhttps://github.com/FrictionTribologyEnigma/SlipPY/tree/master/examples\n\n"""\n\n# from .adhesion_models import *\nfrom slippy.core import Rigid, rigid, Elastic, elastic_influence_matrix_spatial, OutputRequest, OutputReader, \\\n    OutputSaver, read_output, guess_loads_from_displacement, bccg, plan_convolve, plan_multi_convolve\nfrom .hertz import hertz_full, solve_hertz_line, solve_hertz_point\nfrom .lubricant import Lubricant\nfrom .adhesion_models import MDAdhesionPotential, AdhesionModelFromFunction\nfrom .lubrication_steps import IterSemiSystem\nfrom .models import ContactModel\nfrom .static_step import StaticStep\nfrom .steps import _ModelStep, RepeatingStateStep\nfrom .unified_reynolds_solver import UnifiedReynoldsSolver\nfrom .quasi_static_step import QuasiStaticStep\nfrom . import sub_models\n\n__all__ = [\'hertz_full\', \'solve_hertz_line\', \'solve_hertz_point\', \'Lubricant\',\n           \'lubricant_models\', \'IterSemiSystem\', \'Elastic\', \'Rigid\', \'rigid\', \'elastic_influence_matrix_spatial\',\n           \'ContactModel\', \'OutputRequest\', \'OutputReader\', \'OutputSaver\', \'read_output\',\n           \'StaticStep\', \'UnifiedReynoldsSolver\', \'sub_models\', \'QuasiStaticStep\', \'sub_models\',\n           \'guess_loads_from_displacement\', \'bccg\', \'plan_convolve\', \'plan_multi_convolve\', \'_ModelStep\',\n           \'RepeatingStateStep\', \'MDAdhesionPotential\', \'AdhesionModelFromFunction\']\n', 'is_package': True},
    'slippy.contact._lubrication_utils': {'source': 'import numpy as np\nfrom scipy.linalg.lapack import dgtsv\n\n__all__ = [\'tdma\', \'cyclic_tdma\']\n\n\ndef tdma(lower_diagonal, main_diagonal, upper_diagonal, right_hand_side):\n    """The thomas algorithm (tdma) solution for tri-diagonal matrix inversion\n\n    Parameters\n    ----------\n    lower_diagonal: np.ndarray\n        The lower diagonal of the matrix length n-1\n    main_diagonal: np.ndarray\n        The main diagonal of the matrix length n\n    upper_diagonal: np.ndarray\n        The upper diagonal of the matrix length n-1\n    right_hand_side: np.ndarray\n        The array bof size max(1, ldb*n_rhs) for column major layout and max(1, ldb*n) for row major layout contains the\n        matrix B whose columns are the right-hand sides for the systems of equations.\n\n    Returns\n    -------\n    x: np.ndarray\n        The solution array length n\n\n    Notes\n    -----\n    Nothing is mutated by this function\n    """\n    _, _, _, x, _ = dgtsv(lower_diagonal, main_diagonal, upper_diagonal, right_hand_side)\n    return x\n\n\ndef cyclic_tdma(lower_diagonal, main_diagonal, upper_diagonal, right_hand_side):\n    """The thomas algorithm (TDMA) solution for tri-diagonal matrix inversion with the sherman morison formula applied\n\n    Parameters\n    ----------\n    lower_diagonal: np.ndarray\n        The lower diagonal of the matrix length n, the first element is taken to be the top right element of the matrix\n    main_diagonal: np.ndarray\n        The main diagonal of the matrix length n\n    upper_diagonal: np.ndarray\n        The upper diagonal of the matrix length n, the last element is taken to be the bottom left element of the matrix\n    right_hand_side: np.ndarray\n        The right hand side of the equation\n\n    Returns\n    -------\n    x: np.ndarray\n        The solution array length n\n\n    Notes\n    -----\n    Nothing is mutated by this function\n    """\n    # modify b\n    gamma = -main_diagonal[0] if main_diagonal[0] else 1.0\n    main_diagonal[0] = main_diagonal[0] - gamma\n    main_diagonal[-1] = main_diagonal[-1] - lower_diagonal[0] * upper_diagonal[-1] / gamma\n    # find Ax=rhs\n    _, _, _, x, _ = dgtsv(lower_diagonal[1:], main_diagonal, upper_diagonal[:-1], right_hand_side)\n    # make u\n    u = np.zeros_like(right_hand_side)\n    u[0] = gamma\n    u[-1] = upper_diagonal[-1]\n    # find Az=u\n    _, _, _, z, _ = dgtsv(lower_diagonal[1:], main_diagonal, upper_diagonal[:-1], u)\n\n    # find the factor from the second part of SM formula\n    factor = (x[0] + x[-1] * lower_diagonal[0] / gamma) / (1 + z[0] + z[-1] * lower_diagonal[0] / gamma)\n\n    return x - z * factor\n', 'is_package': False},
    'slippy.contact._model_utils': {'source': 'import typing\n\nimport numpy as np\n\n__all__ = [\'get_gap_from_model\', \'non_dimensional_height\']\n\n\ndef non_dimensional_height(height: float, youngs: float, v: float, load: float, gs_x: float, gs_y: float = None,\n                           inverse: bool = False, return_uz: bool = False):\n    """Gives the non dimensional height from a dimensional height\n\n    Parameters\n    ----------\n    height: float\n        The height to be dimensionalised\n    youngs: float\n        The Young\'s modulus of the material\n    v: float\n        The Poisson\'s ratio of the material\n    load: float\n        The total load on the contact\n    gs_x: float\n        The grid spacing of the discrete grid in the x direction\n    gs_y: float, optional (None)\n        The grid spacing of the descretisation grid in the y direction, if None it is assumed that the grid is square\n    inverse: bool, optional (False)\n        If set to True the height will be re dimensionalised, else it will be non dimensionalised\n    return_uz: bool, optional (False)\n        If True the descriptive height uz will be returned\n\n    Returns\n    -------\n    non_dimensional_height: float\n        or the dimensionalised height if inverse is set to True\n\n    Notes\n    -----\n    The height is non dimensionalised by dividing by the displacement caused by a the load on a single grid square:\n    H = h/u_z\n    u_z found according to equation 3.25 in the reference\n\n    References\n    ----------\n    """\n    load = load or 1\n    a = gs_x\n    b = gs_x if gs_y is None else gs_y\n    c = (a ** 2 + b ** 2) ** 0.5\n    big_a = 2 * a * np.log((b + c) / (c - b)) + 2 * b * np.log((a + c) / (c - a))\n    uz = big_a * load * (1 - v ** 2) / np.pi / youngs / a / b\n    if return_uz:\n        return uz\n    if inverse:\n        return height * uz\n    else:\n        return height / uz\n\n\n# noinspection PyUnresolvedReferences\ndef get_gap_from_model(model, interference: float = 0,\n                       off_set: typing.Sequence = (0, 0), mode: str = \'nearest\',\n                       periodic: bool = False, _return_sub: bool = False):\n    """\n\n    Parameters\n    ----------\n    model : ContactModel\n        An instance of a contact model containing two surfaces\n    interference :\n        The interference between the surfaces, from the point of first contact, positive is into the surface\n    off_set\n        The off set in the x and y directions between the origin of the first and second surface\n    mode : str {\'nearest\', \'linear\', \'cubic\'} optional, \'nearest\'\n        The mode of interpolation used to generate the points on the second surface, see surface.interpolate for more\n        information\n    periodic : bool, optional (False)\n        If True the second surface is considered periodic, the result will be the same shape and size as the first\n        surface\n    _return_sub: bool, optional (False)\n        If true this function returns the areas of each surface used to calculate the gap, used for testing\n\n    Returns\n    -------\n    point_wise_interference : np.ndarray\n        point wise interference between the surfaces with the same grid spacing as the first surface in the contact\n        model\n    contact_points_1 : tuple[np.ndarray, np.ndarray]\n        The x and y locations of the interference array in the same coordinates as the first surface\n    contact_points_2 : tuple[np.ndarray, np.ndarray]\n        The x and y locations of the interference array in the same coordinates as the second surface\n\n    See Also\n    --------\n    slippy.surface._Surface.interpolate\n    """\n    # if not isinstance(model, _ContactModelABC):\n    #    raise ValueError("Model must be a contact model object")\n    # Type checking\n    if len(off_set) != 2:\n        raise ValueError("off_set should be a two element sequence")\n\n    s1 = model.surface_1\n    s2 = model.surface_2\n\n    if s2 is None:\n        raise ValueError("Second surface must be set for this contact type")\n    if not s1.is_discrete:\n        raise ValueError("The master surface (surface 1) must be discrete to find the interference")\n\n    if periodic:\n        # find smallest surface, set this as master\n        if not s2.is_discrete:\n            raise ValueError("Periodic geometry currently requires both surfaces to be "\n                             "descretised")\n        if s1.extent[0] <= s2.extent[0] and s1.extent[1] <= s2.extent[1]:\n            swapped = False\n        elif s1.extent[0] >= s2.extent[0] and s1.extent[1] >= s2.extent[1]:\n            swapped = True\n            s1, s2 = s2, s1\n            off_set = [-1 * os for os in off_set]\n        else:\n            raise ValueError("Periodic geometry currently requires one surface be smaller "\n                             "in both dimensions")\n    else:\n        swapped = False\n\n    if s2.is_discrete:\n        # find overlap\n        if periodic:\n            contact_points_1 = s1.get_points_from_extent()\n            contact_points_2y = contact_points_1[0] - off_set[0] + np.finfo(float).eps * s1.extent[0]\n            contact_points_2x = contact_points_1[1] - off_set[1] + np.finfo(float).eps * s1.extent[1]\n            contact_points_2 = (np.remainder(contact_points_2y, s2.extent[0]),\n                                np.remainder(contact_points_2x, s2.extent[1]))\n            sub_1 = s1.profile\n        else:  # not periodic\n            extent_1y = (max(off_set[0], 0), min(s1.extent[0], s2.extent[0] + off_set[0]))\n            slice_y = [ex / s1.grid_spacing for ex in extent_1y]\n            # slice_y[1] += 1\n            extent_1x = (max(off_set[1], 0), min(s1.extent[1], s2.extent[1] + off_set[1]))\n            slice_x = [ex / s1.grid_spacing for ex in extent_1x]\n            # slice_x[1] += 1\n            contact_points_1 = np.meshgrid(np.arange(extent_1x[0], extent_1x[1],\n                                                     s1.grid_spacing),\n                                           np.arange(extent_1y[0], extent_1y[1],\n                                                     s1.grid_spacing))\n            contact_points_1 = (contact_points_1[1], contact_points_1[0])\n            contact_points_2 = (np.array(contact_points_1[0]) - off_set[0],\n                                np.array(contact_points_1[1]) - off_set[1])\n            sub_1 = s1.profile[int(slice_y[0]):int(slice_y[1]), int(slice_x[0]):int(slice_x[1])]\n        # interpolate using the required technique\n        # return sub_1, contact_points_2, extent_1y, extent_1x, slice_x, slice_y\n        sub_2 = s2.interpolate(*contact_points_2, mode=mode, remake_interpolator=True)\n\n    else:  # model.surface_2 is not descrete\n        if not model.surface_2.is_analytic:\n            raise ValueError("The second surface is not descretised or an analytical surface the interference "\n                             "between the surfaces cannot be found")\n        # find overlap extents (same as periodic)\n        contact_points_1 = model.surface_1.get_points_from_extent()\n        contact_points_2 = contact_points_1[0] - off_set[0], contact_points_1[1] - off_set[1]\n        # call the height function on the second surface\n        sub_1 = model.surface_1.profile\n        sub_2 = model.surface_2.height(*contact_points_2)\n\n    if swapped:\n        sub_1, sub_2 = sub_2, sub_1\n        contact_points_1 = tuple(cp - os for cp, os in zip(contact_points_1, off_set))\n        contact_points_2 = tuple(cp + os for cp, os in zip(contact_points_2, off_set))\n        contact_points_1, contact_points_2 = contact_points_2, contact_points_1\n\n    point_wise_interference = -sub_2 - sub_1\n    point_wise_interference -= min(point_wise_interference.flatten()) + interference\n    if not point_wise_interference.size:\n        raise ValueError("Surfaces are no longer in contact, off set too large")\n    if _return_sub:\n        return sub_1, sub_2\n    return point_wise_interference, contact_points_1, contact_points_2\n', 'is_package': False},
    'slippy.contact._step_utils': {'source': '"""\nHelper functions for steps\n"""\nimport os\nimport typing\nimport warnings\nimport bisect\nfrom collections import namedtuple\nfrom numbers import Number\nfrom scipy.interpolate import interp1d\n\nimport numpy as np\n\nimport slippy\n\nif slippy.CUDA:\n    import cupy as cp\nelse:\n    cp = None\n\nfrom slippy.core import _ContactModelABC, bccg, plan_convolve, _IMMaterial, polonsky_and_keer, rey, \\\n    ConvolutionFunction, _AdhesionModelABC  # noqa: E402\n\n__all__ = [\'solve_normal_interference\', \'get_next_file_num\', \'OffSetOptions\', \'solve_normal_loading\',\n           \'HeightOptimisationFunction\', \'make_interpolation_func\']\n\nOffSetOptions = namedtuple(\'off_set_options\', [\'off_set\', \'abs_off_set\', \'periodic\', \'interpolation_mode\'])\n\n\ndef make_interpolation_func(values, kind, name: str):\n    """\n\n    Parameters\n    ----------\n    values: sequence of floats\n        Either [start, finish] or [position, time] where position and time are equal length sequences of floats.\n    kind: any kind compatible with scipy.interpolate.interp1d\n    name: str\n        The name of the parameter being interpolated used for errors\n\n    Returns\n    -------\n    interpolation_function: callable\n    """\n    try:\n        values = np.asarray(values, dtype=float)\n        assert not np.any(np.isnan(values))\n    except ValueError:\n        raise ValueError(f"Could not convert values for {name} to an valid format")\n    except AssertionError:\n        raise ValueError(f"Could not convert values for {name} to an valid format")\n\n    if values.size == 2:\n        position = values\n        time = np.array([0, 1])\n    elif values.shape[0] == 2:\n        position = values[0]\n        time = values[1]\n    else:\n        raise ValueError(f"Values for {name} are an invalid shape, should be 2 values (start, finish) or two equally "\n                         f"sized sequences of values (position, time: shape 2 by n). Input shape was {values.shape}")\n    return interp1d(time, position, kind, bounds_error=False, fill_value=(position[0], position[-1]))\n\n\nclass HeightOptimisationFunction:\n    """ A class to make a memorised function to be used in a height optimisation loop\n    Ths doesn\'t do the optimising it just gives a a callable class that can be used in one of scipy\'s methods\n\n    Parameters\n    ----------\n    just_touching_gap: np.ndarray\n        The just touching gap between the surfaces, should be found by get_gap_from function\n    model: _ContactModelABC\n        The contact model this will be solved in\n    adhesion_model: float\n        The maximum adhesive pressure between the surfaces\n    initial_contact_nodes:\n        If set the solution will be constrained to these nodes, if this is not wanted use None\n    max_it: int\n        The maximum number of iterations (for the inner loops if double optimisation is used)\n    rtol: float\n        The tolerance used to declare convergence (for the inner loops if double optimisation is used)\n    material_options: dict, list of dict\n        Material options for the materials in the model\n    max_set_load: float\n        The target total load in the normal direction, this must be kept up to date if the same function is being reused\n    rtol_outer: float\n        The tolerance used in the outer loop, only used if double optimisation method is used\n    use_cache: bool, optional (True)\n        If False the cache won\'t be used\n    cache_loads: bool, optional (True)\n        If False the full loads result will not be cached (otherwise this will be used to generate an initial guess of\n        the loads for each iteration)\n    """\n    _contact_nodes = None\n    _last_loads = None\n    _results: typing.Optional[dict] = None\n    set_contact_nodes = False\n\n    def __init__(self, just_touching_gap: np.ndarray, model: _ContactModelABC,\n                 adhesion_model: _AdhesionModelABC, initial_contact_nodes: np.ndarray,\n                 max_it: int, rtol: float, material_options: typing.Union[typing.Sequence[dict], dict],\n                 max_set_load: float, rtol_outer: float = 0, max_it_outer: int = 0, use_cache: bool = True,\n                 cache_loads=True, periodic_axes: typing.Tuple[bool] = (False, False)):\n        if slippy.CUDA:\n            xp = cp\n            cache_loads = False\n        else:\n            xp = np\n        self._grid_spacing = model.surface_1.grid_spacing\n\n        self._just_touching_gap = np.asarray(just_touching_gap)\n        self._model = model\n        self._adhesion_model = adhesion_model\n        self.initial_contact_nodes = initial_contact_nodes\n        self._max_it = max_it\n        self._tol = rtol\n        self._max_it_outer = max_it_outer\n        self._tol_outer = rtol_outer\n        self._material_options = material_options\n        self._original_set_load = max_set_load\n        self._set_load = float(max_set_load)\n        self._periodic_axes = periodic_axes\n        self.cache_heights = [0.0]\n        self.cache_total_load = [0.0]\n        self.cache_surface_loads = [xp.zeros(just_touching_gap.shape)]\n\n        self.it = 0\n        self.use_cache = use_cache\n        self.use_loads_cache = cache_loads\n        surf_1 = model.surface_1\n        surf_2 = model.surface_2\n\n        self.im_mats = False\n        self.conv_func: ConvolutionFunction = None\n        self.cache_max = False\n        self.last_call_failed = False\n        self._last_converged_loads = None\n\n        if isinstance(surf_1.material, _IMMaterial) and isinstance(surf_2.material, _IMMaterial):\n            self.im_mats = True\n            self._zero_frequency_zero = (surf_1.material.zero_frequency_value == 0 and\n                                         surf_2.material.zero_frequency_value == 0)\n            span = tuple([s * (2 - pa) for s, pa in zip(just_touching_gap.shape, periodic_axes)])\n            max_pressure = min([surf_1.material.max_load, surf_2.material.max_load])\n            self.max_pressure = max_pressure\n            im1 = surf_1.material.influence_matrix(components=[\'zz\'], grid_spacing=[surf_1.grid_spacing] * 2,\n                                                   span=span)[\'zz\']\n            im2 = surf_2.material.influence_matrix(components=[\'zz\'], grid_spacing=[surf_1.grid_spacing] * 2,\n                                                   span=span)[\'zz\']\n            total_im = im1 + im2\n            self.total_im = xp.asarray(total_im)\n\n            self.contact_nodes = initial_contact_nodes\n\n            if use_cache and max_pressure != np.inf:\n                max_loads = max_pressure * xp.ones(just_touching_gap.shape)\n                self.cache_total_load.append(max_pressure * just_touching_gap.size * surf_1.grid_spacing ** 2)\n                max_elastic_disp = self.conv_func(max_loads)\n                self.cache_heights.append(xp.max(max_elastic_disp + xp.asarray(just_touching_gap)))\n                if cache_loads:\n                    self.cache_surface_loads.append(slippy.asnumpy(max_loads))\n        else:\n            self.contact_nodes = initial_contact_nodes\n\n    @property\n    def contact_nodes(self):\n        return self._contact_nodes\n\n    @contact_nodes.setter\n    def contact_nodes(self, value):\n        if value is None:\n            self._contact_nodes = None\n        else:\n            value = np.array(value, dtype=bool)\n            self._contact_nodes = value\n        if self.im_mats:\n            self.conv_func = plan_convolve(self._just_touching_gap, self.total_im, self._contact_nodes,\n                                           circular=self._periodic_axes)\n\n    @property\n    def results(self):\n        if self._results is None:\n            print("No results found in height opt func")\n        if slippy.CUDA:\n            xp = cp\n        else:\n            xp = np\n        if self.im_mats and \'surface_1_displacement\' not in self._results:\n            # need to put the loads into an np array of right shape\n            # find the full displacements (and convert to np array)\n            # find disp on surface 1 and surface 2\n            surf_1 = self._model.surface_1\n            surf_2 = self._model.surface_2\n            span = tuple([s * (2 - pa) for s, pa in zip(self._just_touching_gap.shape, self._periodic_axes)])\n            # noinspection PyUnresolvedReferences\n            im1 = surf_1.material.influence_matrix(span=span, grid_spacing=[surf_1.grid_spacing] * 2,\n                                                   components=[\'zz\'])[\'zz\']\n            # noinspection PyUnresolvedReferences\n            im2 = surf_2.material.influence_matrix(span=span, grid_spacing=[surf_1.grid_spacing] * 2,\n                                                   components=[\'zz\'])[\'zz\']\n\n            if \'domain\' in self._results and \'loads_in_domain\' in self._results:\n                full_loads = xp.zeros(self._just_touching_gap.shape)\n                full_loads[self._results[\'domain\']] = self._results[\'loads_in_domain\']\n                full_disp = slippy.asnumpy(self.conv_func(self._results[\'loads_in_domain\'], ignore_domain=True))\n                full_loads = slippy.asnumpy(full_loads)\n\n            elif \'loads_z\' in self._results:\n                full_loads = slippy.asnumpy(self._results[\'loads_z\'])\n                full_disp = slippy.asnumpy(self._results[\'total_displacement_z\'])\n            else:\n                raise ValueError("Results not properly set")\n\n            conv_func_1 = plan_convolve(full_loads, im1, None, circular=self._periodic_axes)\n            conv_func_2 = plan_convolve(full_loads, im2, None, circular=self._periodic_axes)\n\n            disp_1 = conv_func_1(full_loads)\n            disp_2 = conv_func_2(full_loads)\n\n            if slippy.CUDA:\n                disp_1, disp_2 = xp.asnumpy(disp_1), xp.asnumpy(disp_2)\n                full_loads = xp.asnumpy(full_loads)\n\n            total_load = float(np.sum(full_loads) * self._grid_spacing ** 2)\n\n            if \'contact_nodes\' in self._results:\n                contact_nodes = self._results[\'contact_nodes\']\n            else:\n                contact_nodes = full_loads > 0\n\n            if \'gap\' in self._results:\n                gap = self._results[\'gap\']\n            else:\n                gap = self._just_touching_gap-self._results[\'interference\']+full_disp\n\n            results = {\'loads_z\': full_loads, \'total_displacement_z\': full_disp,\n                       \'surface_1_displacement_z\': disp_1, \'surface_2_displacement_z\': disp_2,\n                       \'contact_nodes\': contact_nodes, \'total_normal_load\': total_load,\n                       \'interference\': self._results[\'interference\'], \'gap\': gap}\n            return results\n        else:\n            return self._results\n\n    def clear_cache(self):\n        if self.cache_max:\n            self.cache_heights = [self.cache_heights[0], self.cache_heights[-1]]\n            self.cache_total_load = [self.cache_total_load[0], self.cache_total_load[-1]]\n            self.cache_surface_loads = [self.cache_surface_loads[0], self.cache_surface_loads[-1]]\n        else:\n            self.cache_heights = []\n            self.cache_total_load = []\n            self.cache_surface_loads = []\n        self._last_converged_loads = None\n\n    def change_load(self, new_load, contact_nodes):\n        # if you change the load... need to change the set load,\n        if float(new_load) == self._set_load:\n            return\n        self.contact_nodes = contact_nodes\n        if contact_nodes is None:\n            self.set_contact_nodes = False\n        else:\n            self.set_contact_nodes = True\n        self._set_load = float(new_load)\n        self._last_loads = None\n        self._results = None\n        self.it = 0\n\n    def get_bounds_from_cache(self, lower, upper):\n        # want to find the closest HEIGHT above and below the set load, if none above or below return None for that one\n        if len(self.cache_heights) < 2:\n            return lower, upper\n        index = bisect.bisect_left(self.cache_total_load, self._set_load)\n        try:\n            upper_bound = self.cache_heights[index]\n        except IndexError:\n            upper_bound = upper\n\n        if index > 0:\n            lower_est = self.cache_heights[index - 1]\n            lower_bound = max(lower_est, lower)\n        else:\n            lower_bound = lower\n\n        if abs(upper_bound - lower_bound) / upper_bound < 1e-10 or upper_bound < lower_bound:\n            interpolator = interp1d(self.cache_total_load, self.cache_heights, kind=\'cubic\', assume_sorted=True)\n            upper_bound = interpolator(self._set_load * 2)\n\n        return float(lower_bound), float(upper_bound)\n\n    def brent(self, xa: float, xb: float, xg: float = None, x_tol: float = np.inf):\n        """\n        A \'nan safe\' version of the brent root finding algorithm\n\n        Parameters\n        ----------\n        xa, xb: float\n            The lower and upper bracket values respectively (f(xa) must be smaller than 0, f(xb) must be larger than 0)\n        xg: float, optional (None)\n            An optional first guess at the zero location, zero can be above or below this value\n        x_tol: float, optional (inf)\n            The computed root x0 will satisfy np.allclose(x, x0, atol=x_tol, rtol=r_tol), where x is the exact root. The\n            parameter must be non-negative. For nice functions, Brent’s method will often satisfy the above condition\n            with x_tol/2 and r_tol/2. [Brent1973]\n\n        Returns\n        -------\n        converged: bool\n            True if the value converged, False if the maximum number of iterations was reached\n        x0: float\n            The x value corresponding to the found zero\n\n        Notes\n        -----\n        This function is a version of the scipy brentq function, rewritten to be constrained to increasing objective\n        functions with a zero for a positive value of x. It is also tolerant to single nan values from the function to\n        help with convergence.\n\n        The relative tolerance is set to self._r_tol_outer, the max iterations is set to self._max_it_outer.\n\n        """\n        failed, _ = safe_brent(self, xa, xb, xg, self._tol_outer, self._tol_outer, self._max_it_outer)\n        self._results[\'converged\'] = not failed\n\n    def rey(self, target_load: float = None, target_mean_gap: float = None, add_to_cache: bool = True):\n        """ Solve the contact problem using the Rey algorithm\n\n        Parameters\n        ----------\n        target_load: float\n            The target total load\n        target_mean_gap: float\n            The target mean gap\n        add_to_cache: bool\n            If True the result will be cached\n\n        Returns\n        -------\n        None\n\n        Notes\n        -----\n        The results from this method can be accessed by accessing the results property of this class, this will\n        automatically fill in displacement for both surfaces and the rigid body interference result.\n\n        The contact nodes property must be set to None before using this method, this remakes the convolution function.\n        """\n        if not self._zero_frequency_zero:\n            raise ValueError("Rey solver requires a zero frequency value of 0, set in material definitions")\n        if not all(self._periodic_axes):\n            raise ValueError("Rey solver requires fully periodic contact, set periodic axes to True in step definition")\n        if self.max_pressure < np.inf:\n            raise ValueError("Rey algorithm cannot be used with a maximum pressure")\n        if target_load is None:\n            target_mean_pressure = None\n        else:\n            target_mean_pressure = target_load / (self._just_touching_gap.size * self._grid_spacing ** 2)\n        failed, pressure, gap, total_displacement, contact_nodes = rey(self._just_touching_gap, self.conv_func,\n                                                                       self._adhesion_model, self._tol,\n                                                                       self._max_it, target_mean_gap,\n                                                                       target_mean_pressure)\n        self._results = {\'loads_z\': pressure, \'total_displacement_z\': total_displacement,\n                         \'interference\': np.mean((slippy.asnumpy(self._just_touching_gap) +\n                                                  slippy.asnumpy(total_displacement))[slippy.asnumpy(pressure > 0)]),\n                         \'converged\': not failed, \'gap\': gap, \'contact_nodes\': contact_nodes}\n        if add_to_cache:\n            self.add_to_cache(self._results[\'interference\'], target_load, pressure, failed)\n\n    def p_and_k(self, target_load: float, pressure_guess: np.ndarray = None, add_to_cache: bool = True):\n        """ Solve the set contact problem using the Polonsky and Keer algorithm\n\n        Parameters\n        ----------\n        target_load: float\n            The target total load\n        pressure_guess: array, optional (None)\n            The initial guess for the pressure solution, if none is supplied the last converged solution is used if\n            there is no last converged solution a flat array (ones) is used.\n        add_to_cache: bool\n            If True the result will be cached\n\n        Returns\n        -------\n        None\n\n        Notes\n        -----\n        The results from this method can be accessed by accessing the results property of this class, this will\n        automatically fill in displacement for both surfaces and the rigid body interference result.\n\n        The contact nodes property must be set to None before using this method, this remakes the convolution function.\n        """\n        if self.max_pressure < np.inf:\n            raise ValueError("Polonsky and Keer algorithm cannot be used with a maximum pressure")\n\n        if pressure_guess is None:\n            pressure_guess = self._last_converged_loads or np.ones_like(self._just_touching_gap)\n        failed, pressure, gap = polonsky_and_keer(self.conv_func, pressure_guess, self._just_touching_gap, target_load,\n                                                  self._grid_spacing, self._tol, self._max_it)\n        total_displacement = self.conv_func(pressure)\n        self._results = {\'loads_z\': pressure, \'total_displacement_z\': total_displacement,\n                         \'interference\': np.mean((slippy.asnumpy(self._just_touching_gap) +\n                                                  slippy.asnumpy(total_displacement))[slippy.asnumpy(pressure > 0)]),\n                         \'converged\': not failed}\n        if add_to_cache:\n            self.add_to_cache(self._results[\'interference\'], target_load, pressure, failed)\n\n    def __call__(self, height, current_state=None):\n        # If the height guess is in the cache that can be out load guess\n        height = float(height)\n        if height in self.cache_heights:\n            total_load = self.cache_total_load[self.cache_heights.index(height)]\n            print(f"Returning bound value from cache: height: {height:.4}, total_load {total_load:.4}")\n            return total_load - self._set_load\n        pressure_initial_guess = self.get_loads_from_cache(height)\n        self.it += 1\n        # if im mats we can save some time here mostly by not moving data to and from the gpu\n        if self.im_mats:\n            z = - self._just_touching_gap + height\n            if not self.set_contact_nodes:\n                self.contact_nodes = z > 0  # this will remake the conv function as a side effect\n            contact_nodes = self.contact_nodes\n            if not np.any(contact_nodes):\n                print(\'no contact nodes\')\n                total_load = 0\n                full_loads = np.zeros(contact_nodes.shape)\n                failed = False\n            else:\n                if pressure_initial_guess is None:\n                    pressure_initial_guess = np.zeros(z.shape)\n                z_in = z[contact_nodes]\n                pressure_guess_in = pressure_initial_guess[contact_nodes]\n                loads_in_domain, failed = bccg(self.conv_func, z_in, self._tol,\n                                               self._max_it, pressure_guess_in,\n                                               0, self.max_pressure)\n                loads_in_domain = slippy.asnumpy(loads_in_domain)\n                self._results = {\'loads_in_domain\': loads_in_domain, \'domain\': self.contact_nodes,\n                                 \'interference\': height}\n                total_load = float(np.sum(loads_in_domain) * self._grid_spacing ** 2)\n                if not failed:\n                    full_loads = np.zeros(contact_nodes.shape)\n                    full_loads[contact_nodes] = loads_in_domain\n                    self._last_converged_loads = full_loads\n                else:\n                    full_loads = None\n\n            self.add_to_cache(height, total_load, full_loads, failed)\n            if failed:\n                # noinspection PyUnboundLocalVariable\n                print(f\'Failed: total load: {total_load}, height {height}, max_load {np.max(loads_in_domain)}\')\n                self.last_call_failed = True\n            else:\n                print(f\'Solved: interference: {height}\\tTotal load: {total_load}\\tTarget load: {self._set_load}\')\n                self.last_call_failed = False\n            return total_load - self._set_load\n\n        # else use the basic form\n\n        loads, total_disp, disp_1, disp_2, contact_nodes, failed = \\\n            solve_normal_interference(height, gap=self._just_touching_gap,\n                                      model=self._model,\n                                      current_state=current_state,\n                                      adhesive_pressure=self._adhesion_model,\n                                      contact_nodes=self.contact_nodes,\n                                      max_iter=self._max_it,\n                                      material_options=self._material_options,\n                                      tol=self._tol,\n                                      initial_guess_loads=pressure_initial_guess)\n\n        self._results[\'loads_z\'] = loads\n        self._results[\'total_displacement\'] = total_disp\n        self._results[\'surface_1_displacement\'] = disp_1\n        self._results[\'surface_2_displacement\'] = disp_2\n        self._results[\'contact_nodes\'] = contact_nodes\n        self._results[\'interference\'] = height\n\n        total_load = np.sum(loads.flatten()) * self._grid_spacing ** 2\n\n        self._results[\'total_normal_load\'] = total_load\n\n        if failed:\n            self.last_call_failed = True\n            print(f\'Failed: total load: {total_load}, height {height}, max_load {np.max(loads.flatten())}\')\n        else:\n            self.last_call_failed = False\n            print(f\'Interference is: {height}\\tTotal load is: {total_load}\\tTarget load is: {self._set_load}\')\n\n        self.add_to_cache(height, total_load, loads, failed)\n\n        return total_load - self._set_load\n\n    def get_loads_from_cache(self, height):\n        if self.use_loads_cache:\n            index = bisect.bisect_left(self.cache_heights, height)\n            if index == len(self.cache_heights):\n                return self.cache_surface_loads[-1]\n            if not index:\n                return self.cache_surface_loads[0]\n            prop = height - self.cache_heights[index - 1] / (self.cache_heights[index] - self.cache_heights[index - 1])\n            return prop * self.cache_surface_loads[index] + (1 - prop) * self.cache_surface_loads[index - 1]\n        else:\n            return self._last_converged_loads\n\n    def add_to_cache(self, height, total_load, loads, failed):\n        if self.use_cache and height not in self.cache_heights and not failed:\n            print(\n                f"Inserting height: {height}, total_load: {total_load} into cache, len = {1 + len(self.cache_heights)}")\n            index = bisect.bisect_left(self.cache_heights, height)\n            self.cache_heights.insert(index, height)\n            self.cache_total_load.insert(index, total_load)\n            # print(f\'Cache: adding value: total load: {total_load},\n            # height {height}, cache len:{len(self.cache_heights)}\')\n            if self.use_loads_cache:\n                self.cache_surface_loads.insert(index, loads)\n\n\ndef safe_brent(f: typing.Callable, xa: float, xb: float, xg: typing.Optional[float], x_tol: float, r_tol: float,\n               max_iter: int):\n    """\n    A \'nan safe\' version of the brent root finding algorithm\n\n    Parameters\n    ----------\n    f: Callable\n        The objective function, should be increasing (a<b implies f(a)<f(b)) with a zero at some positive value.\n    xa, xb: float\n        The lower and upper bracket values respectively (f(xa) must be smaller than 0, f(xb) must be larger than 0)\n    xg: float, optional (None)\n        An optional first guess at the zero location, zero can be above or below this value\n    x_tol: float\n        The computed root x0 will satisfy np.allclose(x, x0, atol=xtol, rtol=rtol), where x is the exact root. The\n        parameter must be non-negative. For nice functions, Brent’s method will often satisfy the above condition with\n        xtol/2 and rtol/2. [Brent1973]\n    r_tol: float\n        The computed root x0 will satisfy np.allclose(x, x0, atol=xtol, rtol=rtol), where x is the exact root. The\n        parameter cannot be smaller than its default value of 4*np.finfo(float).eps. For nice functions, Brent’s method\n        will often satisfy the above condition with xtol/2 and rtol/2. [Brent1973]\n    max_iter: int\n        The maximum number of iterations\n\n    Returns\n    -------\n    converged: bool\n        True if the value converged, False if the maximum number of iterations was reached\n    x0: float\n        The x value corresponding to the found zero\n\n    Notes\n    -----\n    This function is a version of the scipy brentq function, rewritten to be constrained to increasing objective\n    functions with a zero for a positive value of x. It is also tolerant to single nan values from the function to help\n    with convergence.\n\n    """\n    x_pre = xa\n    x_cur = xb\n    x_blk = 0.\n    f_blk = 0.\n    s_pre = 0.\n    s_cur = 0.\n    f_pre = f(x_pre)\n    f_cur = f(x_cur)\n    if f_pre > f_cur:\n        x_pre, x_cur = x_cur, x_pre\n        f_pre, f_cur = f_cur, f_pre\n    if f_pre == 0:\n        return True, x_pre\n    if f_cur == 0:\n        return True, x_cur\n    i = 0\n    while f_pre > 0 or np.isnan(f_pre):\n        x_pre = x_pre / 2\n        f_pre = f(x_pre)\n        i += 1\n        if i >= max_iter:\n            raise ValueError("Could not find upper bound")\n    i = 0\n    while f_cur < 0 or np.isnan(f_cur):\n        if np.isnan(f_cur):\n            x_cur = x_cur / 2\n        else:\n            x_cur = x_cur * 1.3\n        f_cur = f(x_cur)\n        i += 1\n        if i >= max_iter:\n            raise ValueError("Could not find upper bound")\n    # deal with guess:\n    if xg is None:\n        fg = np.nan\n    else:\n        fg = f(xg)\n    if not np.isnan(fg):\n        if fg * f_pre > 0:\n            if abs(x_cur - xg) < abs(x_pre - x_cur):\n                x_pre, f_pre = xg, fg\n        elif fg * f_cur > 0:\n            if abs(x_pre - xg) < abs(x_pre - x_cur):\n                x_cur, f_cur = xg, fg\n\n    for i in range(max_iter):\n        if f_pre * f_cur < 0:\n            x_blk = x_pre\n            f_blk = f_pre\n            s_pre = s_cur = x_cur - x_pre\n\n        if abs(f_blk) < abs(f_cur):\n            x_pre = x_cur\n            x_cur = x_blk\n            x_blk = x_pre\n            f_pre = f_cur\n            f_cur = f_blk\n            f_blk = f_pre\n\n        delta = (x_tol + r_tol * abs(x_cur)) / 2\n        s_bis = (x_blk - x_cur) / 2\n        s_try_lin = -f_cur * (x_cur - x_blk) / (f_cur - f_blk)\n        if f_cur == 0 or abs(s_bis) < delta:\n            return True, x_cur\n\n        bisect_used = True\n\n        if abs(s_pre) > delta and abs(f_cur) < abs(f_pre):\n            if x_pre == x_blk:\n                # interpolate\n                s_try = s_try_lin\n            else:\n                # extrapolate\n                d_pre = (f_pre - f_cur) / (x_pre - x_cur)\n                d_blk = (f_blk - f_cur) / (x_blk - x_cur)\n                s_try = -f_cur * (f_blk * d_blk - f_pre * d_pre) / (d_blk * d_pre * (f_blk - f_pre))\n\n            if 2 * abs(s_try) < min(abs(s_pre), 3 * abs(s_bis) - delta):\n                # good short step\n                s_pre = s_cur\n                s_cur = s_try\n                s_cur_old = None\n                bisect_used = False\n            else:\n                # bisect\n                s_pre = s_bis\n                s_cur_old = s_cur\n                s_cur = s_bis\n        else:\n            # bisect\n            s_pre = s_bis\n            s_cur_old = s_cur\n            s_cur = s_bis\n        x_pre = x_cur\n        f_pre = f_cur\n        if abs(s_cur) > delta:\n            x_cur += s_cur\n        else:\n            x_cur += np.sign(s_bis) * delta\n        f_cur = f(x_cur)\n        if np.isnan(f_cur):\n            if bisect_used:\n                s_pre = s_cur_old\n                s_cur = s_try_lin\n                x_cur = x_pre + s_cur\n            else:\n                s_pre = s_bis\n                s_cur = s_bis\n                x_cur = x_pre + s_cur\n            f_cur = f(x_cur)\n        if np.isnan(f_cur):\n            raise ValueError("Too many nan values in root finding")\n    return False, x_cur\n\n\ndef solve_normal_loading(loads_z, model: _ContactModelABC, current_state: dict,\n                         deflections: str = \'xyz\', material_options: list = None,\n                         reverse_loads_on_second_surface: str = \'\'):\n    """\n\n    Parameters\n    ----------\n    loads_z: Loads\n        The loads on the surface in the same units as the material object\n    model: _ContactModelABC\n        A contact model object containing the surfaces and materials to be used\n    current_state: dict\n        The state dict for the model before this step is called\n    deflections: str, optional (\'xyz\')\n        The directions of the deflections to be calculated for each surface\n    material_options: dict, optional (None)\n        list of Dicts of options to be passed to the displacement_from_surface_loads method of the surface\n    reverse_loads_on_second_surface: str, optional (\'\')\n        string containing the components of the loads to be reversed for the second surface for example \'x\' will reverse\n        loads in the x direction only\n\n    Returns\n    -------\n    total_displacement: Displacements\n        A named tuple of the total displacement\n    surface_1_displacement: Displacements\n        A named tuple of the displacement on surface 1\n    surface_2_displacement: Displacements\n        A named tuple of the displacement on surface 2\n\n    """\n    surf_1 = model.surface_1\n    surf_2 = model.surface_2\n    if material_options is None:\n        material_options = [dict(), dict()]\n    else:\n        material_options = [mo or dict() for mo in material_options]\n\n    surface_1_displacement = surf_1.material.displacement_from_surface_loads(loads=loads_z,\n                                                                             grid_spacing=surf_1.grid_spacing,\n                                                                             deflections=deflections,\n                                                                             current_state=current_state,\n                                                                             **material_options[0])\n\n    if reverse_loads_on_second_surface:\n        loads_2 = -loads_z\n    else:\n        loads_2 = loads_z\n\n    surface_2_displacement = surf_2.material.displacement_from_surface_loads(loads=loads_2,\n                                                                             grid_spacing=surf_1.grid_spacing,\n                                                                             deflections=deflections,\n                                                                             current_state=current_state,\n                                                                             **material_options[1])\n    total_displacement = surface_1_displacement + surface_2_displacement\n\n    return total_displacement, surface_1_displacement, surface_2_displacement\n\n\n# noinspection PyArgumentList\ndef solve_normal_interference(interference: float, gap: np.ndarray, model: _ContactModelABC, current_state: dict,\n                              adhesive_pressure: typing.Union[float, typing.Callable] = None,\n                              contact_nodes: np.ndarray = None, max_iter: int = 100, tol: float = 1e-4,\n                              initial_guess_loads: np.ndarray = None,\n                              material_options: dict = None, remove_percent: float = 0.5,\n                              node_thresh_percent: int = 0.01):\n    """Solves contact with set normal interference\n\n    Parameters\n    ----------\n    interference: float\n        The interference between the surfaces measured from the point of first contact\n    gap: np.ndarray\n        The undeformed gap between the surfaces at the moment of first contact\n    model: _ContactModelABC\n        A contact model object containing the surfaces\n    current_state: dict\n        The state dict for the model before this step is solved\n    adhesive_pressure: {float, Callable}, optional (None)\n        The maximum adhesive force between the two surfaces, or a callable which wll be called as following:\n        adhesive_force(surface_loads, deformed_gap, contact_nodes, model) and must return two boolean arrays containing\n        the nodes to be removed and the nodes to be added in the iteration.\n    contact_nodes: np.ndarray\n        Boolean array of the surface nodes in contact at the start of the calculation, if set loading will be confined\n        to these nodes\n    material_options: dict\n        Dict of options to be passed to the loads_from_surface_displacement method of the first surface\n    max_iter: int\n        The maximum number of iterations to find a stable set of contact nodes\n    tol: float\n        The tolerance on the solution\n    initial_guess_loads: np.ndarray\n        The initial guess for the loads, used in the optimisation step, must be the same shape as the gap array\n        if this is not supplied the materials are used to generate an initial guess, this is often less accurate than\n        using the previous time step, especially when the time step is short\n    remove_percent: float\n        The percentage of the current contact nodes which can be removed in a single iteration\n    node_thresh_percent: float\n        Percentage of contact nodes which can need to be added before the solution is converged\n\n    Returns\n    -------\n    loads_z: array\n        A named tuple of surface loads\n    total_displacement_z: array\n        A named tuple of the total displacement\n    surface_1_displacement_z: array\n        A named tuple of the displacement on surface 1\n    surface_2_displacement_z: array\n        A named tuple of the displacement on surface 2\n    contact_nodes: np.ndarray\n        A boolean array of nodes in contact\n    failed: bool\n        False if the solution converged\n\n    Notes\n    -----\n\n    """\n\n    surf_1 = model.surface_1\n    surf_2 = model.surface_2\n\n    material_options = material_options or dict()\n\n    if contact_nodes is None and adhesive_pressure is not None:\n        warnings.warn(\'Contact nodes not set from previous step results may show unphysical adhesion force, use a \'\n                      \'no adhesion step to initialise the contact nodes to avoid this behaviour\')\n\n    if adhesive_pressure is None:\n        adhesive_pressure = 0\n\n    z = interference - gap  # necessary displacement for completely touching, positive is into surfaces\n\n    if contact_nodes is None:\n        contact_nodes = z > 0\n\n    if not np.any(contact_nodes.flatten()):\n        print(\'no_contact_nodes\')\n        zeros = np.zeros_like(z)\n        return (zeros, zeros.copy(), zeros.copy(), zeros.copy(),\n                contact_nodes, False)\n\n    if isinstance(surf_1.material, _IMMaterial) and isinstance(surf_2.material, _IMMaterial):\n        raise ValueError("Use the height optimiser function")\n    # if not both influence matrix based materials\n    displacements = z.copy()\n    displacements[np.logical_not(contact_nodes)] = np.nan\n\n    it_num = 0\n    added_nodes_last_it = np.inf\n    failed = False\n\n    while True:\n\n        loads, disp_tup = surf_1.material.loads_from_surface_displacement(displacements=displacements,\n                                                                          grid_spacing=surf_1.grid_spacing,\n                                                                          other=surf_2.material,\n                                                                          current_state=current_state,\n                                                                          **material_options)\n\n        # find deformed nd_gap and add contacting nodes to the contact nodes\n        deformed_gap = gap - interference + disp_tup[0].z  # the nd_gap minus the interference plus the displacement\n\n        force_another_iteration = False\n        n_contact_nodes = sum(contact_nodes.flatten())\n\n        print(\'Total contact nodes:\', n_contact_nodes)\n\n        if isinstance(adhesive_pressure, Number):\n            nodes_to_remove = np.logical_and(loads.z < adhesive_pressure, contact_nodes)\n            nodes_to_add = np.logical_and(deformed_gap < 0, np.logical_not(contact_nodes))\n            print(\'Nodes to add: \', sum(nodes_to_add.flatten()))\n            # noinspection PyUnresolvedReferences\n            print(\'Nodes to remove raw: \', sum(nodes_to_remove.flatten()))\n\n            max_remove = int(min(n_contact_nodes * remove_percent, 0.5 * added_nodes_last_it))\n            # noinspection PyUnresolvedReferences\n            if sum(nodes_to_remove.flatten()) > max_remove:\n                nodes_to_remove = np.argpartition(-loads.z.flatten(), -max_remove)[-max_remove:]\n                nodes_to_remove = np.unravel_index(nodes_to_remove, contact_nodes.shape)\n                print(\'Nodes to remove treated: \', len(nodes_to_remove[0]))\n                print(\'Forcing another iteration\')\n                force_another_iteration = True\n        else:\n            nodes_to_remove, nodes_to_add, force_another_iteration = adhesive_pressure(loads, deformed_gap,\n                                                                                       contact_nodes, model)\n\n        node_thresh = n_contact_nodes * node_thresh_percent\n\n        if force_another_iteration or any(nodes_to_remove.flatten()) or sum(nodes_to_add.flatten()) > node_thresh:\n            contact_nodes[nodes_to_add] = True\n            contact_nodes[nodes_to_remove] = False\n            n_nodes_added = sum(nodes_to_add.flatten())\n            added_nodes_last_it = n_nodes_added if n_nodes_added else added_nodes_last_it  # if any nodes then update\n            displacements = z.copy()\n            displacements[np.logical_not(contact_nodes)] = np.nan\n\n        else:\n            break\n\n        it_num += 1\n\n        if it_num > max_iter:\n            warnings.warn(\'Solution failed to converge on a set of contact nodes while solving for normal interference\')\n            loads.z[:] = np.nan\n            failed = True\n            break\n\n    return (loads,) + disp_tup + (contact_nodes, failed)\n\n\ndef get_next_file_num(output_folder):\n    highest_num = 0\n    for f in os.listdir(output_folder):\n        if os.path.isfile(os.path.join(output_folder, f)):\n            file_name = os.path.splitext(f)[0]\n            try:\n                file_num = int(file_name)\n                if file_num > highest_num:\n                    highest_num = file_num\n            except ValueError:\n                pass\n\n    output_file_num = str(highest_num + 1)\n    return output_file_num\n', 'is_package': False},
    'slippy.contact.adhesion_models': {'source': 'import numpy as np\nfrom scipy.misc import derivative\nfrom functools import partial\nfrom typing import Callable, Optional\nfrom slippy.core import _AdhesionModelABC\n\n__all__ = [\'MDAdhesionPotential\', \'AdhesionModelFromFunction\']\n\n\nclass MDAdhesionPotential(_AdhesionModelABC):\n    """\n    The Maugis-Dugdale adhesive potential (constant force gamma/rho when gap is smaller than rho)\n\n    Parameters\n    ----------\n    rho: float\n        The range of the potential\n    gamma: float\n        The adhesive force when in range is gamma/rho\n    """\n    def __init__(self, rho: float, gamma: float):\n        self.gamma = gamma\n        self.rho = rho\n\n    def energy(self, gap: np.ndarray):\n        return -self.gamma*np.sum(1-gap/self.rho) * (gap <= self.rho).astype(float)\n\n    def energy_gradient(self, gap: np.ndarray):\n        return self.gamma / self.rho * (gap <= self.rho).astype(float)\n\n\nclass AdhesionModelFromFunction(_AdhesionModelABC):\n    """ Generates and adhesion model object from energy or energy gradient functions\n\n    Parameters\n    ----------\n    energy_function: Callable, optional (None)\n        The energy function giving the adhesive energy as a function of the gap, if only this function is supplied\n        the derivative will be found by numerical differentiation by the central difference approximation\n    energy_gradient_function: Callable, optional (None)\n        The adhesive force as a function of the gap\n    dx: float, optional (1e-8)\n        The spacing of the points for numerical differentiation, only used if energy_gradient_function is None\n    order: int, optional (3)\n        The number of points for numerical differentiation must be odd, only used if energy_gradient_function is None\n\n    """\n    def __init__(self, energy_function: Optional[Callable] = None, energy_gradient_function: Optional[Callable] = None,\n                 dx: float = 1e-8, order: int = 3):\n        if (energy_function is None) and (energy_gradient_function is None):\n            raise ValueError("Either the energy function or the energy gradient function must be set")\n        self._energy_function = energy_function\n        if energy_gradient_function is None:\n            energy_gradient_function = partial(derivative, energy_function, dx=dx, order=order)\n        self._energy_gradient_function = energy_gradient_function\n\n    def energy_gradient(self, gap):\n        return self._energy_gradient_function(gap)\n\n    def energy(self, gap):\n        return self._energy_function(gap)\n', 'is_package': False},
    'slippy.contact.hertz': {'source': '# hertz.py\n\n# TODO stresses in elliptical contacts\n\nimport typing\nfrom collections import abc\nfrom collections import namedtuple\n\nimport numpy as np\nimport scipy.integrate as integrate\nimport scipy.optimize as optimize\nimport scipy.special as special\nimport sympy as sp\nfrom sympy.solvers import solve\n\n__all__ = [\'hertz_full\', \'solve_hertz_line\', \'solve_hertz_point\', \'HertzLineSolution\', \'HertzPointSolution\']\n\nHertzLineSolution = namedtuple(\'HertzLineSolution\', [\'r_rel\', \'e1\', \'e2\', \'v1\', \'v2\', \'load\',\n                                                     \'e_star\', \'contact_width\', \'max_pressure\',\n                                                     \'max_shear_stress\', \'max_von_mises\'])\n\n\ndef solve_hertz_line(*, r_rel: float = None,\n                     e1: float = None, e2: float = None,\n                     v1: float = None, v2: float = None,\n                     load: float = None,\n                     max_pressure: float = None,\n                     max_shear_stress: float = None,\n                     max_von_mises: float = None,\n                     contact_width: float = None,\n                     _system: dict = None) -> HertzLineSolution:\n    """\n    Finds remaining hertz parameter for a line contact\n\n    Parameters\n    ----------\n    r_rel: float, optional\n        The relative radii of the contact defined as 1/(1/r1+1/r2) where r1,2\n        are the radii of the bodies, assuming that the axes are parallel (line\n        contact). For a cylinder on the flat r_rel is the radius of the\n        cylinder.\n    e1, e2 : float, optional\n        The Young\'s moduli of the bodies, if neither is set they will be\n        assumed to be equal\n    v1, v2 : float, optional\n        The Poisson\'s ratios for the bodies, if neither is set the are assumed\n        to be equal\n    load : float, optional\n        The load per unit length for the contact\n    max_pressure : float, optional\n        The maximum pressure in the contact region\n    max_shear_stress : float, optional\n        The maximum shear stress in the first body, swap the materials to\n        change the body\n    contact_width : float, optional\n        The contact half width\n    max_von_mises : float, optional\n        The maximum von mises stress in the first body, swap the materials to\n        change body\n\n    Returns\n    -------\n    NamedTuple\n        The system with all of the possible inputs defined\n\n    See Also\n    --------\n    solve_hertz_point\n    hertz_full\n\n    Notes\n    -----\n    This function will only work for line contacts such as aligned cylinders in contact or a cylinder on a plane\n    It also uses approximate formulas based on a Poisson\'s ratio of 0.3 for stress results, if more accurate results are\n    required hertz_full should be used.\n\n    The independent parameters are: r_rel, e1, e2, v1, v2 and load.\n    The dependent parameters are: max_pressure, max_shear_stress, contact_width and max_von_mises\n\n    For this function to run either:\n    All of the independent parameters are set,\n    or\n    All but one of the independent parameters are set and exactly one of the dependent parameters\n    or\n    All of the independent parameters are set apart from both e\'s or both v\'s, in this case they are assumed to be equal\n\n    Regardless of which combination has been set the resulting output will contain all of the possible input parameters\n\n    References\n    ----------\n    Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge University Press. doi:10.1017/CBO9781139171731\n\n    Examples\n    --------\n    Finding the load required to give a specific contact pressure:\n\n    >>> result = solve_hertz_line(r_rel=0.01, e1=200e9, e2=200e9, v1=0.3, v2=0.3, max_pressure=1e9, load=None)\n    >>> result.load\n\n    Finding the stiffness of material required to give a specific contact width:\n\n    >>> result = solve_hertz_line(r_rel=0.05, e1=None, e2=None, v1=0.3, v2=0.3, load=1000, contact_width=1e-8)\n    >>> result.e1\n    """\n    _system = {\'r_rel\': r_rel, \'e1\': e1, \'e2\': e2, \'v1\': v1, \'v2\': v2, \'load\': load}\n\n    der_params = [max_pressure, max_shear_stress, max_von_mises, contact_width]\n    der_none = [el is None for el in der_params]\n    if all(der_none):\n        return _fill_hertz_solution_line(_system)\n    # else work out the first set param then just recursively call to fill in the dict\n    mats_none = [el is None for el in [e1, e2, v1, v2]]\n    if any(mats_none):\n        is_none = \'e_star\'\n\n    else:\n        _system[\'e_star\'] = 1 / ((1 - v1 ** 2) / e1 + (1 - v2 ** 2) / e2)\n        if r_rel is None:\n            is_none = \'r_rel\'\n        else:\n            is_none = \'load\'\n    _system[is_none] = sp.Symbol(is_none)\n\n    if not der_none[0]:\n        # max pressure given\n        _system[is_none] = max(solve(_system[\'load\'] * _system[\'e_star\'] / np.pi / _system[\'r_rel\'] -\n                                     max_pressure ** 2, _system[is_none]))\n    elif not der_none[1]:\n        # max_shear_stress given\n        _system[is_none] = max(solve(0.3 ** 2 * _system[\'load\'] * _system[\'e_star\'] / np.pi /\n                                     _system[\'r_rel\'] - max_shear_stress ** 2, _system[is_none]))\n    elif not der_none[2]:\n        raise NotImplementedError("Not implemented yet, try another stress")\n        # max von mises stress given\n    elif not der_none[3]:\n        # contact width given\n        _system[is_none] = max(solve(4 * _system[\'load\'] * _system[\'r_rel\'] / np.pi / _system[\'e_star\'] -\n                                     contact_width ** 2, _system[is_none]))\n    else:\n        raise ValueError("Not enough parameters given!")\n    _system[is_none] = float(_system[is_none])\n    # sort out materials\n    if is_none == \'e_star\':\n        if sum(mats_none) == 2:\n            if mats_none[0] and mats_none[1]:\n                # neither E is set\n                _system[\'e1\'] = _system[\'e_star\'] * (2 - v1 ** 2 - v2 ** 2)\n                _system[\'e2\'] = _system[\'e1\']\n            elif mats_none[2] and mats_none[3]:\n                # neither v is set\n                _system[\'v1\'] = np.sqrt((1 / _system[\'e_star\'] * (1 / e1 + 1 / e2)) - 1)\n                _system[\'v2\'] = _system[\'v1\']\n            else:\n                raise ValueError(\'Both moduli or both poisson\\\'s ratios can \'\n                                 \'be found but not a combination\')\n        elif sum(mats_none) == 1:\n            # only one thing not set\n            props = [\'e1\', \'e2\', \'v1\', \'v2\']\n            prop_none = props[next((i for i, j in enumerate(mats_none)\n                                    if j), None)]\n\n            _system[prop_none] = sp.Symbol(prop_none)\n            _system[prop_none] = float(max(solve((1 - _system[\'v1\'] ** 2) / _system[\'e1\'] +\n                                                 (1 - _system[\'v2\'] ** 2) / _system[\'e2\'] -\n                                                 1 / _system[\'e_star\'], _system[prop_none])))\n        else:\n            raise ValueError("Not enough material properties set")\n    # recursive call to fill in the rest of the dict\n    return _fill_hertz_solution_line(_system=_system)\n\n\ndef _fill_hertz_solution_line(_system: dict):\n    """\n    Fills in the derived parameters of the system given all of the set parameters\n\n    Parameters\n    ----------\n    _system : dict\n        The hertz system with all of the set parameters found, and derived parameters will be overwritten\n\n    Returns\n    -------\n    system :dict\n        The system with all of the derived parameters filled in (a copy of _system)\n    """\n    system = _system.copy()\n    try:\n        system[\'e_star\'] = 1 / ((1 - system[\'v1\'] ** 2) / system[\'e1\'] + (1 - system[\'v2\'] ** 2) / system[\'e2\'])\n        c = 1 / (1 + 4 * (system[\'v1\'] - 1) * system[\'v1\']) ** 0.5 if system[\'v1\'] <= 0.1938 else \\\n            1.164 + 2.975 * system[\'v1\'] - 2.906 * system[\'v1\'] ** 2\n        system[\'contact_width\'] = np.sqrt(4 * system[\'load\'] * system[\'r_rel\'] / system[\'e_star\'] / np.pi)\n        system[\'max_pressure\'] = np.sqrt(system[\'load\'] * system[\'e_star\'] / np.pi / system[\'r_rel\'])\n        system[\'max_shear_stress\'] = system[\'max_pressure\'] * 0.3\n        system[\'max_von_mises\'] = system[\'max_pressure\'] / c\n    except ValueError:\n        raise ValueError(\'Not enough input parameters defined\')\n    try:\n        del system[\'is_none\']\n    except KeyError:\n        pass\n    return HertzLineSolution(**system)\n\n\nHertzPointSolution = namedtuple(\'HertzPointSolution\', [\'r_rel\', \'e1\', \'e2\', \'v1\', \'v2\', \'load\',\n                                                       \'e_star\', \'contact_radius\', \'max_pressure\', \'max_tensile_stress\',\n                                                       \'max_shear_stress\', \'max_von_mises\', \'total_displacement\'])\n\n\ndef solve_hertz_point(*, r_rel=None,\n                      e1=None, e2=None,\n                      v1=None, v2=None,\n                      load=None,\n                      max_pressure=None,\n                      max_shear_stress=None,\n                      contact_radius=None,\n                      max_von_mises=None,\n                      total_displacement=None,\n                      max_tensile_stress=None):\n    """Finds the remaining hertz parameter for a spherical contact\n\n    Parameters\n    ----------\n\n    r_rel: float, optional\n        The relative radii of the contact defined as 1/(1/r1+1/r2) where r1,2 are the radii of the bodies.\n        For a ball on the flat r_rel is the radius of the ball.\n    e1,e2 : float, optional\n        The Young\'s moduli of the bodies, if neither is set they will be assumed to be equal\n    v1,v2 : float, optional\n        The Poisson\'s ratios for the bodies, if neither is set the are assumed to be equal\n    load : float, optional\n        The load per unit length for the contact\n\n    max_pressure : float, optional\n        The maximum pressure in the contact region\n    max_shear_stress : float, optional\n        The maximum shear stress in the first body, swap the materials to\n        change the body\n    contact_radius : float, optional\n        The radius of the contact patch\n    max_von_mises : float, optional\n        The maximum von mises stress in the first body, swap the materials to change body\n    total_displacement : float, optional\n        The displacement of the bodies towards each other\n    max_tensile_stress : float, optional\n        The maximum tensile stress in the first body, swap the materials to cahnge the body\n\n    Returns\n    -------\n    HertzPointSolution : namedtuple\n        The system with all of the possible inputs defined\n\n    See Also\n    --------\n    solve_hertz_line\n    hertz_full\n\n    Notes\n    -----\n    This function will only work for spherical contacts such as a ball on flat, a ball on ball or crossed cylinders.\n    It also uses approximate formulas based on a poissions ratio of 0.3 for stress calculations, if more accurate\n    results are required hertz_full should be used.\n\n    The independent parameters are: r_rel, e1, e2, v1, v2 and load.\n    The dependent parameters are: max_pressure, max_shear_stress, contact_width and max_von_mises\n\n    For this function to run either:\n    All of the independent parameters are set,\n    or\n    All but one of the independent parameters are set and exactly one of the dependent parameters\n    or\n    All of the independent parameters are set apart from both e\'s or both v\'s, in this case they are assumed to be equal\n\n    Regardless of which combination has been set the resulting output will contain all of the possible input parameters\n\n    References\n    ----------\n    Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge University Press. doi:10.1017/CBO9781139171731\n\n    Examples\n    --------\n\n    Finding the radius of ball required to give a specific contact pressure:\n\n    >>> result = solve_hertz_point(r_rel=None, e1=200e9, e2=200e9, v1=0.3, v2=0.3, max_pressure=1e9, load=500)\n    >>> result.load\n\n    Finding the stiffness of material required to give a specific contact radius:\n\n    >>> result = solve_hertz_point(r_rel=0.05, e1=None, e2=None, v1=0.3, v2=0.3, load=1000, contact_radius=1e-8)\n    >>> result.e1\n    """\n\n    _system = {\'r_rel\': r_rel, \'e1\': e1, \'e2\': e2, \'v1\': v1, \'v2\': v2, \'load\': load}\n\n    der_params = [max_pressure, max_shear_stress, max_von_mises, contact_radius, total_displacement, max_tensile_stress]\n    der_none = [el is None for el in der_params]\n\n    if all(der_none):\n        return _fill_hertz_solution_point(_system=_system)\n\n    # else work out the first set param then just recursively call to fill in the dict\n    mats_none = [el is None for el in [e1, e2, v1, v2]]\n    if any(mats_none):\n        is_none = \'e_star\'\n    else:\n        _system[\'e_star\'] = 1 / ((1 - v1 ** 2) / e1 + (1 - v2 ** 2) / e2)\n        if r_rel is None:\n            is_none = \'r_rel\'\n        else:\n            is_none = \'load\'\n    _system[is_none] = sp.Symbol(is_none)\n\n    if not der_none[0]:  # done\n        # max pressure given\n        _system[is_none] = max(solve(6 * _system[\'load\'] * _system[\'e_star\'] ** 2 / np.pi ** 3 /\n                                     _system[\'r_rel\'] ** 2 - max_pressure ** 3, _system[is_none]))\n    elif not der_none[1]:  # done\n        # max_shear_stress given\n        # assuming that max shear stress is 0.46*p0 (as in v=0.3)\n        _system[is_none] = max(solve(0.46 * ((6 * _system[\'load\'] * _system[\'e_star\'] ** 2 / np.pi ** 3 /\n                                              _system[\'r_rel\'] ** 2) ** (1 / 3)) - max_shear_stress, _system[is_none]))\n\n    elif not der_none[2]:  # TODO\n        # max von mises stress given\n        raise NotImplementedError("Von mises stresses are not yet implemented")\n\n    elif not der_none[3]:  # done\n        # contact radius given\n        _system[is_none] = max(solve(3 * _system[\'load\'] * _system[\'r_rel\'] / 4 / _system[\'e_star\'] -\n                                     contact_radius ** 3, _system[is_none]))\n    elif not der_none[4]:  # done\n        # total deflection given\n        _system[is_none] = max(solve(9 * _system[\'load\'] ** 2 / 16 / _system[\'r_rel\'] /\n                                     _system[\'e_star\'] ** 2 - total_displacement ** 3, _system[is_none]))\n    elif not der_none[5]:  # done\n        # max tensile stress given\n        if is_none != \'e_star\':\n            _system[is_none] = max(solve((1 - 2 * _system[\'v1\']) * ((6 * _system[\'load\'] * _system[\'e_star\'] ** 2 /\n                                                                     np.pi ** 3 / _system[\'r_rel\'] ** 2) ** (\n                                                                        1 / 3)) / 3 -\n                                         max_tensile_stress, _system[is_none]))\n        elif sum(mats_none) == 2:\n            is_none = None  # To stop the materials being solved for next\n            del _system[\'e_star\']\n            if v1 is None and v2 is None:\n                v = sp.Symbol(\'v\')\n                v = max(solve((1 - 2 * v) * ((6 * _system[\'load\'] * (1 / ((1 - v ** 2) / _system[\'e1\'] +\n                                                                          (1 - v ** 2) / _system[\n                                                                              \'e2\'])) ** 2 / np.pi ** 3 /\n                                              _system[\'r_rel\'] ** 2) ** (1 / 3)) / 3 - max_tensile_stress, v))\n                v = float(v)\n                _system[\'v1\'] = v\n                _system[\'v2\'] = v\n            elif e1 is None and e2 is None:\n                e = sp.Symbol(\'e\')\n                e = max(solve((1 - 2 * _system[\'v1\']) * ((6 * _system[\'load\'] * (1 / ((1 - _system[\'v1\'] ** 2) / e +\n                                                                                      (1 - _system[\n                                                                                          \'v2\'] ** 2) / e)) ** 2 /\n                                                          np.pi ** 3 / _system[\'r_rel\'] ** 2) ** (1 / 3)) / 3 -\n                              max_tensile_stress, _system[is_none]))\n                e = float(e)\n                _system[\'e1\'] = e\n                _system[\'e2\'] = e\n\n        elif sum(mats_none) == 1:\n            del _system[\'e_star\']\n            is_none = [key for key, value in _system.items() if value is None][0]\n\n            x0 = 0.3 if is_none.startswith(\'v\') else 200e9\n\n            root_results = optimize.root(_root_tensile(_system, is_none, max_tensile_stress), np.array(x0))\n\n            _system[is_none] = root_results.x if root_results.success else None\n\n            if _system[is_none] is None:\n                raise StopIteration("Result failed to converge")\n\n        _system[\'e_star\'] = 1 / ((1 - _system[\'v1\'] ** 2) / _system[\'e1\'] + (1 - _system[\'v2\'] ** 2) / _system[\'e2\'])\n\n    else:\n        raise ValueError("Not enough parameters given!")\n\n    if is_none is not None:\n        _system[is_none] = float(_system[is_none])\n\n    # sort out materials\n    if is_none == \'e_star\':\n        if sum(mats_none) == 2:\n            if mats_none[0] and mats_none[1]:\n                # neither E is set\n                _system[\'e1\'] = _system[\'e_star\'] * (2 - v1 ** 2 - v2 ** 2)\n                _system[\'e2\'] = _system[\'e1\']\n            elif mats_none[2] and mats_none[3]:\n                # neither v is set\n                _system[\'v1\'] = np.sqrt((1 / _system[\'e_star\'] * (1 / e1 + 1 / e2)) - 1)\n                _system[\'v2\'] = _system[\'v1\']\n            else:\n                raise ValueError(\'Both moduli or both poisson\\\'s ratios can \'\n                                 \'be found but not a combination\')\n        elif sum(mats_none) == 1:\n            # only one thing not set\n            props = [\'e1\', \'e2\', \'v1\', \'v2\']\n            prop_none = props[next((i for i, j in enumerate(mats_none)\n                                    if j), None)]\n\n            _system[prop_none] = sp.Symbol(prop_none)\n            _system[prop_none] = max(solve((1 - _system[\'v1\'] ** 2) / _system[\'e1\'] +\n                                           (1 - _system[\'v2\'] ** 2) / _system[\'e2\'] -\n                                           1 / _system[\'e_star\'], _system[prop_none]))\n        else:\n            raise ValueError("Not enough material properties set")\n    # recursive call to fill in the rest of the dict\n    return _fill_hertz_solution_point(_system=_system)\n\n\ndef _root_tensile(system, is_none, max_tensile_stress):\n    """\n    Helper function, the root of the inner function is the value for is_none in the system\n\n    Parameters\n    ----------\n    system : dict\n        The system with one parameter set to none\n    is_none : str\n        The key of the none parameter in the dict\n    max_tensile_stress : float\n        The maximum tensile stress to be solved for\n    """\n    system = system.copy()\n\n    def inner(value):\n        nonlocal system\n        system[is_none] = abs(value)\n        return (1 - 2 * system[\'v1\']) * ((6 * system[\'load\'] * (1 / ((1 - system[\'v1\'] ** 2) / system[\'e1\'] +\n                                                                     (1 - system[\'v2\'] ** 2) / system[\'e2\'])) ** 2 /\n                                          np.pi ** 3 / system[\'r_rel\'] ** 2) ** (1 / 3)) / 3 - max_tensile_stress\n\n    return inner\n\n\ndef _fill_hertz_solution_point(_system: dict):\n    """\n    Fills in the derived parameters of the _system dict and returns it\n    Parameters\n    ----------\n    _system : dict\n        the system from solve hertz point\n\n    Returns\n    -------\n    system : HertzPointSolution\n        A named tuple with all of the derived parameters filled in\n    """\n    system = _system.copy()\n\n    try:\n        system[\'e_star\'] = 1 / ((1 - system[\'v1\'] ** 2) / system[\'e1\'] + (1 - system[\'v2\'] ** 2) / system[\'e2\'])\n        c = (1.30075 + 0.87825 * system[\'v1\'] + 0.54373 * system[\'v1\'] ** 2)\n        a = (3 * system[\'load\'] * system[\'r_rel\'] / 4 / system[\'e_star\']) ** (1 / 3)\n        system[\'contact_radius\'] = a\n        system[\'max_pressure\'] = (6 * system[\'load\'] * system[\'e_star\'] ** 2 / np.pi ** 3 /\n                                  system[\'r_rel\'] ** 2) ** (1 / 3)\n        system[\'max_tensile_stress\'] = (1 - 2 * system[\'v1\']) * system[\'max_pressure\'] / 3\n        system[\'max_shear_stress\'] = 0.46 * system[\'max_pressure\']\n        system[\'max_von_mises\'] = system[\'max_pressure\'] * c\n        system[\'total_displacement\'] = a ** 2 / system[\'r_rel\']\n\n    except ValueError:\n        raise ValueError(\'Not enough input parameters defined\')\n\n    try:\n        del system[\'is_none\']\n    except KeyError:\n        pass\n    return HertzPointSolution(**system)\n\n\ndef hertz_full(r1: typing.Union[typing.Sequence, float], r2: typing.Union[typing.Sequence, float],\n               moduli: typing.Union[typing.Sequence, float], v: typing.Union[typing.Sequence, float],\n               load: float, angle: float = 0.0, line: bool = False, integration_error: float = 1e-6,\n               root_error: float = 1e-6):\n    """Find the hertzian stress solution for the given system\n\n    Finds all the known results to the system defined, including full field\n    stress results if possible.\n\n    Parameters\n    ----------\n    r1, r2 : 2 element Sequence of floats or float\n        Two element sequence of the radii in the x and y directions.\n        Each element should be a float, use float(\'inf\') to indicate a flat\n        surface. If a single number is supplied both elements are set to that\n        number: r1=1 is equivalent to r1=[1,1]\n    moduli : Sequence of floats\n        Two element sequence of the young\'s moduli of the first and second bodies. If only one value is supplied it is\n        assumed to be for both surfaces.\n        See note on units.\n    v : Sequence of floats\n        Two element list of the poisson\'s ratios of the first and second bodies. If only one value is supplied it is\n        assumed to be for both surfaces.\n    load : float\n        The load applied for a point contact or the load per unit length for a\n        line contact. If a line contact is intended the line keyword should be\n        set to True. See note on units.\n    angle : float, optional (0)\n        The angle between the x axes in radians\n    line : bool, optional (False)\n        Should be set to True for line contacts, otherwise an error is raised,\n        this is done to avoid accidental line contacts changing the definition\n        of the load parameter.\n    integration_error : float, optional (1e-6)\n        The maximum relative error on the integration steps, used only for\n        elliptical contacts see [Deeg 1992] for more information.\n    root_error : float, optional (1e-6)\n        The maximum relative error on the root finding step, used only for\n        elliptical contacts see [Deeg 1992] for more information.\n\n    Returns\n    -------\n    results : dict\n        Dictionary of the results the keys available in the dictionary will depend on the contact solved.\n\n    See Also\n    --------\n    solve_hertz_line\n    solve_hertz_point\n\n    Notes\n    -----\n    Units must be consistent: if the young\'s moduli is given in N/mm**2, the\n    radii should be given in mm and the load should be given in N. etc.\n\n    The range for the k parameter (ratio of the contact radii) for elliptical\n    contacts is set to 1e-4, practically contacts which are more smaller\n    ratios will not converge, in these cases consider treating as a line\n    contact.\n\n    References\n    ----------\n    Unless otherwise stated formulas are taken from:\n    Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge University Press. doi:10.1017/CBO9781139171731\n\n    The depth and magnitude of maximum stresses in point and line contacts are taken from:\n    Green, I. (2005). Poisson ratio effects and critical values in spherical and cylindrical.\n    International Journal of Applied Mechanics and Engineering, 10(3), 451–462.\n\n    The determination of the ratio of the contact radii is taken from:\n    Deeg, Emil W.. “New Algorithms for Calculating Hertzian Stresses , Deformations , and Contact Zone Parameters.”\n    (1996).\n\n    Examples\n    --------\n    There is a detailed example of this function in the examples folder on github.\n\n    Solving a ball on flat contact:\n\n    >>> import slippy.contact as c\n    >>> full_results = c.hertz_full(r1 = 0.01, r2 = float(\'inf\'), moduli=[200e9, 70e9], v=[0.3, 0.33],\n    >>>                             load = 155)\n\n    Plotting the stresses below the central point of the contact:\n\n    >>> import matplotlib.pyplot as plt\n    >>> import numpy as np\n    >>> z = np.linspace(1e-8, full_results[\'contact_radii\'][0]*3)\n    >>> stress_results = full_results[\'stress_z_axis_b_f\'][0](z)\n    >>> for label, array in stress_results.items():\n    >>>     plt.plot(np.abs(array), -z, label = label)\n    >>> shear = 0.5*np.abs(stress_results[\'sigma_z\']-stress_results[\'sigma_theta\'])\n    >>> plt.plot(shear, -z, label = \'shear\')\n    >>> plt.legend()\n    >>> plt.xlabel(\'Absolute stress (Pa)\')\n    >>> plt.ylabel(\'Depth (m)\')\n\n    """\n    inf = float(\'inf\')\n    results = dict()\n    # check inputs\n    r1 = _sanitise_radii(r1)\n    r2 = _sanitise_radii(r2)\n    moduli = _sanitise_material(moduli, \'moduli\')\n    v = _sanitise_material(v, \'v\')\n\n    angle = angle % np.pi\n    angle = angle if angle < np.pi / 2 else angle - np.pi\n\n    if load <= 0:\n        raise ValueError("Negative or zero loads are not allowed")\n\n    # find the angles between the principal radii of the surfaces and the\n    # principal relative radii\n    with np.errstate(divide=\'ignore\'):\n        const_a = ((1 / r2[0]) - (1 / r2[1]))\n        const_b = ((1 / r1[0]) - (1 / r1[1]))\n        t = 2 * angle\n        alpha = np.arctan2(const_a * np.sin(t), (const_a * np.cos(t) + const_b)) / 2\n        beta = np.arctan2(const_b * np.sin(t), (const_b * np.cos(t) + const_a)) / 2\n\n    if abs(alpha + beta - angle) > 1e-8:\n        raise ValueError("There is a bug in this program please report")\n\n    results[\'alpha\'] = alpha\n    results[\'beta\'] = beta\n    # find principal relative radii\n    c2a = np.cos(alpha) ** 2\n    c2b = np.cos(beta) ** 2\n    s2a = np.sin(alpha) ** 2\n    s2b = np.sin(beta) ** 2\n\n    # From contact mechanics by Johnson pg 85 (eq 4.4)\n    with np.errstate(divide=\'ignore\'):\n        r1_rel = 1 / (c2a / r1[0] + s2a / r1[1] + c2b / r2[0] + s2b / r2[1])\n        r2_rel = 1 / (s2a / r1[0] + c2a / r1[1] + s2b / r2[0] + c2b / r2[1])\n    results[\'relative_radii\'] = [r1_rel, r2_rel]\n    # reduction of the problem\n    results[\'r_e\'] = (r1_rel * r2_rel) ** 0.5\n    e_star = 1 / ((1 - v[0] ** 2) / moduli[0] + (1 - v[1] ** 2) / moduli[1])\n    results[\'e_star\'] = e_star\n    # check validity of radii\n    if r1_rel < 0 or r2_rel < 0:\n        raise ValueError("Relative radii of curvature are negative")\n    if r1_rel == r2_rel == inf:\n        raise ValueError("Conformal contacts are not supported by the "\n                         "hertzian theory")\n\n    if r1_rel / r2_rel > 1e5 or r2_rel / r1_rel > 1e5:\n        results[\'contact_shape\'] = \'line\'\n        if not line:\n            raise ValueError(\'Line contact detected, if this is intentional \'\n                             \'the line key word should be set to True\')\n        r = min(r1_rel, r2_rel)\n        a = np.sqrt(4 * load * r / np.pi / e_star)\n        results[\'contact_radii\'] = [rad if rad == inf else a for rad in\n                                    [r1_rel, r2_rel]]\n        results[\'contact_area\'] = float(\'inf\')\n        results[\'mean_pressure\'] = load / a\n        p0 = 2 * load / np.pi / a\n        results[\'max_pressure\'] = p0\n        results[\'pressure_f\'] = _pressure_line_contact(a, load)\n        results[\'surface_tensile_stress_f\'] = _pressure_line_contact(a, load, neg=True)\n\n        results[\'stress_f\'] = _stress_line_contact(a, p0)\n        c = [1 / (1 + 4 * (v1 - 1) * v1) ** 0.5 if v1 <= 0.1938 else\n             1.164 + 2.975 * v1 - 2.906 * v1 ** 2 for v1 in v]\n        zeta = [0 if v1 <= 0.1938 else 0.223 + 2.321 * v1 - 2.397 * v1 ** 2 for v1 in v]\n        results[\'max_von_mises_stress\'] = [c1 * p0 for c1 in c]\n        results[\'max_von_mises_depth\'] = [a * zeta1 for zeta1 in zeta]\n\n        # The following is taken from deeg\n\n        def line_opt_fn(psi, v1):\n            return -1 * max(\n                psi - psi * v1 + (-1 + 2 * psi ** 2 * (v1 - 1) + 2 * v1) / (2 * np.sqrt(1 + psi ** 2)),\n                psi * (psi / np.sqrt(1 + psi ** 2) - 1),\n                v1 * (np.sqrt(1 + psi ** 1) - psi) - 1 / (2 * np.sqrt(1 + psi ** 2)))\n\n        line_opts = [optimize.minimize(line_opt_fn, np.array([0.48086782]), bounds=[[0, 10]], args=v1) for v1 in v]\n\n        results[\'max_shear_stress_b\'] = [out.fun * -1 * p0 if out.success else None for out in line_opts]\n        results[\'depth_of_max_shear\'] = [out.x * a if out.success else None for out in line_opts]\n\n    elif r1_rel == r2_rel:\n        if line:\n            raise ValueError(\'This is a spherical contact, the line flag \'\n                             \'should be set to false or not set\')\n        results[\'contact_shape\'] = \'sphere\'\n        # spherical contact\n        a = (3 * load * r1_rel / 4 / e_star) ** (1 / 3)\n        results[\'contact_radii\'] = [a, a]\n        results[\'contact_area\'] = np.pi * a ** 2\n        results[\'mean_pressure\'] = load / results[\'contact_area\']\n        results[\'total_deflection\'] = a ** 2 / r1_rel\n        p0 = 3 * load / (2 * np.pi * a ** 2)\n        results[\'max_pressure\'] = p0\n        results[\'surface_displacement_b_f\'] = [_displacement_spherical_contact(moduli[0],\n                                                                               v[0], a, p0),\n                                               _displacement_spherical_contact(moduli[1], v[1], a, p0)]\n        results[\'pressure_f\'] = _pressure_spherical_contact(a, p0)\n        results[\'max_tensile_stress_b\'] = [(1 - 2 * v1) * p0 / 3 for v1 in v]\n        results[\'stress_z_axis_b_f\'] = [_stress_z_axis_spherical(a, p0, v1) for v1 in v]\n\n        # results[\'max_von_mises_stress_b\'] = [p0 * (1.30075 + 0.87825 * v1 +\n        #                                           0.54373 * v1 ** 2) for v1 in v]\n        # results[\'max_von_mises_depth_b\'] = [a * (0.38167 + 0.33136 * v1) for v1 in v]\n\n        results[\'stress_surface_axis_b_f\'] = [_stress_surface_spherical(a, p0, v1) for v1 in v]\n        # The following is taken from Deeg\n        shear_opts = [\n            optimize.minimize(lambda psi: -0.5 * (-1 + 3 / 2 / (1 + psi ** 2) + psi * (1 + v1) * np.arctan(1 / psi)),\n                              np.array([0.48086782]), bounds=[[0, 10]]) for v1 in v]\n\n        results[\'max_shear_stress_b\'] = [out.fun * (-1 * p0) if out.success else None for out in shear_opts]\n        results[\'max_shear_depth_b\'] = [out.x * a if out.success else None for out in shear_opts]\n\n    else:\n        if line:\n            raise ValueError(\'This is an elliptical contact, the line flag \'\n                             \'should be set to false or not set\')\n        results[\'contact_shape\'] = \'elliptical\'\n\n        # elliptical contact parameters are named as in the reference (Deeg)\n\n        theta = [4 * (1 - v1 ** 2) / e1 for v1, e1 in zip(v, moduli)]\n        r = 1 / r1[0] + 1 / r1[1] + 1 / r2[0] + 1 / r2[1]\n        r1_elliptical = 1 / r1[0] - 1 / r1[1]\n        r2_elliptical = 1 / r2[0] - 1 / r2[1]\n        omega = np.arccos(\n            np.sqrt(r1_elliptical ** 2 + r2_elliptical ** 2 + r1_elliptical * r2_elliptical * np.cos(2 * angle)) / r)\n        # k1,k2,k3=0.04,0.56,0.85\n        # g0=k1 if omega <=  5/180*np.pi else 0\n        # g1=g0 if omega >=  1/180*np.pi else 0\n        # g2=k2 if omega <= 73/180*np.pi else 0\n        # g3=g2 if omega >   5/180*np.pi else 0\n        # g4=k3 if omega >  73/180*np.pi else 0\n\n        # k_init=g0+g2+g4\n\n        # check this works, might be very slow\n        try:\n            k = optimize.brentq(_k_root, 0.00001, 1,\n                                args=(omega, integration_error),\n                                rtol=root_error)\n        except ValueError:\n            raise ValueError("Root finding for elliptical contact failed, "\n                             "ensure contact parameters are correct, "\n                             "if problem persists please report.")\n\n        f = (2 * _i(k) / np.pi / (np.sin(omega / 2)) ** 2) ** (1 / 3)\n        g = (2 * _j(k) / np.pi / (np.cos(omega / 2)) ** 2) ** (1 / 3)\n\n        a = f * (3 * load / 8 / r * (theta[0] + theta[1])) ** (1 / 3)\n        b = g * (3 * load / 8 / r * (theta[0] + theta[1])) ** (1 / 3)\n\n        q = a * b * np.pi\n\n        alpha1 = 3 * load * theta[0] * _h(k) / a / 8 / np.pi\n        alpha2 = alpha1 * theta[1] / theta[0]\n        deflection = alpha1 + alpha2\n\n        p0 = 3 * load / 2 / q\n\n        if r1_rel < r2_rel:\n            alpha, beta = alpha + np.pi / 2, beta + np.pi / 2\n        # end of the algorithm in the reference\n\n        results[\'max_pressure\'] = p0\n        results[\'contact_radii\'] = [a, b]\n        results[\'contact_area\'] = q\n        results[\'mean_pressure\'] = p0 / q\n        results[\'total_deflection\'] = deflection\n        results[\'deflection_b\'] = [alpha1, alpha2]\n        results[\'pressure_f\'] = _pressure_elliptical_contact(a, b, p0, alpha, beta)\n        results[\'surface_displacement_b_f\'] = [_displacement_elliptical(\n            a, b, p0, alpha, beta, v1, e1) for v1, e1 in zip(v, moduli)]\n        # TODO fill in here from Johnson\n        # TODO make own method for finding the maximum stresses\n    return results\n\n\n###############################################################################\n# Functions for elliptical contact results\n###############################################################################\ndef _pressure_elliptical_contact(a, b, p0, alpha, beta):\n    def pressure(x, y, transform=0):\n        """\n        Pressure for an elliptical contact\n\n        Parameters\n        ----------\n        x,y : array-like\n            x and y coordinates of the points of interest\n        transform : int {0,1,2}, optional (0)\n            a flag which defines which axes the result is displayed on. If set\n            to 0 the result is displayed on the \'contact axes\' which are\n            aligned with the principal radii of the conatct ellipse. If set to\n            1 or 2 the result is aligned with the axes of the first or second\n            body respectively.\n\n        Returns\n        -------\n        pressure : array\n            The contact pressure at each of the points of interest\n\n        Notes\n        -----\n        The pressure distribution is given by:\n            p(x,y)=p0*(1-(x/a)**2-(y/b)**2)**0.5\n\n        References\n        ----------\n\n        [1] Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge\n        University Press. doi:10.1017/CBO9781139171731\n        """\n        if transform:\n            x, y = _transform_axes(x, y, [alpha, beta][transform - 1])\n        squared = np.clip((1 - (x / a) ** 2 - (y / b) ** 2), 0, float(\'inf\'))\n        return p0 * squared ** 0.5\n\n    return pressure\n\n\ndef _displacement_elliptical(a, b, p0, alpha, beta, v, modulus):\n    """\n    Gives a closure for the surface z displacement for an elliptical contact\n    """\n    # memoize the elliptical integrals\n    l_johnson = None\n    m_johnson = None\n    n_johnson = None\n\n    def surface_displacement(x, y, transform=0):\n        """\n        Into surface displacement at the surface for an elliptical contact\n\n        Parameters\n        ----------\n        x,y : array-like\n            x and y coordinates of the points of interest\n        transform : int {0,1,2}, optional (0)\n            a flag which defines which axes the result is displayed on. If set\n            to 0 the result is displayed on the \'contact axes\' which are\n            aligned with the principal radii of the contact ellipse. If set to\n            1 or 2 the result is aligned with the axes of the first or second\n            body respectively.\n\n        Returns\n        -------\n        displacement : array\n            The into surface displacement at each of the points of interest\n\n        Notes\n        -----\n        The pressure distribution is given by:\n            p(x,y)=p0*(1-(x/a)**2-(y/b)**2)**0.5\n\n        References\n        ----------\n\n        [1] Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge\n        University Press. doi:10.1017/CBO9781139171731\n        """\n        nonlocal l_johnson, m_johnson, n_johnson\n        if l_johnson is None:\n            if b > a:\n                raise ValueError("Change in a>b or b>a between sources, "\n                                 "sort out")\n            e = (1 - b ** 2 / a ** 2) ** 0.5\n\n            l_johnson = np.pi * p0 * b * special.ellipk(e)\n            m_johnson = np.pi * p0 * b / e ** 2 / a ** 2 * (special.ellipk(e) - special.ellipe(e))\n            n_johnson = np.pi * p0 * b / a ** 2 / e ** 2 * (\n                (a ** 2 / b ** 2) * special.ellipe(e) - special.ellipk(e))\n\n        if transform:\n            x, y = _transform_axes(x, y, [alpha, beta][transform - 1])\n\n        out_of_bounds = np.clip((1 - (x / a) ** 2 - (y / b) ** 2), 0, float(\'inf\')) == 0\n        displacement = np.array((1 - v ** 2) / modulus / np.pi * (l_johnson - m_johnson * x ** 2 - n_johnson * y ** 2))\n\n        displacement[out_of_bounds] = float(\'Nan\')\n\n        return displacement\n\n    return surface_displacement\n\n\ndef _transform_axes(x, y, angle):\n    """\n    Transforms points on one set of axes to another, the two sets share an\n    origin and are off set by angle\n\n    """\n    x = np.asarray(x)\n    y = np.asarray(y)\n    x1 = x * np.cos(angle) - y * np.sin(angle)\n    y1 = x * np.sin(angle) + y * np.cos(angle)\n\n    return x1, y1\n\n\n###############################################################################\n# Functions to find elliptical contact parameters\n###############################################################################\ndef _k_root(k, aux_angle, int_error=1e-6):\n    """\n    Defines the equation that k (b/a) is the root of for elliptical contacts\n    """\n    return ((k ** 3 / np.tan(aux_angle / 2) ** 2) -\n            (_j(k, int_error) / _i(k, int_error)))\n\n\ndef _h(k, int_error=1e-6):\n    """\n    The H parameter in the reference (Deeg), defined in table 6\n    """\n    return integrate.quad(lambda psi: 1 / np.sqrt(1 - (1 - k ** 2) * np.sin(psi) ** 2),\n                          0, np.pi / 2, epsrel=int_error)[0]\n\n\ndef _i(k, int_error=1e-6):\n    """\n    The I parameter in the reference (Deeg), defined in table 6\n    """\n\n    return integrate.quad(lambda psi: np.cos(psi) ** 2 / np.sqrt((1 - (1 - k ** 2) * np.sin(psi) ** 2) ** 3),\n                          0, np.pi / 2, epsrel=int_error)[0]\n\n\ndef _j(k, int_error=1e-6):\n    """\n    The J parameter in the reference (Deeg), defined in table 6\n    """\n    if k == 0:\n        return 0\n    return integrate.quad(lambda psi: np.cos(psi) ** 2 / np.sqrt((1 - (1 - 1 / k ** 2) * np.sin(psi) ** 2) ** 3),\n                          0, np.pi / 2, epsrel=int_error)[0]\n\n\n###############################################################################\n# Line contact functions\n###############################################################################\ndef _stress_line_contact(a, p0):\n    """Gives a closure for full field stresses in a line contact\n\n    Parameters\n    ----------\n    a : float\n        the contact radius of the line contact\n    p0 : float\n        The maximum pressure of the line contact\n\n    Returns\n    -------\n    Stress : closure\n        Callable closure that gives the stesses in the x and z directions and\n        shear stress in the xz plane\n\n    Notes\n    -----\n    Stress in the y direction is v*(sima_x+sigma_z) where v is the poissions\n    ratio\n\n    References\n    ----------\n    [1] Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge\n    University Press. doi:10.1017/CBO9781139171731\n    """\n\n    def stress(x, z):\n        """ Full field stresses for a hertzian line contact\n\n        Parameters\n        ----------\n        x,z : array-like\n            x and z coordinates of points of interest\n\n        Returns\n        -------\n        Stresses : dict\n            Dictionary of stresses at the points of interest with keys\n            {\'sigma_x\', \'sigma_z\', \'tau_xz\'}.\n\n        Notes\n        -----\n        The stress in the Y direction (along the axis of contact) can be found\n        by v*(sigma_x+sigma_z) where v is the poisson\'s ratio.\n\n        References\n        ----------\n        [1] Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge\n        University Press. doi:10.1017/CBO9781139171731\n        """\n        x, z = np.asarray(x), np.asarray(z)\n        a2 = a ** 2\n\n        # m and n as defined on page 103 of Johnson\n        c = 0.5 * (np.sqrt((a2 - x ** 2 + z ** 2) ** 2 + 4 * x ** 2 * z ** 2) + (a2 - x ** 2 + z ** 2))\n        m = np.sign(z) * c\n        n = np.sign(x) * c\n\n        sig_x = -1 * p0 / a * (m * (1 + (z ** 2 + n ** 2) / (m ** 2 + n ** 2)) - 2 * z)\n        sig_z = -1 * p0 / a * m * (1 + (z ** 2 + n ** 2) / (m ** 2 + n ** 2))\n        tau_xz = -1 * p0 / a * n * ((m ** 2 - z ** 2) / (m ** 2 + n ** 2))\n        return {\'sigma_x\': sig_x, \'sigma_z\': sig_z, \'tau_xz\': tau_xz}\n\n    return stress\n\n\ndef _pressure_line_contact(a, load, neg=False):\n    """Gives a closure for the pressure in a line contact\n\n    Parameters\n    ----------\n\n    a : float\n        Contact radius\n    load : float\n        load per unit length for the line contact\n\n    Returns\n    -------\n    surface_pressure : closure\n        A callable closure which gives the pressure at any point in the contact\n    """\n\n    def surface_pressure(x):\n        """The surface pressure in a hertzian line contact\n\n        Surface pressures for a hertzian line contact, no coordinate transforms\n        are completed on the input coordinates. The x axis in this function is\n        perpendicular to the axes of the cylinders in contact.\n\n        Parameters\n        ----------\n        x : array-like\n            The x-coordinates of the positions of interest\n\n        Returns\n        -------\n        pressure : array\n            The pressure at the points of interest\n\n        Notes\n        -----\n        For a line contact the radial stress at the surface is always equal to\n        the pressure at the surface and compressive[1]\n\n        References\n        ----------\n        [1] Johnson, K. (1985). Contact Mechanics. Cambridge: Cambridge\n        University Press. doi:10.1017/CBO9781139171731\n\n        """\n        x = np.clip(np.asarray(x), -1 * a, a)\n        pressure = 2 * load / np.pi / a ** 2 * (a ** 2 - x ** 2) ** 0.5\n        if neg:\n            return -1 * pressure\n        else:\n            return pressure\n\n    return surface_pressure\n\n\n# Spherical contact functions\n\ndef _stress_z_axis_spherical(a, p0, v):\n    """ Gives a closure for the stresses on the z axis in a spherical contact\n\n    Parameters\n    ----------\n    a : float\n        The contact radius\n    p0 : float\n        The maximum pressure according to hertz\n    v : float\n        The possions ratio of the surface\n\n    Returns\n    -------\n    stress : closure\n        A callable that can be used to find the stress at any point on the\n        z axis\n    """\n\n    def stress(z):\n        """ Stresses at any point on the z axis for a point contact\n\n        Parameters\n        ----------\n        z : array-like\n            The z coordinates of the points of interest\n\n        Returns\n        -------\n        stress : dict\n            The stresses at the points of interest with keys: {\'sigma_r\', \'sigma_theta\', \'sigma_z\'}\n            each value will be an array with the same shape as r\n        """\n        z = np.asarray(z)\n        sig_r = p0 * (- (1 + v) * (1 - (z / a) * np.arctan(a / z)) + 0.5 * 1 / (1 + z ** 2 / a ** 2))\n        sig_theta = sig_r.copy()\n        sig_z = -p0 / (1 + z ** 2 / a ** 2)\n        return {\'sigma_r\': sig_r, \'sigma_theta\': sig_theta, \'sigma_z\': sig_z}\n\n    return stress\n\n\ndef _stress_surface_spherical(a, p0, v):\n    """ Gives a list of closures for the stresses on each surface\n\n    Parameters\n    ----------\n    a : float\n        The contact radius\n    p0 : float\n        The maximum contact pressure\n    v : float\n        The possions ratio of the surface\n    """\n\n    def stress(r):\n        """Stresses on the surface for a spherical contact\n\n        Parameters\n        ----------\n        r : array-like\n            The radial coordinate of the points of interest\n\n        Returns\n        -------\n        stresses : dict\n            The stresses at each point on the surface,  with keys: {\'sigma_r\', \'sigma_theta\', \'sigma_z\'}\n            each value will be an array with the same shape as r\n        """\n        r = np.asarray(r)\n        r2 = r ** 2\n        r2a2 = r2 / a ** 2\n        inside = r <= a\n        sig_r, sig_theta, sig_z = np.zeros_like(r), np.zeros_like(r), np.zeros_like(r)\n        sig_r[inside] = p0 * ((1 - 2 * v) / 3 * (a ** 2 / r[inside] ** 2) * (1 - (1 - r2a2[inside]) ** (3 / 2)) -\n                              np.sqrt(1 - r2a2[inside]))\n        sig_theta[inside] = -p0 * ((1 - 2 * v) / 3 * (a ** 2 / r[inside] ** 2) * (1 - (1 - r2a2[inside]) ** (3 / 2)) -\n                                   2 * v * np.sqrt(1 - r2a2[inside]))\n        sig_z[inside] = -np.sqrt(1 - r2a2[inside]) * p0\n        outside = np.logical_not(inside)\n        sr_out = p0*(1-2*v)*a**2/3/r2[outside]\n        sig_r[outside] = sr_out\n        sig_theta[outside] = -sr_out\n        return {\'sigma_r\': sig_r, \'sigma_theta\': sig_theta, \'sigma_z\': sig_z}\n\n    return stress\n\n\ndef _pressure_spherical_contact(a, p0):\n    """ Gives a closure for the surface pressures\n\n    Parameters\n    ----------\n    a : float\n        The contact radius\n    p0 : float\n        The maximum pressure according to hertz\n\n    Returns\n    -------\n    pressure : closure\n        A callable that can be used to find the pressure at any point on the\n        surface\n    """\n\n    def pressure(x, y=0):\n        """Contact pressure for a spherical contact according to hertz\n\n        Parameters\n        ----------\n        x : array-like\n            The x coordinated of the points of interest\n        y : array-like, optional (0)\n            The y coordinated of the points of interest\n\n        Returns\n        -------\n        pressure : array\n            The surface pressure at the specified points\n        """\n        r = np.asarray(np.sqrt(x ** 2 + y ** 2))\n        squared = np.clip(1 - (r / a) ** 2, 0, float(\'inf\'))\n        return p0 * squared ** 0.5\n\n    return pressure\n\n\ndef _displacement_spherical_contact(young_modulus, v, a, p0):\n    def displacement(x, y=0):\n        """\n        Surface displacements for spherical contacts\n\n        Parameters\n        ----------\n\n        x,y : float or array-like\n            x and y coordinates of the surface points of interest\n\n        Returns\n        -------\n        result : dict\n            With members \'uz\' and \'ur\'; in to surface and radial displacements\n            respectively\n\n        See Also\n        --------\n        hertz\n\n        References\n        ----------\n        Contact mechanics. Johnson\n        """\n\n        r = np.asarray(np.sqrt(x ** 2 + y ** 2))\n        axial = np.zeros_like(r)\n        radial = np.zeros_like(r)\n        r_in = r[r <= a]\n        r_out = r[r > a]\n\n        axial[r <= a] = ((1 - v ** 2) * np.pi * p0) / (young_modulus * 4 * a) * (2 * a ** 2 - r_in ** 2)\n        axial[r > a] = ((1 - v ** 2) * p0) / \\\n                       (young_modulus * 2 * a) * ((2 * a ** 2 - r_out ** 2) * np.arcsin(a / r_out) +\n                                                  r_out * a * np.sqrt(1 - a ** 2 / r_out ** 2))\n        with np.errstate(divide=\'ignore\', invalid=\'ignore\'):\n            radial[r <= a] = ((1 - 2 * v) * (1 + v) * a ** 2 * p0 / (3 * young_modulus * r_in) *\n                              (1 - (1 - r_in ** 2 / a ** 2) ** (3 / 2)))\n\n        radial[np.isnan(radial)] = 0\n\n        radial[r > a] = (1 - 2 * v) * (1 + v) * p0 * a ** 2 / (3 * young_modulus * r_out)\n        return {\'uz\': axial, \'ur\': radial}\n\n    return displacement\n\n\ndef _sanitise_radii(radii):\n    """\n    checks on the radii input to hertz\n    """\n    if not isinstance(radii, abc.Sequence):\n        try:\n            radii = [float(radii)] * 2\n        except TypeError:\n            raise TypeError("radii must be list or number, not a"\n                            " {}".format(type(radii)))\n    else:\n        if len(radii) == 1:\n            radii = [radii[0], radii[0]]\n\n        if len(radii) != 2:\n            raise ValueError("Radii must be a two element list supplied radii"\n                             " list has {} elements".format(len(radii)))\n        try:\n            radii = [float(r) for r in radii]\n        except ValueError:\n            raise TypeError("Elements of radii are not convertible to floats:"\n                            "{}".format(radii))\n    if any([r == 0 for r in radii]):\n        raise ValueError("Radii contains zero values, use float(\'inf\') for fla"\n                         "t surfaces")\n    return np.array(radii)\n\n\ndef _sanitise_material(e, name):\n    """\n    Make sure material properties are valid and in the expected form\n    """\n    if not isinstance(e, abc.Sequence):\n        try:\n            e = 2 * [float(e)]\n        except ValueError:\n            raise TypeError("Material properties should be sequence type or "\n                            "convertible to float, "\n                            f\'{name} supplied is {type(e)}\')\n    if len(e) == 1:\n        e = list(e) * 2\n    if len(e) == 2:\n        if any([e == 0 for e in e]) and name == \'e\':\n            raise ValueError(\'Zero moduli are not supported, supplied moduli\'\n                             f\' were e={e}\')\n        return np.array(e, dtype=float)\n    else:\n        raise ValueError(f"Too many elements supplied in {name}")\n', 'is_package': False},
    'slippy.contact.lubricant': {'source': '"""\nA class for containing information about lubricants, allows the user to set sub models for the density etc,\nshould supply whatever is needed for the reynolds solver and the sub models/ other models in the lubricant\n"""\nimport inspect\nimport typing\nimport warnings\nfrom collections import OrderedDict\n\nfrom slippy.core import _LubricantModelABC\nfrom .lubricant_models import __all__ as built_in_models\nfrom .lubricant_models import constant_array_property\n\n__all__ = [\'Lubricant\']\n\n\nclass Lubricant(_LubricantModelABC):\n    """A class for describing lubricant behaviours\n\n    Parameters\n    ----------\n    name: str\n        The name of the lubricant, used for output and error messages\n    models: OrderedDict\n        The sub models to solve\n    constant_viscosity: float, optional (None)\n        The viscosity, should only be supplied if the viscosity is constant, otherwise an appropriate model should be\n        used. This adds both viscosity and nd_viscosity models.\n    constant_density: float, optional (None)\n        The density, should only be supplied if the density is constant, otherwise an appropriate model should be used.\n        This adds both density and nd_density models\n\n    Attributes\n    ----------\n    sub_models: OrderedDict\n        The sub models which will be executed on each iteration of the reynolds solver\n    built_in_models: list\n        A list of all the named sub models built in to slippy, these are all available in slippy.contact.*model_name*\n\n    Methods\n    -------\n\n    Notes\n    -----\n\n    Examples\n    --------\n    """\n\n    built_in_models = tuple(built_in_models)\n\n    def __init__(self, name: str, models: OrderedDict = None,\n                 constant_viscosity: float = None, constant_density: float = None):\n\n        self.name = name\n        self.sub_models = OrderedDict()\n\n        if constant_viscosity is not None:\n            self.add_sub_model(\'viscosity\', constant_array_property(constant_viscosity))\n            self.add_sub_model(\'nd_viscosity\', constant_array_property(1.0))\n        if constant_density is not None:\n            self.add_sub_model(\'density\', constant_array_property(constant_density))\n            self.add_sub_model(\'nd_density\', constant_array_property(1.0))\n\n        if models is not None:\n            try:\n                for param, func in models.items():\n                    self.add_sub_model(param, func)\n            except AttributeError:\n                raise TypeError(\'Models should be ordered dict of callable objects\')\n            except TypeError:\n                raise TypeError(\'Models should be ordered dict of callable objects\')\n\n    def add_sub_model(self, parameter: str, function: typing.Callable):\n        """\n        Adds a lubricant sub model to be solved on each iteration of the solver\n\n        Parameters\n        ----------\n        parameter: str\n            The name of the parameter found by the sub model, each sub model can only find one parameter\n        function: callable\n            The model function which will be called on each iteration of the solver. See notes for calling details\n\n        Notes\n        -----\n        The function will be called by passing the current model state dictionary to it as key word arguments. This\n        means that all models should:\n        - Accept the required keyword arguments\n        - Have no positional arguments\n        - Accept un used keyword arguments as **kwargs\n\n        The function can find any value but typically it will out put either a single value or a numpy array of values.\n\n        No additional parameters can be passed to the function when it is called (such as coefficients for a particular\n        fluid). This sort of parametrisation can be applied by passing a closure as the callable.\n\n        A list of the named sub models built in to slippy is available as the built_in_models attribute of this class.\n\n        Sub models will execute in the order they are added to this dict.\n\n        Examples\n        --------\n        #TODO\n        """\n        # check that parameter is a string, with no spaces etc.\n        assert isinstance(parameter, str), \'Parameter name must be a string\'\n        assert parameter.isidentifier(), \'Parameter name must be a valid variable name\'\n        # check that function is callable\n        assert callable(function), \'Function must be callable\'\n        # check that function has ** kwargs argument\n        full_arg_spec = inspect.getfullargspec(function)\n        assert full_arg_spec.varkw is not None, \'Function must accept a variable number of keyword arguments (**kwargs)\'\n        # check that function has no positional only arguments\n\n        # warn if collision with existing sub model\n        if parameter in self.sub_models:\n            warnings.warn(f"Parameter {parameter} is already in sub models, this action has replaced the existing "\n                          f"sub model")\n        # Add function to sub_models ordered dict\n        self.sub_models[parameter] = function\n\n    def data_check(self, current_state: set) -> set:\n        """Use introspection to check that all sub models will solve properly\n\n        Parameters\n        ----------\n        current_state: set\n            The state at the end of one iteration of the reynolds solver\n\n        Returns\n        -------\n        current_state: set\n            The updated current state with variables from the sub models\n\n        """\n        for key, value in self.sub_models.items():\n            full_arg_spec = inspect.getfullargspec(value)\n            args = full_arg_spec.args\n            for arg in args:\n                if arg not in current_state and arg != \'self\':\n                    raise ValueError(f"Lubricant sub model {key} will not solve, requires {arg}, current state is "\n                                     f"{current_state}")\n            current_state.add(key)\n\n        return current_state\n\n    def solve_sub_models(self, current_state: dict) -> dict:\n        """\n\n        Parameters\n        ----------\n        current_state: dict\n            The current state of the model\n\n        Returns\n        -------\n        previous_state\n\n        """\n        for parameter, func in self.sub_models.items():\n            current_state[parameter] = func(**current_state)\n        return current_state\n', 'is_package': False},
    'slippy.contact.lubricant_models': {'source': '"""\nCommon sub models for lubricants\n\n"""\n\nimport numpy as np\n\n__all__ = [\'constant_array_property\', \'roelands\', \'barus\', \'nd_barus\', \'nd_roelands\', \'dowson_higginson\',\n           \'nd_dowson_higginson\']\n\n\ndef constant_array_property(value: float):\n    """ Produce a closure that returns an index able constant value\n\n    Parameters\n    ----------\n    value: float\n        The value of the constant\n\n    Returns\n    -------\n    inner: closure\n        A closure that returns a fully populated array the same size as the just_touching_gap keyword argument, this is\n        guaranteed to be in the current state dict, and therefore passed as a keyword when sub models are saved.\n\n    Notes\n    -----\n    Using this closure means that lubrication steps can be writen for the general case, using indexing on fluid\n    properties.\n\n    See Also\n    --------\n    constant_array_property\n\n    Examples\n    --------\n    >>> closure = constant_array_property(1.23)\n    >>> constant_array = closure(just_touching_gap = np.ones((5,5)))\n    >>> constant_array.shape\n    (5,5)\n    >>> constant_array[0,0]\n    1,23\n    """\n\n    def inner(just_touching_gap: np.ndarray, **kwargs):\n        return np.ones_like(just_touching_gap) * value\n\n    return inner\n\n\ndef roelands(eta_0, pressure_0, z):\n    """ The roelands pressure viscosity equation\n\n    Parameters\n    ----------\n    eta_0, pressure_0, z: float\n        Coefficients for the equation, see notes for details\n\n    Returns\n    -------\n    inner: closure\n        A callable that produces the viscosity terms according to the Roelands equation, see notes for details\n\n    Notes\n    -----\n    The roelands equation linking viscosity (eta) to the fluid pressure (p) is given by:\n    eta(p) = eta_0*exp((ln(eta_0)+9.67)*(-1+(1+(p/p_0)^z))\n    eta_0, p_0 and z are coefficients that depend on the oil and it\'s temperature.\n\n    """\n    ln_eta_0 = np.log(eta_0) + 9.67\n\n    def inner(pressure: np.ndarray, **kwargs):\n        return eta_0 * np.exp(ln_eta_0 * (-1 + (1 + pressure / pressure_0) ** z))\n\n    return inner\n\n\ndef nd_roelands(eta_0: float, pressure_0: float, pressure_hertzian: float, z: float):\n    """ The roelands pressure viscosity equation in a non dimentional form\n\n    Parameters\n    ----------\n    eta_0, pressure_0, z: float\n        Coefficients for the equation, see notes for details\n    pressure_hertzian: float\n        The hertzian pressure used to non dimentionalise the pressure term in the equation. Should be the same as is\n        used in the reynolds solver\n\n    Returns\n    -------\n    inner: closure\n        A callable that produces the non dimentional viscosity according to the Roelands equation, see notes for details\n\n    Notes\n    -----\n    The roelands equation linking viscosity (eta) to the non dimentional fluid pressure (nd_p) is given by:\n    eta(p)/eta_0 = exp((ln(eta_0)+9.67)*(-1+(1+(nd_p/p_0*p_h)^z))\n    eta_0, p_0 and z are coefficients that depend on the oil and it\'s temperature.\n    p_h is the hertzian pressure used to non dimentionalise the pressure term.\n\n    """\n    ln_eta_0 = np.log(eta_0) + 9.67\n    p_all = pressure_hertzian / pressure_0\n\n    def inner(nd_pressure: np.ndarray, **kwargs):\n        return np.exp(ln_eta_0 * (-1 + (1 + p_all * nd_pressure) ** z))\n\n    return inner\n\n\ndef barus(eta_0: float, alpha: float):\n    """ The Barus pressure viscosity equation\n\n    Parameters\n    ----------\n    eta_0, alpha: float\n        Coefficients in the equation, see notes for details\n\n    Returns\n    -------\n    inner: closure\n        A callable that returns the resulting viscosity according to the barus equation\n\n    Notes\n    -----\n    The Barus equation linking pressure (p) to viscosity (eta) is given by:\n    eta(p) = eta_0*exp(alpha*p)\n    In which eta_0 and alpha are coefficients which depend on the lubricant and it\'s temperature\n    """\n\n    def inner(pressure: np.ndarray, **kwargs):\n        return eta_0 * np.exp(alpha * pressure)\n\n    return inner\n\n\ndef nd_barus(pressure_hertzian: float, alpha: float):\n    """ A non dimentional form of the Barus equation\n\n    Parameters\n    ----------\n    alpha: float\n        A coefficient in the Barus equation, see notes for details\n    pressure_hertzian: float\n        The hertzian pressure used to non dimensionalise the pressure\n\n    Returns\n    -------\n    inner: closure\n        A callable that will produce the non dimentional viscosity according to the barus equation\n\n    Notes\n    -----\n    The non dimentional Barus equation relating the viscosity (eta) to the non dimentional pressure (nd_p) is given by:\n    eta(p)/eta_0 = exp(alpha*p_h*nd_p)\n    In which alpha is alpha is a coefficient which will depend on the lubricant used and the temperature\n    p_h is the hertzian pressure used to non dimentionalise the pressure, this must be the same as is passed to the\n    reynolds solver.\n\n    """\n\n    def inner(nd_pressure: np.ndarray, **kwargs):\n        return np.exp(alpha * pressure_hertzian * nd_pressure)\n\n    return inner\n\n\ndef dowson_higginson(rho_0: float):\n    """ The Dowson Higginson equation relating pressure to density\n\n    Parameters\n    ----------\n    rho_0: float\n        A coefficient of the dowson higginson equation, seen notes for details\n\n    Returns\n    -------\n    inner: closure\n        A callable that returns the density based on the pressure according to the dowson higginson equation\n\n    Notes\n    -----\n    The dowson higginson equation relating pressure (p) to density (rho) is given by:\n    rho(p) = rho_0 * (5.9e8+1.34*p)/(5.9e8+p)\n    In which rho_0 is the parameter of the equation which will depend on the lubricant used and it\'s temperature\n    """\n\n    def inner(pressure: np.ndarray, **kwargs):\n        return rho_0 * (5.9e8 + 1.34 * pressure) / (5.9e8 + pressure)\n\n    return inner\n\n\ndef nd_dowson_higginson(pressure_hertzian: float):\n    """ A non dimentional form of the Dowson Higginson equation relating pressure to density\n\n    Parameters\n    ----------\n    pressure_hertzian: float\n        The hertzian pressure used to non dimentionalise the pressure, this must match the pressure given to the\n        reynolds solver\n\n    Returns\n    -------\n    inner: closure\n        A callable that returns the non dimentional density based on the non dimentional pressure\n\n    Notes\n    -----\n    The non dimentional dowson higginson equation relating non dimensional pressure (nd_p) to density (rho) is given by:\n    rho(p)/rho_0 = (5.9e8+1.34*p_h*nd_p)/(5.9e8+p_h*nd_p)\n    In which p_h is the hertzian pressure used to non denationalise the pressure and rho_0 is a parameter of the\n    dimentional form of the dowson higginson equation. Here the value rho(p)/rho_0 is returned\n    """\n    constant = 5.9e8 / pressure_hertzian\n\n    def inner(nd_pressure: np.ndarray, **kwargs):\n        return (constant + 1.34 * nd_pressure) / (constant + nd_pressure)\n\n    return inner\n', 'is_package': False},
    'slippy.contact.lubrication_steps': {'source': '"""\nModel steps for lubricated contacts\n"""\nimport typing\nimport warnings\nfrom collections.abc import Sequence\nfrom numbers import Number\n\nimport numpy as np\nimport slippy\n\nfrom slippy.core import _NonDimensionalReynoldSolverABC\nfrom ._model_utils import get_gap_from_model\nfrom ._step_utils import make_interpolation_func, solve_normal_loading\nfrom slippy.core.influence_matrix_utils import plan_convolve\nfrom .steps import _ModelStep\nfrom slippy.core.materials import _IMMaterial\n\n__all__ = [\'IterSemiSystem\']\n\n\nclass IterSemiSystem(_ModelStep):\n    """\n    Lubrication solutions by iteration of semi systems\n\n    Parameters\n    ----------\n    step_name: str\n        An identifying name for the step used for errors and outputs\n    reynolds_solver: _NonDimensionalReynoldSolverABC\n        A reynolds solver object which will be used to solve for pressures\n    rolling_speed: float or Sequence of float, optional (None)\n        The mean speed of the surfaces (u1+u2)/2 parameters can be:\n\n        * A constant (float) value, indicating a constant rolling speed.\n        * A two element sequence of floats, indicating the the start and finish rolling speed, if this is used, the\n          movement_interpolation_mode will be used to generate intermediate values\n        * A 2 by n array of n rolling speed and n time values normalised to a 0-1 scale. array[0] should be\n          position values and array[1] should be time values, time values must be between 0 and 1. The\n          movement_interpolation_mode will be used to generate intermediate values\n    number_of_steps: int\n        The number of sub steps the problem will be split into, together with the time_period this controls the duration\n        of the time steps used\n    no_time: bool, optional (False)\n        Set to true if there is no time dependence and the time steps can be solved in any order (no permanent changes\n        between steps such as plastic deformation or heat generation), if True the model will be solved more efficiently\n    time_period: float, optional (1.0)\n        The total time period of this model step, used for solving sub-models and writing outputs\n    off_set_x, off_set_y: float or Sequence of float, optional (0.0)\n        The off set between the surfaces in the x and y directions, this can be a relative off set or an absolute off\n        set, controlled by the relative_loading parameter:\n\n        * A constant (float) value, indicating a constant offset between the surfaces (no relative movement of profiles)\n        * A two element sequence of floats, indicating the the start and finish offsets, if this is used, the\n          movement_interpolation_mode will be used to generate intermediate values\n        * A 2 by n array of n absolute position values and n time values normalised to a 0-1 scale. array[0] should be\n          position values and array[1] should be time values, time values must be between 0 and 1. The\n          movement_interpolation_mode will be used to generate intermediate values\n    interference, normal_load: float or Sequence of float, optional (None)\n        The interference and normal load between the surfaces, only one of these can be set (the other will be solved\n        for) setting neither keeps the interference as it is at the start of this model step. As above for the off sets,\n        either of these parameters can be:\n\n        * A constant (float) value, indicating a constant load/ interference between the surfaces.\n        * A two element sequence of floats, indicating the the start and finish load. interference, if this is used, the\n          movement_interpolation_mode will be used to generate intermediate values\n        * A 2 by n array of n absolute position values and n time values normalised to a 0-1 scale. array[0] should be\n          position values and array[1] should be time values, time values must be between 0 and 1. The\n          movement_interpolation_mode will be used to generate intermediate values\n    relative_loading: bool, optional (False)\n        If True the load or displacement and off set will be applied relative to the value at the start of the step,\n        otherwise the absolute value will be used. eg, if the previous step ended with a load of 10N and this step ramps\n        from 0 to 10N setting relative_loading to True will ramp the total load form 10 to 20N over this step.\n    movement_interpolation_mode: str or int, optional (\'linear\')\n        Any valid input to scipy.interpolate.interp1d as the \'kind\' parameter, using \'nearest\', \'previous\' or \'next\'\n        will cause a warning. This parameter controls how the offset and loading is interpolated over the step\n    profile_interpolation_mode: {\'nearest\', \'linear\'}, optional (\'nearest\')\n        Used to generate the grid points for the second surface at the location of the grid points for the first\n        surface, nearest ensures compatibility with sub models which change the profile, if the grid spacings of the\n        surfaces match\n    periodic_geometry: bool, optional (False)\n        If True the surface profile will warp when applying the off set between the surfaces\n    periodic_axes: tuple, optional ((False, False))\n        For each True value the corresponding axis will be solved by circular convolution, meaning the result is\n        periodic in that direction. NOTE: this only controls the deformation result from the materials, ensure that the\n        reynolds equation solver used supports periodic solutions and is set to produce a periodic solution to the\n        pressure equation. Additionally, ensure that the axes of periodicity match.\n    max_it_pressure: int, optional (100)\n        The maximum number of iterations in the fluid pressure calculation loop\n    rtol_pressure: float, optional (1e-7)\n        The relative tolerance for the fluid pressure calculation loop\n    max_it_interference: int, optional (100)\n        The maximum number of iterations in the loop that finds the interference between the surfaces\n    rtol_interference: float, optional (1e-7)\n        The relative tolerance on the total load (integral of the pressure solution minus the applied load)\n    initial_guess: {callable, \'previous\', list}, optional (\'previous\')\n        The initial guess for the interference, and/ or pressure profile between the surfaces, any callable will be\n        called with the contact model and the undeformed nd_gap as positional arguments, it must return the interference\n        and the pressure profile. \'previous\' will use the result(s) from the previous step, if results are not found the\n        interference and pressure profile will be set to 0. Can also be a 2 element list, the first element being the\n        interference and the second being the pressure profile as an array, if this is the wrong shape zeros wil be\n        used.\n    no_update_warning: bool, optional (True)\n        Change to False to suppress warning given when no movement or loading changes are specified\n\n    Notes\n    -----\n    The solver iterates through a \'pressure loop\' until the solution has converged to a set of pressure values, then the\n    loading is checked, if the total pressure is too low the surfaces are brought closer together. This is continued\n    until the total load has converged to the set value. This outer loop is referred to as the interference loop.\n\n    Examples\n    --------\n    In this example we will model smooth surface EHL with a non newtonian fluid:\n\n    >>> import slippy\n    >>> slippy.CUDA = False  # Note: we are using a reynolds solver which does not currently support the CUDA back end\n    >>> import slippy.surface as s\n    >>> import slippy.contact as c\n    >>>\n    >>> radius = 0.01905       # The radius of the ball\n    >>> load = 800             # The load on the ball in N\n    >>> rolling_speed = 4      # The rolling speed in m/s (The mean speed of the surfaces)\n    >>> youngs_modulus = 200e9 # The youngs modulus of the surfaces\n    >>> p_ratio = 0.3          # The poission\'s ratio of the surfaces\n    >>> grid_size = 33         # The number of points in the descretisation grid\n    >>> eta_0 = 0.096          # Coefficient in the roelands pressure-viscosity equation\n    >>> roelands_p_0 = 1/5.1e-9# Coefficient in the roelands pressure-viscosity equation\n    >>> roelands_z = 0.68      # Coefficient in the roelands pressure-viscosity equation\n    >>>\n    >>> # Solving the hertzian contact to get the domain size and the initial guess\n    >>> hertz_result = c.hertz_full([radius, radius], [float(\'inf\'), float(\'inf\')],\n    >>>                             [youngs_modulus, youngs_modulus],\n    >>>                             [p_ratio, p_ratio], load)\n    >>> hertz_pressure = hertz_result[\'max_pressure\']\n    >>> hertz_a = hertz_result[\'contact_radii\'][0]\n    >>> hertz_deflection = hertz_result[\'total_deflection\']\n    >>> hertz_pressure_function = hertz_result[\'pressure_f\']\n    >>>\n    >>> # make the surfaces\n    >>> ball = s.RoundSurface((radius,)*3, shape = (grid_size, grid_size),\n    >>>                       extent=(hertz_a*4,hertz_a*4), generate = True)\n    >>> flat = s.FlatSurface()\n    >>>\n    >>> # assigning materials\n    >>> steel = c.Elastic(\'steel\', {\'E\' : youngs_modulus, \'v\' : p_ratio})\n    >>> ball.material = steel\n    >>> flat.material = steel\n    >>>\n    >>> # make the non newtonian fluid\n    >>> oil = c.Lubricant(\'oil\') # Making a lubricant object to contain our sub models\n    >>> oil.add_sub_model(\'nd_viscosity\', c.lubricant_models.nd_roelands(eta_0, roelands_p_0,\n    >>>                                                                  hertz_pressure, roelands_z))\n    >>> oil.add_sub_model(\'nd_density\', c.lubricant_models.nd_dowson_higginson(hertz_pressure))\n    >>>\n    >>> # make the contact model\n    >>> my_model = c.ContactModel(\'lubrication_test\', ball, flat, oil)\n    >>>\n    >>> # make a reynolds solver\n    >>> reynolds = c.UnifiedReynoldsSolver(time_step = 0,\n    >>>                                    grid_spacing = ball.grid_spacing,\n    >>>                                    hertzian_pressure = hertz_pressure,\n    >>>                                    radius_in_rolling_direction=radius,\n    >>>                                    hertzian_half_width=hertz_a,\n    >>>                                    dimentional_viscosity=eta_0,\n    >>>                                    dimentional_density=872)\n    >>>\n    >>> # Find the hertzian pressure distribution as an initial guess\n    >>> X, Y = ball.get_points_from_extent()\n    >>> X, Y = X + ball._total_shift[0], Y + ball._total_shift[1]\n    >>> hertzian_pressure_dist = hertz_pressure_function(X, Y)\n    >>>\n    >>> # Making the step\n    >>> step = c.IterSemiSystem(\'main\', reynolds, rolling_speed, 1, no_time=True, normal_load=line_load,\n    >>>                         initial_guess=[hertz_deflection, hertzian_pressure_dist],\n    >>>                         relaxation_factor=0.05, max_it_interference=3000)\n    >>>\n    >>> # Adding the step to the contact model\n    >>> my_model.add_step(step)\n    >>>\n    >>> # solve the model:\n    >>> state = my_model.solve()\n\n    """\n    "The minimum number of iterations in the reynolds solving loop"\n    _dh = 0\n    "The base change in height"\n    _interferences = list()\n    _load_errors = list()\n\n    _reynolds: typing.Optional[_NonDimensionalReynoldSolverABC] = None\n    initial_guess: typing.Optional[typing.Union[typing.Callable, list, str]]\n\n    def __init__(self, step_name: str, reynolds_solver: _NonDimensionalReynoldSolverABC,\n                 rolling_speed: typing.Union[float, typing.Sequence[float]],\n                 number_of_steps: int = 1,\n                 no_time: bool = False, time_period: float = 1.0,\n                 off_set_x: typing.Union[float, typing.Sequence[float]] = 0.0,\n                 off_set_y: typing.Union[float, typing.Sequence[float]] = 0.0,\n                 interference: typing.Union[float, typing.Sequence[float]] = None,\n                 normal_load: typing.Union[float, typing.Sequence[float]] = None,\n                 relative_loading: bool = False,\n                 movement_interpolation_mode: str = \'linear\',\n                 profile_interpolation_mode: str = \'nearest\',\n                 periodic_geometry: bool = False, periodic_axes: tuple = (False, False),\n                 max_it_pressure: int = 5000, rtol_pressure: float = 2e-6,\n                 max_it_interference: int = 5000,\n                 rtol_interference: float = 1e-4,\n                 relaxation_factor: float = 0.1,\n                 initial_guess: typing.Union[typing.Callable, str, typing.Sequence] = \'previous\',\n                 no_update_warning: bool = True):\n\n        self._adjust_height_every_step = True\n        self._initial_guess = initial_guess\n        self._no_time = no_time\n        self.total_time = time_period\n        self._relative_loading = relative_loading\n        self.profile_interpolation_mode = profile_interpolation_mode\n        self._periodic_profile = periodic_geometry\n        self._periodic_axes = periodic_axes\n        self._max_it_pressure = max_it_pressure\n        self._max_it_interference = max_it_interference\n        self._rtol_pressure = rtol_pressure\n        self._rtol_interference = rtol_interference\n        self._nd_max_pressure = None\n\n        self.reynolds = reynolds_solver\n\n        if relaxation_factor <= 0 or relaxation_factor > 1:\n            raise ValueError("Relaxation factor must be greater than 0 and less than or equal to 1")\n        self._relaxation_factor = relaxation_factor\n\n        self.time_step = time_period / number_of_steps\n        self.number_of_steps = number_of_steps\n\n        self.update = set()\n\n        if not isinstance(off_set_x, Number) or not isinstance(off_set_y, Number):\n            if no_time:\n                raise ValueError("Can not have no time dependence and sliding contact")\n            off_set_x = [off_set_x] * 2 if isinstance(off_set_x, Number) else off_set_x\n            off_set_y = [off_set_y] * 2 if isinstance(off_set_y, Number) else off_set_y\n            off_set_x_func = make_interpolation_func(off_set_x, movement_interpolation_mode, \'relative_off_set_x\')\n            off_set_y_func = make_interpolation_func(off_set_y, movement_interpolation_mode, \'relative_off_set_y\')\n            self._off_set_upd = lambda time: np.array([off_set_x_func(time), off_set_y_func(time)])\n            self.update.add(\'off_set\')\n            self.off_set = None\n        else:\n            self.off_set = np.array([off_set_x, off_set_y])\n\n        if normal_load is not None and interference is not None:\n            raise ValueError("Both normal_load and interference are set, only one of these can be set")\n        if normal_load is None and interference is None:\n            if relative_loading:\n                interference = 0\n            else:\n                raise ValueError("Cannot have no set load or interference and not relative loading, set either the"\n                                 "normal load, normal interference or change relative_loading to True")\n\n        if isinstance(rolling_speed, Number):\n            self.rolling_speed = rolling_speed\n        else:\n            self.rolling_speed = None\n            self._rolling_speed_upd = make_interpolation_func(rolling_speed, movement_interpolation_mode,\n                                                              \'rolling_speed\')\n            self.update.add(\'rolling_speed\')\n\n        if normal_load is not None:\n            if isinstance(normal_load, Number):\n                self.normal_load = normal_load\n            else:\n                self.normal_load = None\n                self._normal_load_upd = make_interpolation_func(normal_load, movement_interpolation_mode,\n                                                                \'normal_load\')\n                self.update.add(\'normal_load\')\n            self.load_controlled = True\n        else:\n            self.normal_load = None\n\n        if interference is not None:\n            if isinstance(interference, Number):\n                self.interference = interference\n            else:\n                self.interference = None\n                self._interference_upd = make_interpolation_func(interference, movement_interpolation_mode,\n                                                                 \'interference\')\n                self.update.add(\'interference\')\n            self.load_controlled = False\n\n        if not self.update and no_update_warning:\n            warnings.warn("Nothing set to update")\n\n        self._provides = None\n\n        base_provides = {\'just_touching_gap\', \'surface_1_points\', \'surface_2_points\', \'off_set\', \'time_step\', \'time\',\n                         \'interference\', \'total_normal_load\', \'pressure\', \'nd_pressure\', \'loads\',\n                         \'surface_1_displacement\', \'surface_2_displacement\', \'total_displacement\', \'converged\',\n                         \'gap\', \'nd_gap\', \'rolling_speed\'}\n\n        provides = base_provides.union(reynolds_solver.provides).union(reynolds_solver.requires)\n\n        super().__init__(step_name, time_period, provides)\n\n    @property\n    def provides(self):\n        results_set = self._provides\n        if self.model is None:\n            return results_set\n        if self.model.lubricant_model is None:\n            return results_set\n        return results_set.union(set(self.model.lubricant_model.sub_models.keys()))\n\n    @provides.setter\n    def provides(self, value):\n        if self._provides is None:\n            self._provides = value\n        else:\n            raise ValueError("The provides property can only be set during instantiation")\n\n    @property\n    def reynolds(self):\n        return self._reynolds\n\n    @reynolds.setter\n    def reynolds(self, value):\n        if isinstance(value, _NonDimensionalReynoldSolverABC):\n            self._reynolds = value\n        else:\n            raise ValueError("Cannot set a non reynolds solver object as the reynolds solver, to use custom solvers"\n                             f"first subclass _NonDimensionalReynoldSolverABC from slippy.core, received "\n                             f"type was {type(value)}")\n\n    @reynolds.deleter\n    def reynolds(self):\n        self._reynolds = None\n\n    def data_check(self, current_state):\n        if self.reynolds is None:\n            _data_check_error_or_warn(f"Reynolds solver not set for step {self.name}")\n        if self.model.lubricant_model is None:\n            _data_check_error_or_warn(f"Step {self.name} requires a lubricant to be defined in the contact model")\n        if (self.reynolds.requires - set(self.model.lubricant_model.sub_models)) - {\'nd_gap\', \'nd_pressure\'}:\n            _data_check_error_or_warn(f"Reynolds solve in step {self.name} has requirements which are not provided by"\n                                      f" the lubricant sub models:\\n"\n                                      f"Requires: {self.reynolds.requires}\\n"\n                                      f"Sub models provide: {set(self.model.lubricant_model.sub_models)}")\n\n    def update_movement(self, relative_time, original):\n        for name in self.update:\n            if self._relative_loading:\n                self.__setattr__(name, original[name] + self.__getattribute__(f\'_{name}_upd\')(relative_time))\n            else:\n                self.__setattr__(name, self.__getattribute__(f\'_{name}_upd\')(relative_time))\n\n    def solve(self, previous_state: dict, output_file):\n        cuda = slippy.CUDA\n        slippy.CUDA = False\n        start_time = previous_state[\'time\']\n        gs = self.model.surface_1.grid_spacing\n\n        im_mats = (isinstance(self.model.surface_1.material, _IMMaterial) and\n                   isinstance(self.model.surface_2.material, _IMMaterial))\n        surf_1_material = self.model.surface_1.material\n        surf_2_material = self.model.surface_2.material\n\n        for s in self.sub_models:\n            s.no_time = self._no_time\n\n        relative_time = np.linspace(0, 1, self.number_of_steps+1)[1:]\n        just_touching_gap = None\n\n        original = dict()\n\n        if self._relative_loading:\n            original[\'normal_load\'] = previous_state[\'total_normal_load\'] if \'total_normal_load\' in previous_state \\\n                else 0\n            original[\'interference\'] = previous_state[\'interference\'] if \'interference\' in previous_state else 0\n            original[\'off_set\'] = np.array(previous_state[\'off_set\']) if \'off_set\' in previous_state else \\\n                np.array([0, 0])\n\n        previous_gap_shape = None  # shape of just touching gap array\n\n        for i in range(self.number_of_steps):\n            self.update_movement(relative_time[i], original)\n            self.reynolds.rolling_speed = self.rolling_speed\n            # find overlapping nodes\n            if \'off_set\' in self.update or just_touching_gap is None or not self._no_time:\n                just_touching_gap, surface_1_points, surface_2_points \\\n                    = get_gap_from_model(self.model, interference=0, off_set=self.off_set,\n                                         mode=self.profile_interpolation_mode, periodic=self._periodic_profile)\n\n            time_step_current_state = dict(just_touching_gap=just_touching_gap, surface_1_points=surface_1_points,\n                                           surface_2_points=surface_2_points, off_set=self.off_set,\n                                           time_step=self.time_step, time=start_time+(i+1)*self.time_step)\n\n            # make a new loads function if we need it\n            if (previous_gap_shape is None or previous_gap_shape != just_touching_gap.shape) and im_mats:\n                span = tuple([s*(2-pa) for s, pa in zip(just_touching_gap.shape, self._periodic_axes)])\n                max_pressure = self.reynolds.dimensionalise_pressure(min([surf_1_material.max_load,\n                                                                          surf_2_material.max_load]), True)\n                self._nd_max_pressure = max_pressure\n                im1 = surf_1_material.influence_matrix(components=[\'zz\'], grid_spacing=[gs] * 2, span=span)[\'zz\']\n                im2 = surf_2_material.influence_matrix(components=[\'zz\'], grid_spacing=[gs] * 2, span=span)[\'zz\']\n                total_im = im1 + im2\n                loads_func = plan_convolve(just_touching_gap, total_im, circular=self._periodic_axes)\n                previous_gap_shape = just_touching_gap.shape\n\n            elif not im_mats:\n                def loads_func(loads):\n                    return solve_normal_loading(loads_z=loads, model=self.model,\n                                                deflections=\'z\', current_state=time_step_current_state)[0][\'z\']\n            # sort out initial guess\n            if i >= 0:\n                initial_guess = \'previous\'\n            else:\n                initial_guess = self.initial_guess\n\n            if initial_guess is None:\n                initial_guess = [self.reynolds.dimensionalise_gap(0.01),\n                                 self.reynolds.dimensionalise_pressure(0.05)]\n            if isinstance(initial_guess, str) and initial_guess.lower() == \'previous\':\n                pressure = np.zeros_like(just_touching_gap) if \'pressure\' not in previous_state else \\\n                    previous_state[\'pressure\']\n                interference = 0.0 if \'interference\' not in previous_state else previous_state[\'interference\']\n            elif isinstance(initial_guess, Sequence):\n                interference = initial_guess[0]\n                if isinstance(initial_guess[1], Number):\n                    pressure = initial_guess[1] * np.ones_like(just_touching_gap)\n                else:\n                    try:\n                        pressure = np.asarray(initial_guess[1], dtype=np.float)\n                        assert (pressure.shape == just_touching_gap.shape)\n                    except ValueError:\n                        raise ValueError(\'Initial guess for pressure could not be converted to a numeric array\')\n                    except AssertionError:\n                        # noinspection PyUnboundLocalVariable\n                        raise ValueError("Initial guess for pressure produced an array of the wrong size:"\n                                         f"expected {just_touching_gap.shape}, got: {pressure.shape}")\n            elif hasattr(initial_guess, \'__call__\'):\n                interference, pressure = initial_guess(self.model, just_touching_gap)\n            else:\n                raise ValueError(\'Unsupported type for initial guess\')\n\n            results_last_it = {\'nd_pressure\': self.reynolds.dimensionalise_pressure(pressure, True),\n                               \'just_touching_gap\': just_touching_gap,\n                               \'interference\': interference,\n                               \'pressure\': pressure}\n\n            # we have the interference, and the pressure initial guesses, find the initial displacement before solving\n\n            if not (results_last_it[\'nd_pressure\'] == 0).all():\n                # noinspection PyUnboundLocalVariable\n                results_last_it[\'total_displacement_z\'] = loads_func(previous_state[\'pressure\'])\n\n            else:\n                results_last_it[\'total_displacement_z\'] = np.zeros_like(just_touching_gap)\n            results_last_it = self.model.lubricant_model.solve_sub_models(results_last_it)\n            # main loops\n            it_num = 0\n            # Find the gap and non denationalise it\n            gap = just_touching_gap + results_last_it[\'total_displacement_z\'] - results_last_it[\'interference\']\n            results_last_it[\'nd_interference\'] = self.reynolds.dimensionalise_gap(results_last_it[\'interference\'], True)\n            results_last_it[\'gap\'] = gap\n\n            while True:\n                nd_gap = self.reynolds.dimensionalise_gap(results_last_it[\'gap\'], True)\n                results_last_it[\'nd_gap\'] = nd_gap\n                # if flag:\n                #     return locals()\n                # else:\n                #     flag = True\n                # solve reynolds equation\n                results_this_it = self.reynolds.solve(results_last_it, self._nd_max_pressure)\n\n                # add just touching gap, needed for sub models\n                results_this_it[\'just_touching_gap\'] = just_touching_gap\n\n                # check for pressure convergence\n                change_in_pressures = results_this_it[\'nd_pressure\'] - results_last_it[\'nd_pressure\']\n                total_nd_pressure = np.sum(results_last_it[\'nd_pressure\'])  # use previous state here ... more stable\n                if total_nd_pressure > 0:\n                    pressure_relative_error = np.sum(np.abs(change_in_pressures)) / total_nd_pressure\n                else:\n                    pressure_relative_error = 1\n                pressure_converged = pressure_relative_error < self._rtol_pressure\n\n                # apply the relaxation factor to the pressure result\n                if self._nd_max_pressure is not None:\n                    results_this_it[\'nd_pressure\'] = np.clip(results_last_it[\'nd_pressure\'] +\n                                                             self._relaxation_factor * change_in_pressures, None,\n                                                             self._nd_max_pressure)\n                else:\n                    results_this_it[\'nd_pressure\'] = (results_last_it[\'nd_pressure\'] +\n                                                      self._relaxation_factor * change_in_pressures)\n\n                # solve contact geometry\n                results_this_it[\'pressure\'] = self.reynolds.dimensionalise_pressure(results_this_it[\'nd_pressure\'])\n                results_this_it[\'total_displacement_z\'] = loads_func(results_this_it[\'pressure\'])\n\n                # find gap\n                gap = just_touching_gap + results_this_it[\'total_displacement_z\'] - results_last_it[\'interference\']\n                results_this_it[\'gap\'] = gap\n\n                # solve lubricant sub models\n                results_this_it = self.model.lubricant_model.solve_sub_models(results_this_it)\n\n                # check for load convergence\n                total_load = np.sum(results_this_it[\'pressure\']) * gs ** 2\n\n                if self.load_controlled:\n                    load_relative_error = (total_load / self.normal_load) - 1\n                    load_converged = abs(load_relative_error) < self._rtol_pressure\n                else:\n                    load_converged = True\n                    load_relative_error = 0.0\n\n                results_this_it[\'nd_gap\'] = self.reynolds.dimensionalise_gap(results_this_it[\'gap\'], True)\n                results_this_it[\'interference\'] = results_last_it[\'interference\']\n\n                # escape the loop if it converged\n                if pressure_converged and load_converged:\n                    converged = True\n                    print(f"Step {self.name} converged successfully after {it_num} iterations.")\n                    print(f"Converged load is {total_load}, last change in pressure was {pressure_relative_error}\\n")\n                    break\n\n                # escape the loop it if failed\n                if it_num > self._max_it_pressure:  # this logic has changed used to just check the error\n                    converged = False\n                    print(f"Step {self.name} failed to converge after {it_num} iterations.\\n")\n                    print("Consider increasing the maximum number of iterations or reducing the relaxation factor")\n                    print(f"Converged load is {total_load}, last change in pressure was {pressure_relative_error}")\n                    break\n\n                # adjust height for load balance\n\n                if self._adjust_height_every_step and self.load_controlled:\n                    # adjust height based on load balance\n                    new_nd_interference = self.update_interference(it_num, pressure_relative_error,\n                                                                   load_relative_error,\n                                                                   results_last_it[\'nd_interference\'],\n                                                                   np.mean(results_this_it[\'nd_gap\']),\n                                                                   np.min(results_this_it[\'nd_gap\']))\n                    interference_updated = True\n\n                elif pressure_converged:\n                    # adjust height based on load balance\n                    new_nd_interference = self.update_interference(it_num, pressure_relative_error,\n                                                                   load_relative_error,\n                                                                   results_last_it[\'nd_interference\'],\n                                                                   np.mean(results_this_it[\'nd_gap\']),\n                                                                   np.min(results_this_it[\'nd_gap\']))\n                    interference_updated = True\n                else:\n                    new_nd_interference = 0\n                    interference_updated = False\n\n                if interference_updated:\n                    results_this_it[\'nd_interference\'] = new_nd_interference\n                    results_this_it[\'interference\'] = self.reynolds.dimensionalise_gap(new_nd_interference)\n                    gap = (just_touching_gap + results_this_it[\'total_displacement_z\'] - results_this_it[\'interference\'])\n                    results_this_it[\'gap\'] = gap\n                    # print summary of iteration to log file\n                    old_int = results_last_it[\'nd_interference\']\n                    print(f\'{it_num}\\ter_load: {load_relative_error:.4g}\\t\'\n                          f\'er_press: {pressure_relative_error:.4g}\\t\'\n                          f\'old_int: {old_int:.6g}\\t\'\n                          f\'new_int: {new_nd_interference:.6g}\')\n                else:\n                    results_this_it[\'nd_interference\'] = results_last_it[\'nd_interference\']\n                    results_this_it[\'interference\'] = results_last_it[\'interference\']\n\n                it_num += 1\n                results_last_it = results_this_it\n\n            # clean up after it has converged\n            current_state = {**time_step_current_state, **results_this_it}\n            pressure = current_state[\'pressure\']\n            if im_mats:\n                current_state[\'surface_1_displacement_z\'] = plan_convolve(pressure, im1,\n                                                                          circular=self._periodic_axes)(pressure)\n                current_state[\'surface_2_displacement_z\'] = plan_convolve(pressure, im2,\n                                                                          circular=self._periodic_axes)(pressure)\n                current_state[\'total_displacement_z\'] = current_state[\'total_displacement_z\']\n\n            else:\n                all_disp = solve_normal_loading(pressure, self.model, current_state, \'z\')\n                current_state[\'total_displacement_z\'] = all_disp[0]\n                current_state[\'surface_1_displacement_z\'] = all_disp[1]\n                current_state[\'surface_2_displacement_z\'] = all_disp[2]\n\n            # del current_state[\'total_displacement_z\']\n            current_state[\'total_normal_load\'] = total_load\n            current_state[\'loads_z\'] = current_state[\'pressure\']\n            current_state[\'converged\'] = converged\n            current_state[\'rolling_speed\'] = self.rolling_speed\n            current_state = self.solve_sub_models(current_state)\n            self.save_outputs(current_state, output_file)\n\n            previous_state = current_state\n\n        slippy.CUDA = cuda\n\n        return current_state\n\n    def __repr__(self):\n        return "Lubrication step"\n\n    def update_interference(self, it_num, pressure_error_rel, load_error_rel, current_interference, mean_gap, min_gap):\n        """This method updates the interference between the 2 surfaces during solution\n\n        Parameters\n        ----------\n        it_num: int\n            The current iteration number of the solution\n        pressure_error_rel\n            The current relative pressure error on the solution\n        load_error_rel: float\n            The current relative load error\n        current_interference: float\n            The current interference between the two bodies (the maximum overlap between the undeformed profiles)\n        mean_gap\n            The average nd_gap between the surfaces\n        min_gap\n            The minimum nd_gap between the surfaces\n\n        Returns\n        -------\n        new_interference: float\n            The non dimensional interference between the surfaces\n\n        Notes\n        -----\n        This method is quite basic at the moment and can definitely be improved, if executed on every loop, the height\n        is just updated by a fixed proportion of the minimum nd_gap size\n\n        If updated only when the solver converges, the Regula-Falsi method is used\n        """\n        if self._adjust_height_every_step:\n            new_interference = current_interference - 0.1 * load_error_rel\n            return new_interference\n\n        # else:  # height only adjusted when the load has converged, in this case use the Regula-Falsi method\n        self._interferences.append(current_interference)\n        self._load_errors.append(load_error_rel)\n\n        if len(self._interferences) == 1:  # if this is the first guess give a value that will probably bound it\n            new_interference = current_interference + abs(mean_gap) * -np.sign(load_error_rel)\n            return new_interference\n\n        if len(self._interferences) > 2 and abs(sum(np.sign(self._load_errors))) == 1:\n            # if this is true we must have bound a root\n\n            if self._load_errors[0] * self._load_errors[2] < 0:\n                del (self._interferences[1])\n                del (self._load_errors[1])\n            else:\n                del (self._interferences[0])\n                del (self._load_errors[0])\n\n        else:  # we have not bound a root, continue with the secant method but del the first item so we progress\n            del (self._interferences[0])\n            del (self._load_errors[0])\n\n        new_interference = (self._interferences[0] - self._load_errors[0] * (self._interferences[1] -\n                                                                             self._interferences[0]) /\n                            (self._load_errors[1] - self._load_errors[0]))\n\n        print(f\'Adjusting interference, new interference is {new_interference}\')\n\n        return new_interference\n\n\ndef _data_check_error_or_warn(msg: str):\n    if slippy.ERROR_IN_DATA_CHECK:\n        raise ValueError(msg)\n    else:\n        warnings.warn(msg)\n', 'is_package': False},
    'slippy.contact.models': {'source': '"""\nmodel object, just a container for step object that do the real work\n"""\nimport os\nimport typing\nimport slippy\nimport warnings\nfrom collections import OrderedDict\nfrom contextlib import redirect_stdout, ExitStack\nfrom datetime import datetime\nfrom slippy.core.outputs import OutputSaver, OutputRequest\n\nfrom slippy.core import _SurfaceABC, _LubricantModelABC, _ContactModelABC, _AdhesionModelABC\nfrom slippy.contact.steps import _ModelStep, InitialStep\n\n__all__ = [\'ContactModel\']\n\n\nclass ContactModel(_ContactModelABC):\n    """ A container for multi step contact mechanics and lubrication problems\n\n    Parameters\n    ----------\n    name: str\n        The name of the contact model, used for output and log files by default\n    surface_1, surface_2: _SurfaceABC\n        A surface object with the height profile and the material for the surface set. The first surface will be the\n        master surface, when grid points are not aligned surface 2 will be interpolated on the grid points for\n        surface 1.\n    lubricant: _LubricantModelABC, optional (None)\n        A lubricant model\n    adhesion: _AdhesionModelABC, optional (None)\n        An adhesion model\n    output_dir: str, optional (None)\n        Path to an output directory can be relative or absolute, slippy will attempt to make directory if it does not\n        exist, defaults to slippy.OUTPUT_DIR, which defaults to the current working directory.\n\n    Attributes\n    ----------\n    steps: OrderedDict\n        The model steps in the order they will be solved in, each value will be a ModelStep object.\n    surface_1, surface_2: _SurfaceABC\n        Surface objects of the two model surfaces\n    lubricant_model: _LubricantModelABC\n        A lubricant model\n\n    Methods\n    -------\n    add_step\n        Adds a step object to the model\n    add_output\n        Adds an output request to the model or selected steps\n    data_check\n        Performs analysis checks for each of the steps and the model as a whole, prints the results to the log file\n    solve\n        Solves all of the model steps in sequence, writing history and field outputs to the output file. Writes progress\n        to the log file\n\n    """\n\n    """Flag set to true if one of the surfaces is rigid"""\n    _is_rigid: bool = False\n    steps: OrderedDict\n    _current_state_debug: dict = None\n    _all_step_outputs = []\n\n    def __init__(self, name: str, surface_1: _SurfaceABC, surface_2: _SurfaceABC = None,\n                 lubricant: _LubricantModelABC = None, adhesion: _AdhesionModelABC = None, output_dir: str = None):\n        self.surface_1 = surface_1\n        self.surface_2 = surface_2\n        self.name = name\n        self.lubricant_model = lubricant\n        self.adhesion = adhesion\n        if adhesion is not None and lubricant is not None:\n            warnings.warn("No steps can handle both adhesion and lubrication at this time")\n        self.steps = OrderedDict({\'Initial\': InitialStep()})\n        self.current_step = None\n        self.current_step_start_time = None\n        if output_dir is not None:\n            if not os.path.isdir(output_dir):\n                try:\n                    os.mkdir(output_dir)\n                except OSError:\n                    raise ValueError("Output directory not found and creation of the output "\n                                     "directory: %s failed" % output_dir)\n            slippy.OUTPUT_DIR = output_dir\n\n    @property\n    def log_file_name(self):\n        return os.path.join(slippy.OUTPUT_DIR, self.name + \'.log\')\n\n    def add_step(self, step_instance: _ModelStep = None, position: typing.Union[int, str] = None):\n        """ Adds a solution step to the current model\n\n        Parameters\n        ----------\n        step_instance: _ModelStep\n            An instance of a model step\n        position : {int, None}, optional (None)\n            The position of the step in the existing order, if None will add step to the end\n\n        See Also\n        --------\n        step\n\n        Notes\n        -----\n        Steps should only be added to the model using this method\n        #TODO detailed description of inputs\n\n        Examples\n        --------\n        >>> #TODO\n        """\n        new_step = step_instance\n\n        step_name = step_instance.name\n        step_instance.model = self\n\n        if position is None:\n            self.steps[step_name] = new_step\n        else:\n            keys = list(self.steps.keys())\n            values = list(self.steps.values())\n            if type(position) is str:\n                position = keys.index(position)\n            keys.insert(position, step_name)\n            values.insert(position, new_step)\n            self.steps = OrderedDict()\n            for k, v in zip(keys, values):\n                self.steps[k] = v\n        for sub_model in step_instance.sub_models:\n            sub_model.model = self\n\n    def add_output(self, output_request: OutputRequest, active_steps: typing.Union[str, typing.Sequence[str]] = \'all\'):\n        """\n        Add an output to one or more steps in the model\n\n        Parameters\n        ----------\n        output_request: OutputRequest\n            A slippy.contact.OutputRequest with describing the parameters to save and the time points they will be saved\n            for\n        active_steps: str or list of str, optional (\'all\')\n            The step or a list of steps this output is active for, defaults to all the steps currently in the model\n\n        Examples\n        --------\n\n        """\n        if active_steps == \'all\':\n            active_steps = set(self.steps)\n            active_steps.remove(\'Initial\')\n        if isinstance(active_steps, str):\n            active_steps = [active_steps, ]\n        for this_step in active_steps:\n            self.steps[this_step].outputs.append(output_request)\n\n    def data_check(self):\n        print("Data check started at:")\n        print(datetime.now().strftime(\'%H:%M:%S %d-%m-%Y\'))\n        print(f"Checking model {self.name}:")\n        self._model_check()\n\n        current_state = None\n\n        for this_step in self.steps:\n            current_state = self.steps[this_step]._data_check(current_state)\n\n    def _model_check(self):\n        """\n        Checks the model for possible errors (the model steps are checked independently)\n        """\n        def warn_or_error(msg):\n            if slippy.ERROR_IN_DATA_CHECK:\n                raise ValueError(msg)\n            else:\n                warnings.warn(msg)\n\n        if self.surface_1 is None:\n            warn_or_error("Master surface is not set")\n        if not self.surface_1.is_discrete:\n            warn_or_error("Master is not discrete, only secondary surface may be analytic")\n        if self.surface_1.material is None:\n            warn_or_error("Material for master surface is not set")\n        if self.surface_2 is None:\n            warn_or_error("Secondary surface is not set")\n        if self.surface_2.material is None:\n            warn_or_error("Material for second surface is not set, for a rigid surface use the Rigid material")\n\n    def solve(self, verbose: bool = False, skip_data_check: bool = False):\n        """\n        Solve all steps and sub-models in the model as well as writing all outputs\n\n        Parameters\n        ----------\n        verbose: bool optional (False)\n            If True, logs are written to the console instead of the log file\n        skip_data_check: bool, optional (False)\n            If True the data check will be skipped, this is not recommended but may be necessary for some steps\n\n        Returns\n        -------\n        current_state: dict\n            A dictionary containing the final state of the model\n\n        Notes\n        -----\n        Most steps produce detailed logging information that can be found in the log file.\n\n        """\n        if os.path.exists(self.log_file_name):\n            os.remove(self.log_file_name)\n\n        current_state = {\'time\': 0.0}\n\n        with ExitStack() as stack:\n            output_writer = stack.enter_context(OutputSaver(self.name))\n            if not verbose:\n                log_file = stack.enter_context(open(self.log_file_name, \'x\'))\n                stack.enter_context(redirect_stdout(log_file))\n\n            if not skip_data_check:\n                self.data_check()\n\n            print(f"Solving model {self.name}, CUDA = {slippy.CUDA}")\n\n            for this_step in self.steps:\n                print(f"Solving step {this_step}")\n                self.current_step = self.steps[this_step]\n                self.current_step_start_time = current_state[\'time\']\n                for output in self.steps[this_step].outputs:\n                    output.new_step(current_state[\'time\'])\n                current_state = self.steps[this_step].solve(current_state, output_writer)\n\n            now = datetime.now().strftime(\'%H:%M:%S %d-%m-%Y\')\n            print(f"Analysis completed successfully at: {now}")\n\n        return current_state\n\n    def __repr__(self):\n        return (f\'ContactModel(surface1 = {repr(self.surface_1)}, \'\n                f\'surface2 = {repr(self.surface_2)}, \'\n                f\'steps = {repr(self.steps)})\')\n\n    def __str__(self):\n        return (f\'ContactModel with surfaces: {str(self.surface_1)}, {str(self.surface_2)}, \'\n                f\'and {len(self.steps)} steps: {", ".join([str(st) for st in self.steps])}\')\n', 'is_package': False},
    'slippy.contact.quasi_static_step': {'source': 'import numpy as np\nfrom numbers import Number\nimport typing\nimport warnings\n\nfrom .steps import _ModelStep\nfrom ._model_utils import get_gap_from_model\nfrom ._step_utils import HeightOptimisationFunction, make_interpolation_func\n\n__all__ = [\'QuasiStaticStep\']\n\n\nclass QuasiStaticStep(_ModelStep):\n    """\n    A model step for quasi static relative movement\n\n    To be used for loading, unloading and sliding as well as quasi static impacts, can be used for rolling-sliding\n    with appropriate sub models for tangential behaviour.\n\n    Parameters\n    ----------\n\n    step_name: str\n        An identifying name for the step used for errors and outputs\n    number_of_steps: int\n        The number of sub steps the problem will be split into, together with the time_period this controls the duration\n        of the time steps used\n    no_time: bool, optional (False)\n        Set to true if there is no time dependence and the time steps can be solved in any order (no permanent changes\n        between steps such as plastic deformation or heat generation), if True the model will be solved more efficiently\n    time_period: float, optional (1.0)\n        The total time period of this model step, used for solving sub-models and writing outputs\n    off_set_x, off_set_y: float or Sequence of float, optional (0.0)\n        The off set between the surfaces in the x and y directions, this can be a relative off set or an absolute off\n        set, controlled by the relative_loading parameter:\n\n        * A constant (float) value, indicating a constant offset between the surfaces (no relative movement of profiles)\n        * A two element sequence of floats, indicating the the start and finish offsets, if this is used, the\n          movement_interpolation_mode will be used to generate intermediate values\n        * A 2 by n array of n absolute position values and n time values normalised to a 0-1 scale. array[0] should be\n          position values and array[1] should be time values, time values must be between 0 and 1. The\n          movement_interpolation_mode will be used to generate intermediate values\n    interference, normal_load, mean_gap: float or Sequence of float, optional (None)\n        The interference, normal load and mean gap between the surfaces, only one of these can be set, setting neither\n        keeps the interference as it is at the start of this model step. As above for the off sets, either of these\n        parameters can be:\n\n        * A constant (float) value, indicating a constant load/ interference between the surfaces.\n        * A two element sequence of floats, indicating the the start and finish load. interference, if this is used, the\n          movement_interpolation_mode will be used to generate intermediate values\n        * A 2 by n array of n absolute position values and n time values normalised to a 0-1 scale. array[0] should be\n          position values and array[1] should be time values, time values must be between 0 and 1. The\n          movement_interpolation_mode will be used to generate intermediate values\n    relative_loading: bool, optional (False)\n        If True the load or displacement and off set will be applied relative to the value at the start of the step,\n        otherwise the absolute value will be used. eg, if the previous step ended with a load of 10N and this step ramps\n        from 0 to 10N setting relative_loading to True will ramp the total load form 10 to 20N over this step.\n    adhesion: bool, optional (True)\n        If True the adhesion model set for the contact model will be used, If set to false this step will ignore the\n        adhesion model (typically used for loading steps)\n    unloading: bool, optional (False)\n        If True the contact nodes will be constrained to be a sub set of those found in the previous time step.\n    fast_ld: bool, optional (False)\n        If True the load and displacements can be swapped to give a faster simulation, eg: if 100 equally spaced load\n        steps are specified by a start and finish load, the displacement at the maximum load will be found and instead\n        100 equally spaced displacement controlled steps will solved between just touching and the maximum deflection.\n        This swapping makes the computation much faster as it removes an optimisation loop.\n    impact_properties: list, optional (None)\n        This is currently not supported, providing a value will cause an error\n    movement_interpolation_mode: str or int, optional (\'linear\')\n        Any valid input to scipy.interpolate.interp1d as the \'kind\' parameter, using \'nearest\', \'previous\' or \'next\'\n        will cause a warning. This parameter controls how the offset and loading is interpolated over the step\n    profile_interpolation_mode: {\'nearest\', \'linear\'}, optional (\'nearest\')\n        Used to generate the grid points for the second surface at the location of the grid points for the first\n        surface, nearest ensures compatibility with sub models which change the profile, if the grid spacings of the\n        surfaces match\n    periodic_geometry: bool, optional (False)\n        If True the surface profile will warp when applying the off set between the surfaces\n    periodic_axes: tuple, optional ((False, False))\n        For each True value the corresponding axis will be solved by circular convolution, meaning the result is\n        periodic in that direction\n    method: {\'auto\', \'pk\', \'double\', \'rey\'}, optional (\'auto\')\n        The method by which the normal contact is solved, only used for load controlled contact.\n        \'pk\' uses the Polonsky and Keer algorithm for elastic contact.\n        \'double\' uses a double iteration procedure, suitable for elastic contact with a maximum pressure.\n        \'auto\' automatically selects \'pk\' if there is no maximum pressure and \'double\' if there is.\n    max_it: int, optional (1000)\n        The maximum number of iterations used in the main loop\n    tolerance: float, optional (1e-8)\n        The relative tolerance used for convergnece of the main loop\n    max_it_outer: int, optional (100)\n        Only used for the double iteration method\n    tolerance_outer: float, optional (1e-4)\n        The norm of the residual used to declare convergence of the bccg iterations\n    tolerance: float, optional (1e-4)\n        The norm of the residual used to declare convergence of the bccg iterations\n    no_update_warning: bool, optional (True)\n        Change to False to suppress warning given when no movement or loading changes are specified\n    upper: float, optional (4.0)\n        For load controlled contact the upper bound for the interference between the bodies will be this factor\n        multiplied by the largest just touching gap. 4 is suitable for flat on flat contacts but for ball on flat\n        contacts a lower value will give faster converging solutions\n\n    Examples\n    --------\n    In the following example we model the contact between a rough cylinder and a flat plane.\n    Both surface are elastic. This code could be used to generate load displacement curves.\n\n    >>> import slippy.surface as s\n    >>> import slippy.contact as c\n    >>> # define contact geometry\n    >>> cylinder = s.RoundSurface((1 ,np.inf, 1), shape=(256, 256), grid_spacing=0.001)\n    >>> roughness = s.HurstFractalSurface(1, 0.2, 1000, shape=(256, 256), grid_spacing=0.001,\n    >>>                                   generate = True)\n    >>> combined = cylinder + roughness * 0.00001\n    >>> flat = s.FlatSurface(shape=(256, 256), grid_spacing=0.001, generate = True)\n    >>> # define material behaviour and assign to surfaces\n    >>> material = c.Elastic(\'steel\', properties = {\'E\':200e9, \'v\':0.3})\n    >>> combined.material = material\n    >>> flat.material = material\n    >>>\n    >>> # make a contact model\n    >>> my_model = c.ContactModel(\'qss_test\', combined, flat)\n    >>>\n    >>> # make a modelling step to describe the problem\n    >>> max_int = 0.002\n    >>> n_time_steps = 20\n    >>> my_step = c.QuasiStaticStep(\'loading\', n_time_steps, no_time=True,\n    >>>                             interference = [max_int*0.001, max_int],\n    >>>                             periodic_geometry=True, periodic_axes = (False, True))\n    >>> # add the steps to the model\n    >>> my_model.add_step(my_step)\n    >>> # add output requests\n    >>> output_request = c.OutputRequest(\'Output-1\',\n    >>>                                  [\'interference\', \'total_normal_load\',\n    >>>                                   \'loads_z\', \'total_displacement\',\n    >>>                                   \'converged\'])\n    >>> my_step.add_output(output_request)\n    >>> # solve the model\n    >>> final_result = my_model.solve()\n    """\n    _just_touching_gap = None\n    _adhesion_model = None\n    _initial_contact_nodes = None\n    _upper = None\n\n    def __init__(self, step_name: str, number_of_steps: int, no_time: bool = False,\n                 time_period: float = 1.0,\n                 off_set_x: typing.Union[float, typing.Sequence[float]] = 0.0,\n                 off_set_y: typing.Union[float, typing.Sequence[float]] = 0.0,\n                 interference: typing.Union[float, typing.Sequence[float]] = None,\n                 normal_load: typing.Union[float, typing.Sequence[float]] = None,\n                 mean_gap: typing.Union[float, typing.Sequence[float]] = None,\n                 relative_loading: bool = False,\n                 adhesion: bool = True,\n                 unloading: bool = False,\n                 fast_ld: bool = False,\n                 impact_properties: dict = None,\n                 movement_interpolation_mode: str = \'linear\',\n                 profile_interpolation_mode: str = \'nearest\',\n                 periodic_geometry: bool = False, periodic_axes: tuple = (False, False),\n                 method: str = \'auto\',\n                 max_it: int = 1000, tolerance=1e-8,\n                 max_it_outer: int = 100, tolerance_outer=1e-4,\n                 no_update_warning: bool = True,\n                 upper: float = 4.0):\n\n        # movement interpolation mode sort out movement interpolation mode make array of values\n        if impact_properties is not None:\n            raise NotImplementedError("Impacts are not yet implemented")\n        # work out the time step if needed:\n        self._no_time = no_time\n        self.total_time = time_period\n        if not no_time and fast_ld:\n            raise ValueError("Cannot have time dependence and fast_ld, either set no_time True or set fast_ld False")\n        self._fast_ld = fast_ld\n        self._relative_loading = relative_loading\n        self.profile_interpolation_mode = profile_interpolation_mode\n        self._periodic_profile = periodic_geometry\n        self._periodic_axes = periodic_axes\n        self._max_it_outer = max_it_outer\n        self._r_tol_outer = tolerance_outer\n        self._max_it = max_it\n        self._r_tol = tolerance\n        self.number_of_steps = int(round(number_of_steps))\n\n        if method not in {\'auto\', \'pk\', \'double\', \'rey\'}:\n            raise ValueError(f"Unrecognised method for step {step_name}: {method}")\n        sum_param = (normal_load is not None) + (interference is not None) + (mean_gap is not None)\n        if sum_param > 1 or sum_param == 0:\n            raise ValueError(f"Exactly one of normal_load, interference and mean_gap must be set, {sum_param} were set")\n        if mean_gap is not None:\n            if method not in {\'auto\', \'rey\'}:\n                raise ValueError("pk and double methods don\'t support mean gap")\n            else:\n                method = \'rey\'\n        if interference is not None and method == \'rey\':\n            raise ValueError("Rey method doesn\'t support interference")\n\n        self._method = method\n        self._height_optimisation_func = None\n        self._adhesion = adhesion\n        self._unloading = unloading\n        self._upper_factor = upper\n\n        self.time_step = time_period / number_of_steps\n\n        # check that something is actually changing\n        self.update = set()\n\n        if not isinstance(off_set_x, Number) or not isinstance(off_set_y, Number):\n            if no_time:\n                raise ValueError("Can not have no time dependence and sliding contact")\n            off_set_x = [off_set_x] * 2 if isinstance(off_set_x, Number) else off_set_x\n            off_set_y = [off_set_y] * 2 if isinstance(off_set_y, Number) else off_set_y\n            off_set_x_func = make_interpolation_func(off_set_x, movement_interpolation_mode, \'relative_off_set_x\')\n            off_set_y_func = make_interpolation_func(off_set_y, movement_interpolation_mode, \'relative_off_set_y\')\n            self._off_set_upd = lambda time: np.array([off_set_y_func(time), off_set_x_func(time)])\n            self.update.add(\'off_set\')\n            self.off_set = None\n        else:\n            self.off_set = np.array([off_set_y, off_set_x])\n\n        if normal_load is not None and interference is not None:\n            raise ValueError("Both normal_load and interference are set, only one of these can be set")\n        if normal_load is None and interference is None:\n            if relative_loading:\n                interference = 0\n            else:\n                raise ValueError("Cannot have no set load or interference and not relative loading, set either the"\n                                 "normal load, normal interference or change relative_loading to True")\n\n        self.load_controlled = False\n\n        if normal_load is not None:\n            if isinstance(normal_load, Number):\n                self.normal_load = normal_load\n            else:\n                self.normal_load = None\n                self._normal_load_upd = make_interpolation_func(normal_load, movement_interpolation_mode,\n                                                                \'normal_load\')\n                self.update.add(\'normal_load\')\n            self.load_controlled = True\n        else:\n            self.normal_load = None\n\n        if mean_gap is not None:\n            if isinstance(mean_gap, Number):\n                self.mean_gap = mean_gap\n            else:\n                self.mean_gap = None\n                self._mean_gap_upd = make_interpolation_func(mean_gap, movement_interpolation_mode,\n                                                             \'mean_gap\')\n                self.update.add(\'mean_gap\')\n        else:\n            self.mean_gap = None\n\n        if interference is not None:\n            if isinstance(interference, Number):\n                self.interference = interference\n            else:\n                self.interference = None\n                self._interference_upd = make_interpolation_func(interference, movement_interpolation_mode,\n                                                                 \'interference\')\n                self.update.add(\'interference\')\n        else:\n            self.interference = None\n\n        if not self.update and no_update_warning:\n            warnings.warn("Nothing set to update")\n\n        provides = {\'off_set\', \'loads_z\', \'surface_1_displacement_z\', \'surface_2_displacement_z\',\n                    \'total_displacement_z\', \'interference\', \'just_touching_gap\', \'surface_1_points\', \'contact_nodes\',\n                    \'surface_2_points\', \'time\', \'time_step\', \'new_step\', \'converged\', \'gap\', \'total_normal_load\'}\n        super().__init__(step_name, time_period, provides)\n\n    def solve(self, previous_state, output_file):\n        current_time = previous_state[\'time\']\n        if self._fast_ld:\n            # solve the normal contact problem\n            raise NotImplementedError("TODO")\n            # TODO\n            # change to disp controlled, set the displacement variable\n\n        for s in self.sub_models:\n            s.no_time = self._no_time\n\n        if self.load_controlled:\n            update_func = self._solve_load_controlled\n        else:  # displacement controlled\n            update_func = self._solve_displacement_controlled\n\n        relative_time = np.linspace(0, 1, self.number_of_steps + 1)[1:]\n        just_touching_gap = None\n        surface_1_points = None\n        surface_2_points = None\n\n        original = dict()\n\n        if self._relative_loading:\n            original[\'normal_load\'] = previous_state[\'total_normal_load\'] if \'total_normal_load\' in previous_state \\\n                else 0\n            original[\'interference\'] = previous_state[\'interference\'] if \'interference\' in previous_state else 0\n            original[\'off_set\'] = np.array(previous_state[\'off_set\']) if \'off_set\' in previous_state else \\\n                np.array([0, 0])\n\n        self._adhesion_model = self.model.adhesion if self._adhesion else None\n        max_pressure = min(self.model.surface_1.material.max_load, self.model.surface_2.material.max_load)\n\n        if self._method == \'auto\':\n            if not np.isinf(max_pressure):\n                if self._adhesion_model:\n                    raise ValueError("Adhesion and maximum load not allowed")\n                self._method = \'double\'\n            elif self._adhesion_model is not None:\n                self._method = \'rey\'\n            else:\n                self._method = \'pk\'\n\n        current_state = dict()\n\n        for i in range(self.number_of_steps):\n            self.update_movement(relative_time[i], original)\n            # find overlapping nodes\n            if \'off_set\' in self.update or just_touching_gap is None or not self._no_time:\n                just_touching_gap, surface_1_points, surface_2_points \\\n                    = get_gap_from_model(self.model, interference=0, off_set=self.off_set,\n                                         mode=self.profile_interpolation_mode, periodic=self._periodic_profile)\n                self._just_touching_gap = just_touching_gap\n                self._upper = None\n            current_state = dict(just_touching_gap=just_touching_gap, surface_1_points=surface_1_points,\n                                 surface_2_points=surface_2_points, off_set=self.off_set,\n                                 time_step=self.time_step)\n            if i == 0:\n                current_state[\'new_step\'] = True\n            else:\n                current_state[\'new_step\'] = False\n            # solve contact\n            if self._unloading and \'contact_nodes\' in previous_state:\n                initial_contact_nodes = previous_state[\'contact_nodes\']\n            else:\n                initial_contact_nodes = None\n\n            self._initial_contact_nodes = initial_contact_nodes\n            print(\'#####################################################\\nTime step:\', i,\n                  \'\\n#####################################################\')\n            print(\'Set load:\', self.normal_load)\n\n            results = update_func(current_state)\n            current_state.update(results)\n            current_time += self.time_step\n            current_state[\'time\'] = current_time\n            # solve sub models\n            self.solve_sub_models(current_state)\n            self.save_outputs(current_state, output_file)\n\n        return current_state\n\n    @property\n    def upper(self):\n        if self._upper is None:\n            self._upper = np.max(self._just_touching_gap) * self._upper_factor\n        return self._upper\n\n    def update_movement(self, relative_time, original):\n        for name in self.update:\n            if self._relative_loading:\n                self.__setattr__(name, original[name] + self.__getattribute__(f\'_{name}_upd\')(relative_time))\n            else:\n                self.__setattr__(name, self.__getattribute__(f\'_{name}_upd\')(relative_time))\n\n    def _solve_load_controlled(self, current_state) -> dict:\n        # if there is time dependence or we don\'t already have one, make a new height optimiser\n        if not self._no_time or self._height_optimisation_func is None:\n            opt_func = HeightOptimisationFunction(just_touching_gap=self._just_touching_gap,\n                                                  model=self.model,\n                                                  adhesion_model=self._adhesion_model,\n                                                  initial_contact_nodes=self._initial_contact_nodes,\n                                                  max_it=self._max_it,\n                                                  rtol=self._r_tol,\n                                                  material_options=dict(),\n                                                  max_set_load=self.normal_load,\n                                                  rtol_outer=self._r_tol_outer,\n                                                  max_it_outer=self._max_it_outer,\n                                                  periodic_axes=self._periodic_axes)\n            self._height_optimisation_func = opt_func\n        else:\n            opt_func = self._height_optimisation_func\n\n        if self._unloading and \'contact_nodes\' in current_state:\n            contact_nodes = current_state[\'contact_nodes\']\n        else:\n            contact_nodes = None\n            # contact_nodes = np.ones(self._just_touching_gap.shape, dtype=np.bool)\n\n        if self._method == \'pk\':\n            opt_func.contact_nodes = None\n            opt_func.p_and_k(self.normal_load)\n        elif self._method == \'rey\':\n            opt_func.contact_nodes = None\n            opt_func.rey(target_load=self.normal_load)\n        else:\n            opt_func.change_load(self.normal_load, contact_nodes)\n            # need to set bounds and pick a sensible starting point\n            upper = self.upper\n            print(f\'upper bound set at: {upper}\')\n            if self._no_time:\n                brackets = opt_func.get_bounds_from_cache(0, upper)\n            else:\n                brackets = (0, upper)\n            print(f\'Bounds adjusted using cache to: {brackets}\')\n            print(f\'Interference tolerance set to {self._r_tol_outer} Relative\')\n            opt_func.brent(0, upper)\n\n        # noinspection PyProtectedMember\n\n        results = opt_func.results\n        load_conv = (np.abs(results[\'total_normal_load\'] - self.normal_load) / self.normal_load) < 0.05\n        results[\'converged\'] = bool(load_conv) and not opt_func.last_call_failed\n        return results\n\n    def _solve_displacement_controlled(self, current_state):\n        # Note also includes gap control for rey\n        if not self._no_time or self._height_optimisation_func is None:\n            opt_func = HeightOptimisationFunction(just_touching_gap=self._just_touching_gap,\n                                                  model=self.model,\n                                                  adhesion_model=self._adhesion_model,\n                                                  initial_contact_nodes=self._initial_contact_nodes,\n                                                  max_it=self._max_it,\n                                                  rtol=self._r_tol,\n                                                  material_options=dict(),\n                                                  max_set_load=1,\n                                                  rtol_outer=self._r_tol_outer,\n                                                  max_it_outer=self._max_it_outer,\n                                                  periodic_axes=self._periodic_axes)\n            self._height_optimisation_func = opt_func\n        else:\n            opt_func = self._height_optimisation_func\n\n        if self._method == \'rey\':\n            opt_func.rey(target_mean_gap=self.mean_gap)\n            return opt_func.results\n\n        if self._unloading and \'contact_nodes\' in current_state:\n            contact_nodes = current_state[\'contact_nodes\']\n        else:\n            contact_nodes = None\n            # contact_nodes = np.ones(self._just_touching_gap.shape, dtype=np.bool)\n\n        opt_func.change_load(1, contact_nodes)\n        _ = opt_func(self.interference, current_state)\n        results = opt_func.results\n        results[\'interference\'] = self.interference\n        results[\'converged\'] = not opt_func.last_call_failed\n        return results\n\n    def __repr__(self):\n        return f\'{self.name}: QuasiStaticStep\'\n', 'is_package': False},
    'slippy.contact.static_step': {'source': 'r"""\n======================\nStatic Modelling steps\n======================\n\nSteps for modelling static or quasi static situations:\nshould include:\nspecified global interference\nspecified global loading\nspecified surface loading\nspecified surface displacement\nclosure plot generator/ adhesive pull of tester (the same but backwards)\n\nNo models should have to do wear or other time varying stuff.\n\nAll should return a current state dict\n"""\n\nimport numpy as np\n\nfrom ._model_utils import get_gap_from_model\nfrom ._step_utils import HeightOptimisationFunction\nfrom .steps import _ModelStep\n\n__all__ = [\'StaticStep\']\n\n\nclass StaticStep(_ModelStep):\n    """\n    Static loading between two bodies\n\n    Parameters\n    ----------\n    step_name: str\n        An identifying name for the step used for errors and outputs\n    time_period: float, optional (1.0)\n        The total time period of this model step, used for solving sub-models and writing outputs\n    off_set_x, off_set_y: float\n        The off set between the surfaces origins, in the same units as the grid spacings of the surfaces.\n    normal_load, interference, mean_gap: float\n        The total compressive load and the interference between the two surfaces (measured from the point of first\n        contact). Exactly one of these must be set. See notes for valid methods for each parameter.\n    relative_loading: bool, optional (False)\n        If True the load or displacement will be applied relative to the value at the start of the step,\n        otherwise the absolute value will be used. eg, if the previous step ended with a load of 10N and this step ramps\n        from 0 to 10N setting relative_loading to True will ramp the total load form 10 to 20N over this step.\n    adhesion: bool, optional (True)\n        If True the adhesion model set for the contact model will be used, If set to false this step will ignore the\n        adhesion model (typically used for loading steps)\n    unloading: bool, optional (False)\n        If True the contact nodes will be constrained to be a sub set of those found in the previous time step.\n    profile_interpolation_mode: {\'nearest\', \'linear\'}, optional (\'nearest\')\n        Used to generate the grid points for the second surface at the location of the grid points for the first\n        surface, nearest ensures compatibility with sub models which change the profile, if the grid spacings of the\n        surfaces match\n    periodic_geometry: bool, optional (False)\n        If True the surface profile will warp when applying the off set between the surfaces\n    periodic_axes: tuple, optional ((False, False))\n        For each True value the corresponding axis will be solved by circular convolution, meaning the result is\n        periodic in that direction\n    method: {\'auto\', \'pk\', \'double\', \'rey\'}, optional (\'auto\')\n        The method by which the normal contact is solved, only used for load controlled contact.\n        \'pk\' uses the Polonsky and Keer algorithm linear contact.\n        \'double\' uses a double iteration procedure, suitable for elastic contact with a maximum pressure.\n        \'rey\' uses the Rey algorithm for adhesive contact.\n        \'auto\' automatically selects \'pk\' if there is no maximum pressure and \'double\' if there is.\n    max_it: int, optional (1000)\n        The maximum number of iterations used in the main loop\n    tolerance: float, optional (1e-8)\n        The relative tolerance used for convergnece of the main loop\n    max_it_outer: int, optional (100)\n        Only used for the double iteration method\n    tolerance_outer: float, optional (1e-4)\n        The norm of the residual used to declare convergence of the bccg iterations\n\n    Notes\n    -----\n    Not all methods can be used for all set parameters and periodic combinations:\n    rey: Both axes must be periodic, mean_gap or normal_load can be set, adhesion allowed, linear materials\n    pk: Any combination of periodic axes, normal load or interference set (interference requires spartially\n        defined influence matrix), no adhesion, linear materials\n    double: Any combination of periodic axes, normal load or interference set (interference requires spartially\n        defined influence matrix), no adhesion, maximum load allowed for materials.\n\n    Setting the method to \'auto\' will choose a method automatically or raise an error if no method can be used. If\n    multiple methods can be used the pk solver is used.\n\n    Examples\n    --------\n    In this example we will recreate the hertz solution using a numerical solver.\n\n    >>> import slippy.surface as s\n    >>> import slippy.contact as c\n    >>> # make surface geometry\n    >>> flat_surface = s.FlatSurface(shift=(0,0))\n    >>> round_surface = s.RoundSurface((1,1,1), extent = (0.006, 0.006),\n    >>>                                shape = (255, 255), generate = True)\n    >>> # make and set materials\n    >>> steel = c.Elastic(\'Steel\', {\'E\': 200e9, \'v\':0.3})\n    >>> aluminum = c.Elastic(\'Aluminum\', {\'E\': 70e9, \'v\':0.33})\n    >>> flat_surface.material = aluminum\n    >>> round_surface.material = steel\n    >>> # make contact model\n    >>> my_model = c.ContactModel(\'model-1\', round_surface, flat_surface)\n    >>> # make and add step\n    >>> total_load = 100\n    >>> my_step = c.StaticStep(\'contact\', normal_load=total_load, rtol_interference=1e-2)\n    >>> my_model.add_step(my_step)\n    >>> # solve the model\n    >>> result = my_model.solve()\n    """\n\n    def __init__(self, step_name: str, time_period: float = 1.0,\n                 off_set_x: float = 0.0, off_set_y: float = 0.0,\n                 normal_load: float = None, interference: float = None,\n                 mean_gap: float = None,\n                 relative_loading: bool = False, adhesion: bool = True,\n                 unloading: bool = False, profile_interpolation_mode: str = \'nearest\',\n                 periodic_geometry: bool = False, periodic_axes: tuple = (False, False),\n                 method: str = \'auto\',\n                 max_it: int = 1000, tolerance=1e-8,\n                 max_it_outer: int = 100, tolerance_outer=1e-8):\n\n        self._off_set = (off_set_x, off_set_y)\n        self._relative_loading = bool(relative_loading)\n        self.profile_interpolation_mode = profile_interpolation_mode\n        self._periodic_profile = periodic_geometry\n        self._periodic_axes = periodic_axes\n        self._max_it = max_it\n        self._rtol = tolerance\n        self._max_it_outer = max_it_outer\n        self._rtol_outer = tolerance_outer\n        self._height_optimisation_func = None\n        self._adhesion = adhesion\n        self._unloading = unloading\n\n        if method not in {\'auto\', \'pk\', \'double\', \'rey\'}:\n            raise ValueError(f"Unrecognised method for step {step_name}: {method}")\n        self._opt_func = None\n        sum_param = (normal_load is not None) + (interference is not None) + (mean_gap is not None)\n        if sum_param > 1 or sum_param == 0:\n            raise ValueError(f"Exactly one of normal_load, interference and mean_gap must be set, {sum_param} were set")\n        if mean_gap is not None:\n            if method not in {\'auto\', \'rey\'}:\n                raise ValueError("pk and double methods don\'t support mean gap")\n            else:\n                method = \'rey\'\n        if interference is not None and method == \'rey\':\n            raise ValueError("Rey method doesn\'t support interference")\n\n        self._method = method\n        # noinspection PyTypeChecker\n        self.interference = interference\n        # noinspection PyTypeChecker\n        self.normal_load = normal_load\n        self.mean_gap = mean_gap\n\n        self.load_controlled = normal_load is not None\n\n        provides = {\'off_set\', \'loads_z\', \'surface_1_displacement_z\', \'surface_2_displacement_z\',\n                    \'total_displacement_z\',\n                    \'interference\', \'just_touching_gap\', \'surface_1_points\', \'contact_nodes\', \'total_normal_load\',\n                    \'surface_2_points\', \'time\', \'time_step\', \'new_step\', \'converged\', \'gap\'}\n\n        super().__init__(step_name, time_period, provides)\n\n    def solve(self, previous_state: dict, output_file) -> dict:\n        """\n        Solve this model step\n\n        Parameters\n        ----------\n        previous_state: dict\n            The previous state of the model\n        output_file: file buffer\n            The file in which the outputs will be written\n\n        Returns\n        -------\n        current_state: dict\n            The current state of the model\n\n        """\n        # just in case the displacement finder in a scipy optimise block should be a continuous function, no special\n        # treatment required\n        for s in self.sub_models:\n            s.no_time = False\n\n        if self._unloading and \'contact_nodes\' in previous_state:\n            initial_contact_nodes = previous_state[\'contact_nodes\']\n        else:\n            initial_contact_nodes = None\n\n        # noinspection PyTypeChecker\n        just_touching_gap, surface_1_points, surface_2_points = get_gap_from_model(self.model, interference=0,\n                                                                                   off_set=self._off_set,\n                                                                                   mode=self.profile_interpolation_mode,\n                                                                                   periodic=self._periodic_profile)\n\n        current_state = {\'just_touching_gap\': just_touching_gap, \'surface_1_points\': surface_1_points,\n                         \'surface_2_points\': surface_2_points, \'time\': previous_state[\'time\'] + self.max_time,\n                         \'time_step\': self.max_time, \'new_step\': True, \'off_set\': self._off_set}\n\n        adhesion_model = self.model.adhesion if self._adhesion else None\n        # for some reason the type checker messes up here, types are actually correct\n        # noinspection PyTypeChecker\n        max_load = self.normal_load if self.load_controlled else 1.0\n        opt_func = HeightOptimisationFunction(just_touching_gap=just_touching_gap, model=self.model,\n                                              adhesion_model=adhesion_model,\n                                              initial_contact_nodes=initial_contact_nodes,\n                                              max_it=self._max_it, rtol=self._rtol,\n                                              max_set_load=max_load,\n                                              rtol_outer=self._rtol_outer, max_it_outer=self._max_it_outer,\n                                              material_options=None,\n                                              periodic_axes=self._periodic_axes, )\n        self._opt_func = opt_func\n\n        if self._method == \'auto\':\n            if not np.isinf(opt_func.max_pressure):\n                if adhesion_model:\n                    raise ValueError("Adhesion and maximum load not allowed")\n                self._method = \'double\'\n            elif adhesion_model is not None:\n                self._method = \'rey\'\n            else:\n                self._method = \'pk\'\n\n        if self._unloading and \'contact_nodes\' in previous_state:\n            contact_nodes = previous_state[\'contact_nodes\']\n        else:\n            contact_nodes = None\n\n        converged = None\n        if self.load_controlled:\n            if self._relative_loading:\n                load = previous_state[\'total_normal_load\'] + self.normal_load\n            else:\n                load = self.normal_load\n\n            if self._method == \'pk\':\n                print(\'Solving contact by PK method\')\n                opt_func.contact_nodes = None\n                opt_func.p_and_k(load)\n            elif self._method == \'rey\':\n                print(\'Solving contact by Rey method\')\n                opt_func.contact_nodes = None\n                opt_func.rey(target_load=load)\n            else:\n                upper = 3 * max(just_touching_gap.flatten())\n                print(f\'upper bound set at: {upper}\')\n                print(f\'Interference tolerance set to {self._rtol_outer} Relative\')\n                opt_func.change_load(load, contact_nodes)\n                opt_func.brent(0, upper)\n        else:\n            if self._relative_loading:\n                interference = previous_state[\'interference\'] + self.interference\n            else:\n                interference = self.interference\n            if self._method == \'rey\':\n                # safe because of error checking in init\n                opt_func.rey(target_mean_gap=self.mean_gap)\n            else:\n                opt_func.change_load(1, contact_nodes)\n                _ = opt_func(interference, current_state)\n                converged = not opt_func.last_call_failed\n\n        current_state.update(opt_func.results)\n        if converged is not None:\n            current_state[\'converged\'] = converged\n        self.solve_sub_models(current_state)\n        self.save_outputs(current_state, output_file)\n\n        return current_state\n\n    def __repr__(self):\n        string = (f\'StaticStep({self.name}, time_period={self.max_time},\'\n                  f\'off_set_x={self._off_set[0]}, off_set_y={self._off_set[1]},\'\n                  f\'normal_load={self.normal_load}, interference={self.interference}\'\n                  f\'relative_loading:={self._relative_loading}, adhesion={self._adhesion},\'\n                  f\'unloading={self._unloading}, profile_interpolation_mode={self.profile_interpolation_mode},\'\n                  f\'periodic_geometry={self._periodic_profile}, periodic_axes{self._periodic_axes},\'\n                  f\'max_it_interference={self._max_it}, rtol_interference:{self._rtol},\'\n                  f\'max_it_displacement={self._max_it_outer}, rtol_displacement={self._rtol_outer})\')\n        return string\n', 'is_package': False},
    'slippy.contact.steps': {'source': 'import abc\nimport typing\nimport numpy as np\nimport slippy\nimport warnings\n\nfrom slippy.core import _ContactModelABC, _StepABC, _SubModelABC\nfrom slippy.core.outputs import OutputRequest\n\n__all__ = [\'_ModelStep\', \'InitialStep\', \'RepeatingStateStep\']\n\n"""\nSteps including solve functions, each actual step is a subclass of ModelStep should provide an __init__, solve\n and check method. these do all the heavy lifting\n"""\n\n\ndef _data_check_error_or_warn(msg: str):\n    if slippy.ERROR_IN_DATA_CHECK:\n        raise ValueError(msg)\n    else:\n        warnings.warn(msg)\n\n\nclass _ModelStep(_StepABC):\n\n    name = None\n    """The name of the step"""\n    _surfaces_required = None\n    """The number of surfaces required to run the step (used in data checks)"""\n    _options = None\n    """A named tuple options object should be different for each step type, specifies all of the analysis options"""\n    _model: _ContactModelABC = None\n    _subclass_registry = []\n    max_time: float\n    sub_models: typing.List[_SubModelABC]\n    outputs: typing.List[OutputRequest]\n\n    def __init__(self, step_name: str, max_time: float, provides: set):\n        assert isinstance(step_name, str), \'Step name must be string, this is used for all outputs related to this step\'\n        self.name = step_name\n        self.max_time = max_time\n        self.provides = provides\n        self.sub_models = []\n        self.outputs = []\n        self._current_state_debug = None\n\n    @classmethod\n    def __init_subclass__(cls, is_abstract=False, **kwargs):\n        super().__init_subclass__(**kwargs)\n        if not is_abstract:\n            _ModelStep._subclass_registry.append(cls)\n\n    @property\n    def model(self):\n        return self._model\n\n    @model.setter\n    def model(self, value):\n        if self._model is not None:\n            raise ValueError("The model cannot be changed after step instantiation")\n        if isinstance(value, _ContactModelABC):\n            self._model = value\n        else:\n            raise ValueError("Supplied model is not a contact model or no contact model supplied")\n\n    def _data_check(self, previous_state: set):\n        """\n        Produce errors for predicted errors during simulation\n\n        Parameters\n        ----------\n        previous_state: set\n            The model state from the last model step\n\n        Returns\n        -------\n        current_state: set\n            set of items in the current state after this step has run\n\n        Notes\n        -----\n        The methods check_sub_models and check_outputs should be called as part of this method\n        """\n        print(f"Checking step: {self.name}")\n        self.data_check(previous_state)\n        current_state = self.provides\n        if \'time\' not in current_state:\n            _data_check_error_or_warn("All steps must provide a time")\n        print(f"Checking sub models for step {self.name}")\n        self.check_sub_models(current_state)\n        print(f"Checking outputs for step {self.name}")\n        self.check_outputs(current_state)\n\n    def data_check(self, current_state):\n        """To be overwritten by steps that need more complicated checking"""\n        pass\n\n    def check_outputs(self, current_state: set):\n        """Data check all outputs\n\n        Parameters\n        ----------\n        current_state: set\n            The model state at the point when the outputs will be called\n\n        Returns\n        -------\n        current_state: set\n            Unmodified from the input set\n\n        Notes\n        -----\n        This should be called by each step in it\'s data check method\n        """\n        params_to_save = {\'time\'}\n        for output in self.outputs:\n            params_to_save.update(output.parameters)\n\n        expanded_state = current_state.copy()\n\n        if \'all\' in params_to_save:\n            params_to_save.update(expanded_state)\n            params_to_save.remove(\'all\')\n\n        for param in [\'loads\', \'total_displacement\', \'surface_1_displacement\', \'surface_2_displacement\']:\n            if param in expanded_state:\n                expanded_state.add(param + \'_x\')\n                expanded_state.add(param + \'_y\')\n                expanded_state.add(param + \'_z\')\n                expanded_state.remove(param)\n            if param in params_to_save:\n                params_to_save.update({param + \'_x\', param + \'_y\', param + \'_z\'})\n                params_to_save.remove(param)\n\n        missing_outputs = params_to_save - set(expanded_state)\n\n        for mo in missing_outputs:\n            if mo.startswith(\'surface\') and \';\' not in mo:\n                warnings.warn(f"Could not check output: {mo}, not possible to check surface outputs at this time")\n            else:\n                _data_check_error_or_warn(f"Could not find output {mo} in state for step {self.name}.\\n"\n                                          f"State will be: {current_state}")\n\n    def check_sub_models(self, current_state: set) -> set:\n        """ Check all the sub models of the current step\n\n        Parameters\n        ----------\n        current_state: set\n            The state of the model when the sub models are evaluated\n\n        Returns\n        -------\n        current_sate: set\n            The input set updated with all values found by the sub models\n\n        Notes\n        -----\n        This should be called by each step in it\'s data check method\n        """\n        for model in self.sub_models:\n            if model.requires - current_state:\n                _data_check_error_or_warn(f"Model step: {self.name} doesn\'t find required inputs for "\n                                          f"model: {model.name}:\\n"\n                                          f"State will be: {current_state}\\n"\n                                          f"Model requires: {model.requires}")\n            print(f"Passed: sub_model {model.name} in step {self.name}")\n            current_state.update(model.provides)\n        return set(current_state)\n\n    def add_sub_model(self, sub_model: _SubModelABC):\n        """\n        Add a sub model to be exec\n        :param sub_model:\n        :return:\n        """\n        if self.model is not None:\n            sub_model.model = self.model\n        self.sub_models.append(sub_model)\n\n    @abc.abstractmethod\n    def solve(self, current_state, output_file) -> dict:\n        """ Take in the current state solve the step and update the current state and any field outputs, printing in the\n        solve method will add to the log file, the standard output will be changed before running\n\n        Parameters\n        ----------\n        current_state\n        output_file\n\n        Returns\n        -------\n        previous_state\n        """\n        raise NotImplementedError("Solver not specified for this step!")\n\n    @abc.abstractmethod\n    def __repr__(self):\n        raise NotImplementedError()\n\n    def save_outputs(self, current_state: dict, output_file):\n        """Writes all outputs for the step into the output file\n\n        Parameters\n        ----------\n        current_state\n        output_file\n\n        Returns\n        -------\n\n        """\n        print("Writing outputs")\n        if not self.outputs:\n            return\n        params_to_save = {\'time\'}\n        for output in self.outputs:\n            if output.is_active(current_state[\'time\'], self.max_time):\n                params_to_save.update(output.parameters)\n        # make an expanded current_state\n        expanded_state = current_state.copy()\n        for param in [\'loads\', \'total_displacement\', \'surface_1_displacement\', \'surface_2_displacement\']:\n            if param in expanded_state:\n                expanded_state[param + \'_x\'] = expanded_state[param].x\n                expanded_state[param + \'_y\'] = expanded_state[param].y\n                expanded_state[param + \'_z\'] = expanded_state[param].z\n                del expanded_state[param]\n            if param in params_to_save:\n                params_to_save.update({param + \'_x\', param + \'_y\', param + \'_z\'})\n                params_to_save.remove(param)\n\n        for param in [\'surface_1_points\', \'surface_2_points\']:\n            if param in expanded_state:\n                expanded_state[param + \'_y\'] = expanded_state[param][0]\n                expanded_state[param + \'_x\'] = expanded_state[param][1]\n                del expanded_state[param]\n            if param in params_to_save:\n                params_to_save.update({param + \'_x\', param + \'_y\'})\n                params_to_save.remove(param)\n\n        # if all in extended params to save\n        if \'all\' in params_to_save:\n            params_to_save.update(expanded_state)\n            params_to_save.remove(\'all\')\n\n        missing_outputs = params_to_save - set(expanded_state)\n\n        missing_outputs_copy = missing_outputs.copy()\n\n        for mo in missing_outputs_copy:\n            if mo.startswith(\'surface\') and \';\' not in mo:\n                try:\n                    exec(\'param = self.model.\' + mo)\n                except IndexError as e:\n                    print(f"Output {mo}, {str(e)}")\n                    param = None\n                except AttributeError as e:\n                    print(f"Output {mo}, {str(e)}")\n                    param = None\n                except SyntaxError as e:\n                    print(f"Output {mo}, {str(e)}")\n                    param = None\n                except Exception as e:\n                    print(f"Output {mo}, {str(e)}")\n                    param = None\n            if param is not None:\n                expanded_state[mo] = param\n                missing_outputs.remove(mo)\n\n        if missing_outputs:\n            print(f"WARNING: Step {self.name}, failed to find outputs: {\', \'.join(missing_outputs)}, "\n                  f"available outputs are: {\', \'.join(set(expanded_state))}, as well as surface attributes "\n                  f"eg: surface1.profile or surface2.material... etc.")\n        for element in missing_outputs:\n            params_to_save.remove(element)\n\n        output_dict = {key: expanded_state[key] for key in params_to_save}\n        output_file.write(output_dict)\n\n    def solve_sub_models(self, current_state: dict):\n        print(\'## Solving sub models\')\n        if self.provides != set(current_state) and not slippy.ERROR_IF_MISSING_MODEL:\n            missing = self.provides-set(current_state)\n            unexpected = set(current_state)-self.provides\n            raise ValueError(f"Step {self.name} dosn\'t provide what it should or provides things which are not "\n                             f"declared, \\nprovides = {self.provides} \\ncurrent_state: {set(current_state)}"\n                             f"\\nMissing from current state = {missing}"\n                             f"\\nUnexpected in current state = {unexpected}"\n                             f"\\nTo suppress this error set slippy.ERROR_IF_MISSING_MODEL to False")\n        for model in self.sub_models:\n            self._current_state_debug = current_state\n            print(f"Sub model {model.name}:")\n            found_params = model.solve(current_state)\n            if model.provides != set(found_params) and not slippy.ERROR_IF_MISSING_SUB_MODEL:\n                unexpected = self.provides - set(current_state)\n                missing = set(current_state) - self.provides\n                raise ValueError(f"Sub model {model.name} dosn\'t provide what it should or provides things which are "\n                                 f"not declared, \\nprovides = {self.provides} \\nresults: {set(current_state)}"\n                                 f"\\nMissing from results = {missing}"\n                                 f"\\nUnexpected in results = {unexpected}"\n                                 f"\\nTo suppress this error set slippy.ERROR_IF_MISSING_SUB_MODEL to False")\n            current_state.update(found_params)\n        self._current_state_debug = None\n        return current_state\n\n    def add_output(self, output):\n        self.outputs.append(output)\n\n\nclass InitialStep(_ModelStep):\n    """\n    The initial step run at the start of each model\n    """\n\n    _options = True\n\n    # Should calculate the just touching position of two surfaces, set initial guesses etc.\n    separation: float = 0.0\n\n    def __init__(self, step_name: str = \'initial\', separation: float = None):\n        super().__init__(step_name=step_name, max_time=0, provides={\'off_set\', \'interference\', \'time\'})\n        if separation is not None:\n            self.separation = float(separation)\n\n    def _data_check(self, current_state: set):\n        """\n        Just check if this is the first step in the model\n        """\n        if current_state is not None:\n            print("Error steps are out of order, initial step should be first")\n        return {\'off_set\', \'time\', \'interference\'}\n\n    def solve(self, current_state, output_file):\n        if len(current_state) > 1 or \'time\' not in current_state:\n            raise ValueError("Steps have been run out of order, the initial step should always be run first")\n        current_state = dict()\n        current_state[\'off_set\'] = (0, 0)\n        current_state[\'interference\'] = 0\n        current_state[\'time\'] = 0\n        return current_state\n\n    def __repr__(self):\n        return f\'InitialStep(model = {str(self.model)}, name = {self.name})\'\n\n\nclass RepeatingStateStep(_ModelStep):\n    """A model step for repeating state\n\n    Parameters\n    ----------\n    name: str\n        The name of the step, used for debugging and logging\n    time_period: float, optional (1.0)\n        The total time period of the step\n    time_steps: int, optional (1)\n        The number of time steps used in the step\n    state: dict, optional (None)\n        The state to be repeated for every time point, if None the state from the previous step is used.\n\n    Notes\n    -----\n    This step is for trivially repeating state as part of a contact model, for example repeating the solution of a\n    normal contact without having to repeat the calculation. This behaviour can be usefull for doing parameter sweeps\n    using submodels. The state will not be updated between time steps.\n\n    Examples\n    --------\n    The following example creates a step which repeats an analytical hertzian solution for line contact:\n    >>> import slippy.surface as s\n    >>> import slippy.contact as c\n    >>> r = 0.047/2\n    >>> e = 210e9\n    >>> v = 0.3\n    >>> load = 320000\n    >>> width = 0.00061\n    >>> full_hertz_result = c.hertz_full([r, np.inf], [r, np.inf], e, v, load, line=True)\n    >>> surface = s.RoundSurface((0,r,r), extent = (width, width),\n    >>>                          shape = (128,128), generate = True)\n    >>> y,x  = surface.get_points_from_extent()\n    >>> x -= np.mean(x)\n    >>> p_hertz = full_hertz_result[\'pressure_f\'](x)\n    >>> contact_nodes = np.abs(x)<=full_hertz_result[\'contact_radii\'][0]\n    >>> step = RepeatingStateStep(\'all\', 1, 100, {\'loads_z\':p_hertz, \'contact_nodes\':contact_nodes})\n\n    Sub models can be added to this step as with any other step, however the contact solution will not be updated for\n    different time points.\n    """\n    def __init__(self, name: str, time_period: float = 1.0, time_steps: int = 1, state: dict = None):\n        super().__init__(name, time_period, set(state.keys()).union({\'time\', \'new_step\'}))\n        self.state = state\n        self.time_steps = time_steps or 1\n        self.time_period = time_period\n\n    def solve(self, previous_state, output_file):\n        times = np.linspace(previous_state[\'time\'],\n                            previous_state[\'time\'] + self.time_period,\n                            self.time_steps + 1)\n        for i in range(self.time_steps):\n            time = times[i + 1]\n            if self.state is None:\n                self.state = previous_state\n            current_state = self.state.copy()\n            current_state[\'time\'] = time\n            current_state[\'new_step\'] = i == 0\n            self.solve_sub_models(current_state)\n            self.save_outputs(current_state, output_file)\n        return current_state\n\n    def __repr__(self):\n        string = (f"RepeatingStateStep({self.name}, {self.time_period}," +\n                  f"{self.time_steps}, {self.state})")\n        return string\n', 'is_package': False},
    'slippy.contact.sub_models': {'source': '"""\nContact mechanics sub models (:mod:`slippy.contact.sub_models`)\n===============================================================\n\n.. currentmodule:: slippy.contact.sub_models\n\nIn slippy, things that are not solved in the main normal contact loop are dealt with using sub models. These could be\nanything from flash temperature to tribofilm growth to friction etc.. These sub models cover behaviour that doesn\'t\nneed to be strongly coupled to the normal contact problem or acts on a slower time scale.\n\nCurrently implemented sub models are:\n\n.. autosummary::\n   :toctree: generated\n\n   ResultContactStiffness       -- Find contact stiffness in any direction\n   WearElasticPerfectlyPlastic  -- Wear the surfaces where there is excess interference after elastic deformation\n\n"""\n\nfrom .contact_stiffness import ResultContactStiffness\nfrom .epp_wear import WearElasticPerfectlyPlastic\nfrom .friction_coulomb_model import FrictionCoulombSimple\nfrom .tangential_pure_sliding import TangentialPureSliding\nfrom .tangential_partial_slip import TangentialPartialSlip\nfrom .sub_surface_stress import SubsurfaceStress\nfrom .rigid_body_displacement import RollingSliding1D, RigidBodyDisplacementSliding\nfrom .dummy_value import DummyValue\nfrom .fill_displacements import FillDisplacements\nfrom ._TransientSubModelABC import _TransientSubModelABC\nfrom .shift_surface import UpdateShiftRollingSurface\nfrom .contact_time import ResultContactTime\n\n__all__ = [\'ResultContactStiffness\', \'WearElasticPerfectlyPlastic\', \'FrictionCoulombSimple\', \'TangentialPureSliding\',\n           \'TangentialPartialSlip\', \'SubsurfaceStress\', \'RigidBodyDisplacementSliding\',\n           \'RollingSliding1D\', \'DummyValue\', \'_TransientSubModelABC\', \'FillDisplacements\',\n           \'UpdateShiftRollingSurface\', \'ResultContactTime\']\n', 'is_package': True},
    'slippy.contact.sub_models._TransientSubModelABC': {'source': "from abc import ABC, abstractmethod\n\nimport slippy.core as core\nfrom numbers import Number\nfrom slippy.contact._step_utils import make_interpolation_func\n\n\nclass _TransientSubModelABC(core._SubModelABC, ABC):\n    def __init__(self, name, requires, provides, transient_values, transient_names, interpolation_mode, overwrite=True):\n        self.overwrite = overwrite\n        self.updated_dict = dict()\n        self.update_funcs = dict()\n        for key, value in zip(transient_names, transient_values):\n            if isinstance(value, Number):\n                self.updated_dict[key] = value\n            else:\n                self.updated_dict[key] = None\n                self.update_funcs[key] = make_interpolation_func(value, interpolation_mode, key)\n\n        super().__init__(name, requires, set(list(provides) + list(transient_names)))\n\n    def update_transience(self, time):\n        relative_time = (time - self.model.current_step_start_time) / self.model.current_step.max_time\n        for key, value in self.update_funcs.items():\n            self.updated_dict[key] = float(self.update_funcs[key](relative_time))\n\n    def solve(self, current_state: dict) -> dict:\n        self.update_transience(current_state['time'])\n        rtn_dict = self._solve(current_state, **self.updated_dict)\n        # safer to do this way in case sub model has overwritten the value (eg from another sub model)\n        self.updated_dict.copy().update(rtn_dict)\n        return self.updated_dict\n\n    @abstractmethod\n    def _solve(self, current_state: dict, **kwargs) -> dict:\n        pass\n", 'is_package': False},
    'slippy.contact.sub_models.contact_stiffness': {'source': 'import numpy as np\n\nimport slippy\nif slippy.CUDA:\n    import cupy as cp\nfrom slippy.core import _SubModelABC  # noqa: E402\nfrom slippy.core.influence_matrix_utils import plan_convolve, bccg  # noqa: E402\nfrom slippy.core.materials import _IMMaterial  # noqa: E402\n\n\nclass ResultContactStiffness(_SubModelABC):\n    """A sub model for finding contact stiffness of influence matrix based materials\n\n    Parameters\n    ----------\n    name: str\n        The name of the sub model, used for outputs and debugging\n    loading: bool, optional (True)\n        If True the contact stiffness will be found in the loading direction\n    unloading: bool, optional (True)\n        If True the contact stiffness will be found in the unloading direction\n    direction: str, optional (\'z\')\n        The component of contact stiffness to find, note that \'mean lines\' definition is only available for the\n        z (normal) component\n    tol: float, optional (1e-6)\n        Tolerance to us for the BCCG iterations\n    max_it: int, optional (None)\n        The maximum number of BCCG iterations, None defaults to the size of the problem (contact_nodes.size)\n    definition: {\'mean lines\', \'far points\', \'both\'}, optional (\'mean lines\')\n        The definition of contact stiffness to use:\n        - \'mean lines\' the change in average gap height per unit force.\n        - \'far points\' the approach of points infinitely deep in each half space per unit of force\n        - \'both\' will find both of the above\n    periodic_axes: tuple, optional ((False, False))\n        For each True value the corresponding axis will be solved by circular convolution, meaning the result is\n        periodic in that direction\n    boarder: int, optional (0)\n        If set the contact stiffness will only be calculated for the central portion of the domain.\n\n    Notes\n    -----\n    Results are added to current state dict as:\n    \'s_contact_stiffness_unloading_{ml or fp}_{direction}\' or\n    \'s_contact_stiffness_loading_{ml or fp}_{direction}\'\n    For example the normal contact stiffness in the loading direction will be:\n\n    """\n\n    def __init__(self, name: str, loading: bool = True, unloading: bool = True,\n                 direction: str = \'z\', tol: float = 1e-6,\n                 max_it: int = None, definition: str = \'mean lines\',\n                 periodic_axes=(False, False),\n                 boarder: int = 0):\n\n        if type(definition) is not str:\n            raise ValueError(f"Definition of stiffness must be a string received {type(definition)}")\n\n        definition = definition.lower()\n        valid_defs = {\'mean lines\', \'far points\', \'both\'}\n        if definition not in valid_defs:\n            raise ValueError(f\'Definition not recognised must be one of {valid_defs}, received: {definition}\')\n\n        if definition == \'both\':\n            definition = [\'ml\', \'fp\']\n        elif definition == \'mean lines\':\n            definition = [\'ml\']\n        else:\n            definition = [\'fp\']\n\n        self.definition = definition\n\n        if direction not in [\'x\', \'y\', \'z\']:\n            raise ValueError(\'direction should be one of x, y or z\')\n        self.component = direction * 2\n\n        self.loading = loading\n        self.unloading = unloading\n        self._periodic_axes = periodic_axes\n        self.boarder = boarder\n        self._last_span = (0, 0)\n        self._conv_func_cache = dict()\n\n        provides = set()\n\n        for defin in definition:\n            if loading:\n                provides.add(f\'s_contact_stiffness_loading_{defin}_{direction}_{boarder}\')\n            if unloading:\n                provides.add(f\'s_contact_stiffness_unloading_{defin}_{direction}_{boarder}\')\n\n        if not (loading or unloading):\n            raise ValueError("No output requested")\n\n        self.tol = tol\n        self.max_it = max_it\n        self.k_smooth = None\n        self.last_converged_result = {True: None, False: None}\n        if loading:\n            requires = {\'contact_nodes\', \'loads_z\'}\n        else:\n            requires = {\'contact_nodes\'}\n        super().__init__(name, requires, provides)\n\n    def _solve(self, current_state, loading):\n        rtn_dict = dict()\n\n        surf_1 = self.model.surface_1\n        surf_2 = self.model.surface_2\n\n        if not (isinstance(surf_1.material, _IMMaterial) and isinstance(surf_2.material, _IMMaterial)):\n            raise ValueError(\'Contact stiffness sub model will only work with influence matrix based materials\')\n\n        if loading:\n            max_pressure = min(surf_1.material.max_load, surf_2.material.max_load)\n            contact_nodes = np.logical_and(current_state[\'contact_nodes\'],\n                                           current_state[\'loads_z\'] < max_pressure * 0.99999)\n            p_contact = np.mean(current_state[\'contact_nodes\'])\n            p_plastic = np.mean(current_state[\'loads_z\'] > max_pressure * 0.99999)\n            print("Percentage contact nodes:", p_contact)\n            print("Percentage plastic nodes:", p_plastic)\n            print("Percentage of contact plastic:", p_plastic/p_contact)\n        else:\n            contact_nodes = current_state[\'contact_nodes\']\n\n        if self.boarder:\n            contact_nodes = contact_nodes[self.boarder:-self.boarder, self.boarder:-self.boarder]\n\n        displacement = np.ones(contact_nodes.shape)\n\n        span = tuple([s * (2 - pa) for s, pa in zip(contact_nodes.shape, self._periodic_axes)])\n\n        if span != self._last_span:\n            self._conv_func_cache = dict()\n\n        comp = self.component\n        if comp in self._conv_func_cache:\n            convolution_func = self._conv_func_cache[comp]\n        else:\n\n            im1 = surf_1.material.influence_matrix(components=[comp], grid_spacing=[surf_1.grid_spacing] * 2,\n                                                   span=span)[comp]\n            im2 = surf_2.material.influence_matrix(components=[comp], grid_spacing=[surf_1.grid_spacing] * 2,\n                                                   span=span)[comp]\n            total_im = im1 + im2\n            convolution_func = plan_convolve(displacement, total_im, contact_nodes, circular=self._periodic_axes)\n\n        try:\n            initial_guess = self.last_converged_result[loading]\n        except IndexError:\n            initial_guess = None\n\n        if initial_guess is None:\n            initial_guess = displacement * (1 / np.sum(total_im.flatten()))\n\n        loads_in_domain, failed = bccg(convolution_func, displacement[contact_nodes], self.tol,\n                                       self.max_it, x0=initial_guess[contact_nodes],\n                                       min_pressure=0, max_pressure=np.inf)\n\n        if slippy.CUDA:\n            loads_in_domain = cp.asnumpy(loads_in_domain)\n\n        if not failed:\n            full_result = np.zeros_like(displacement)\n            full_result[contact_nodes] = loads_in_domain\n            self.last_converged_result[loading] = full_result\n\n        k_rough = float(np.sum(loads_in_domain))\n\n        load_str = \'loading\' if loading else \'unloading\'\n\n        if \'fp\' in self.definition:\n            rtn_dict[f\'s_contact_stiffness_{load_str}_fp_\'] = k_rough/contact_nodes.size\n\n        if \'ml\' in self.definition:\n            all_disp = convolution_func(loads_in_domain, ignore_domain=True)\n            all_disp[all_disp > 1] = 1\n            all_disp[contact_nodes] = 1\n            rtn_dict[f\'s_contact_stiffness_{load_str}_ml_\'] = (k_rough / (1 - np.mean(all_disp))) / contact_nodes.size\n\n        return rtn_dict, failed\n\n    def solve(self, current_state):\n        print(f"SUB MODEL: {self.name}")\n        results = dict()\n        direction = self.component[0]\n        if self.loading:\n            sl, failed = self._solve(current_state, True)\n            print(f"Contact stiffness in loading direction, success: {not failed}, stiffness: {sl}")\n            for key, value in sl.items():\n                results[key + direction + f\'_{self.boarder}\'] = value\n        if self.unloading:\n            su, failed = self._solve(current_state, False)\n            print(f"Contact stiffness in unloading direction, success: {not failed}, stiffness: {su}")\n            for key, value in su.items():\n                results[key + direction + f\'_{self.boarder}\'] = value\n        return results\n', 'is_package': False},
    'slippy.contact.sub_models.contact_time': {'source': 'from slippy.core import _SubModelABC\nimport numpy as np\nfrom numba import njit\nimport pickle\n\n__all__ = ["ResultContactTime"]\n\n\nclass ResultContactTime(_SubModelABC):\n    def __init__(self, name: str, interpolate_new: bool = True, movement_axis: int = 1):\n        """\n        Find the contact time for each point in the surface.\n\n        Parameters\n        ----------\n        name: str\n            The name of the sub model, used for debugging\n        interpolate_new: bool, optional (True)\n            If True points which are brought into contact on the current time step will have their initial contact time\n            interpolated. If this is set, the movement_axis must be correct.\n        movement_axis: int, optional (0)\n            The axis along which the contact moves (1 for x direction)\n\n        Notes\n        -----\n        Interpolation of new contact points follows these rules:\n        First the longest line of new contact nodes in the sliding direction will be found and the direction of sliding\n        (+ve/-ve along the axis) will be determined.\n        then for each line of new contact nodes:\n        If there is an adjacent node which was in contact on the last time step:\n            The line is filled starting with the full time step value next to the adjacent node\n        Otherwise:\n            the line is filled starting with the minimum value at the side opposite to the adjacent contact nodes from\n            other lines\n        The step in values is decided by the maximum line length.\n\n        This sub model requires:\n            \'surface_1_points\', \'surface_2_points\', \'time_step\', \'contact_nodes\'\n        and provides:\n            "contact_time_1", "contact_time_2"\n\n        Which are the contact times of the points on the first and second surface respectively\n        """\n        super().__init__(name, requires={\'surface_1_points\', \'surface_2_points\', \'time_step\', \'contact_nodes\'},\n                         provides={"contact_time_1", "contact_time_2"})\n        self._arrays_written = False\n        self._interpolate_new = interpolate_new\n        self._current_times = dict()\n        self._axis = movement_axis\n\n    def solve(self, current_state: dict) -> dict:\n        rtn_dict = {}\n\n        for surface_num in [1, 2]:\n            surface = self.model.__getattribute__(f"surface_{surface_num}")\n            y_real, x_real = surface.convert_coordinates(*current_state[f\'surface_{surface_num}_points\'])\n            x_ind = np.mod(np.array(x_real / surface.grid_spacing + surface.grid_spacing / 2, dtype=np.uint16),\n                           surface.max_shape()[1])\n            y_ind = np.mod(np.array(y_real / surface.grid_spacing + surface.grid_spacing / 2, dtype=np.uint16),\n                           surface.max_shape()[0])\n            if not self._arrays_written:\n                self._current_times[surface_num] = np.zeros(surface.max_shape())\n            sub_view = self._current_times[surface_num][y_ind, x_ind]\n            sub_view += current_state[\'time_step\']\n            sub_view *= current_state[\'contact_nodes\']\n            if self._interpolate_new and self._arrays_written:  # don\'t attempt on first go\n                if not self._axis:\n                    worked = _interpolate_and_fill(sub_view.T, current_state[\'contact_nodes\'].T,\n                                                   current_state[\'time_step\'])\n                else:\n                    worked = _interpolate_and_fill(sub_view, current_state[\'contact_nodes\'], current_state[\'time_step\'])\n                if not worked:\n                    pickle.dump({\'time\': current_state[\'time\'],\n                                 \'axis\': self._axis,\n                                 \'sub_view\': sub_view,\n                                 \'cn\': current_state[\'contact_nodes\'],\n                                 \'time_step\': current_state[\'time_step\']}, open("save.p", "wb"))\n                    raise ValueError(f"Sub model {self.name} could not be solved, this is often cause by the sliding "\n                                     f"axis being wrong in the sub model definition")\n            rtn_dict[f"contact_time_{surface_num}"] = sub_view.copy()\n            self._current_times[surface_num][y_ind, x_ind] = sub_view\n        self._arrays_written = True\n        return rtn_dict\n\n\n@njit\ndef _interpolate_and_fill(current_times: np.ndarray, contact_nodes: np.ndarray, time_step: float):\n    first_index = current_times == time_step\n\n    undecided = True\n    start = None\n    longest_line = 0\n\n    for line, ct, i in zip(first_index, current_times, range(len(first_index))):\n        if np.any(line):\n            # get the ends of the line\n            idx = np.where(line[:-1] != line[1:])[0]\n            line_len = idx[-1] - idx[0]\n            if undecided:\n                if ct[idx[0]]:\n                    start = True\n                    undecided = False\n                elif ct[idx[-1] + 1]:\n                    start = False\n                    undecided = False\n            if line_len > longest_line:\n                longest_line = line_len\n\n    if longest_line == 0:\n        return True\n    if undecided:\n        return False\n\n    fill_values = time_step * (np.arange(longest_line) + 1) / longest_line\n    if start:\n        fill_values = np.flip(fill_values)\n\n    for line, ct, i in zip(first_index, current_times, range(len(first_index))):\n        if np.any(line):\n            # get the ends of the line\n            idx = np.where(line[:-1] != line[1:])[0]\n            line_len = idx[-1] - idx[0]\n            if start:\n                if ct[idx[0]]:\n                    ct[idx[0] + 1:idx[-1] + 1] = fill_values[:line_len]\n                else:\n                    ct[idx[0] + 1:idx[-1] + 1] = fill_values[-line_len:]\n            else:\n                if ct[idx[-1] + 1]:\n                    ct[idx[0] + 1:idx[-1] + 1] = fill_values[-line_len:]\n                else:\n                    ct[idx[0] + 1:idx[-1] + 1] = fill_values[:line_len]\n    current_times *= contact_nodes\n    return True\n', 'is_package': False},
    'slippy.contact.sub_models.dummy_value': {'source': "from slippy.core import _SubModelABC\n\n\nclass DummyValue(_SubModelABC):\n    def __init__(self, dummy_dict: dict):\n        self.dummy_dict = dummy_dict\n        super().__init__('Dummy', set(), set(dummy_dict.keys()))\n\n    def solve(self, current_state: dict) -> dict:\n        return self.dummy_dict\n", 'is_package': False},
    'slippy.contact.sub_models.epp_wear': {'source': 'import warnings\nimport numpy as np\n\nimport slippy\nfrom slippy.core import _SubModelABC\n\n\n__all__ = [\'WearElasticPerfectlyPlastic\']\n\n\nclass WearElasticPerfectlyPlastic(_SubModelABC):\n    r"""\n    Remove overlap between surfaces left after contact with a maximum load\n\n    Parameters\n    ----------\n    name: str\n        The name of the sub model and wear source, used for outputs and error logging\n    proportion_surface_1: float\n        The proportion of the overlap to come be worn from the main surface in the simulation.\n    proportion_surface_2: float, optional (None)\n        The proportion of the overlap to be removed from surface 2, this defaults to the remaining overlap, after\n        subtracting the proportion from the first surface\n    no_time: bool, optional (False)\n        Must be set to True if the step which this sub-model is added to is solved with no time dependence, otherwise\n        the full wear will be applied for each time step leading to unphysical results\n\n    Notes\n    -----\n    This sub model assumes that the grid spacings for the surfaces are the same, if this is not correct wear will be\n    assigned incorrectly\n\n    For this model to work there must be some overlap between the surfaces at the end of the model step, otherwise no\n    wear will be applied.\n\n    Provides:\n\n    * \'total_plastic_deformation\': The total material removed for this time step\n    * \'wear_plastic_surface_1\': The wear applied to each point of surface 1, applied at the points \'surface_1_points\',\n      only provided if proportion_surface_1 is greater than 0\n    * \'wear_plastic_surface_2\': The wear applied to each point of surface 2, applied at the points \'surface_2_points\',\n      only provided if proportion_surface_1 is less than 1\n\n\n    For simulations with movement between the surfaces wear_plastic_surface_1 and 2 can be confusing as they are aligned\n    with the points specified is surface_1_points, not the base coordinates of surface 1 or 2. For examining the output\n    from this wear model over time it may be more simple to request the following output:\n    \'surface_1.wear_volumes[\'this_model_name\']\'\n    This will always contain the cumulative wear from this model in the base coordinates of the surface.\n    """\n    n_calls = 0\n\n    def __init__(self, name: str, proportion_surface_1: float, proportion_surface_2: float = None,\n                 no_time: bool = False):\n        requires = {\'interference\', \'total_displacement_z\', \'just_touching_gap\'}\n        provides = {\'total_plastic_deformation\'}\n        super().__init__(name, requires, provides)\n\n        if proportion_surface_1 > 1 or proportion_surface_1 < 0:\n            raise ValueError("Proportion of wear applied to surface 1 should be between 0 and 1")\n        if proportion_surface_2 is not None:\n            if proportion_surface_2 > 1 or proportion_surface_2 < 0:\n                raise ValueError("Proportion of wear applied to surface 2 should be between 0 and 1")\n            if (proportion_surface_1+proportion_surface_2) > 1.00000001:\n                warnings.warn("Proportion surface 1 + proportion surface 2 is greater than 1, more wear will be applied"\n                              " than the overlap between the surfaces, this will result in unphysical results")\n\n        self.p_surf_1 = proportion_surface_1\n        self.p_surf_2 = proportion_surface_2\n        if proportion_surface_1 > 0:\n            self.requires.add(\'surface_1_points\')\n            self.provides.add(\'wear_plastic_surface_1\')\n        if proportion_surface_2 > 0:\n            self.requires.add(\'surface_2_points\')\n            self.provides.add(\'wear_plastic_surface_2\')\n        self.plastic_def_this_step = None\n        self.no_time = no_time\n\n    def solve(self, current_state: dict) -> dict:\n        if \'converged\' in current_state and not current_state[\'converged\']:\n            print(f"SUB MODEL: {self.name}, Solution did not converge, no wear")\n            return current_state\n\n        if self.no_time:\n\n            just_touching_gap = current_state[\'just_touching_gap\']\n\n            if self.plastic_def_this_step is None or (\'new_step\' in current_state and current_state[\'new_step\']):\n                self.plastic_def_this_step = np.zeros_like(just_touching_gap)\n            # need to sort out the discrepancy between the current just touching gap and the one used for the model\n            gap = (just_touching_gap - current_state[\'interference\'] + current_state[\'total_displacement_z\'] +\n                   self.plastic_def_this_step)\n\n        else:\n            # just use the current just touching gap and interference\n            gap = slippy.asnumpy(current_state[\'gap\'])\n            # just_touching_gap = current_state[\'just_touching_gap\']\n            # gap = (just_touching_gap - current_state[\'interference\'] + current_state[\'total_displacement_z\'])\n\n        max_load = min(self.model.surface_1.material.max_load,\n                       self.model.surface_2.material.max_load)\n        idx = np.logical_and(current_state[\'loads_z\'] >= max_load,\n                             np.logical_and(gap < 0, current_state[\'contact_nodes\']))\n        total_wear = -gap[idx]\n\n        if self.no_time:\n            self.plastic_def_this_step[idx] += total_wear\n        if total_wear.size:\n            tpd = np.sum(total_wear) * self.model.surface_1.grid_spacing ** 2 * (self.p_surf_1+self.p_surf_2)\n        else:\n            tpd = np.array(0.0)\n        results = {\'total_plastic_deformation\': tpd}\n        if self.p_surf_1 > 0:\n            y_pts = current_state[\'surface_1_points\'][0][idx]\n            x_pts = current_state[\'surface_1_points\'][1][idx]\n            surface_1_wear = total_wear * self.p_surf_1\n            results[\'wear_plastic_surface_1\'] = surface_1_wear\n            self.model.surface_1.wear(self.name, x_pts, y_pts, surface_1_wear)\n        if self.p_surf_2 > 0:\n            y_pts = current_state[\'surface_2_points\'][0][idx]\n            x_pts = current_state[\'surface_2_points\'][1][idx]\n            surface_2_wear = total_wear * self.p_surf_2\n            results[\'wear_plastic_surface_2\'] = surface_2_wear\n            self.model.surface_2.wear(self.name, x_pts, y_pts, surface_2_wear)\n\n        print(f"SUB MODEL: {self.name}, total deformation: {tpd}")\n\n        return results\n', 'is_package': False},
    'slippy.contact.sub_models.fill_displacements': {'source': 'from slippy.core import _SubModelABC, plan_coupled_convolve, _IMMaterial\nfrom itertools import product\n\n__all__ = [\'FillDisplacements\', ]\n\n\nclass FillDisplacements(_SubModelABC):\n    def __init__(self, load_directions, displacement_directions=\'xyz\', periodic_axes=(False, False),\n                 name: str = \'fill_displacements\', surfaces=(\'total\',),\n                 overwrite=True):\n        """Find displacements caused by existing loads for influence matrix based materials\n\n        Parameters\n        ----------\n        load_directions: str\n            The directions of loads to consider, this sub model will require all specified loads to be in the state.\n            eg \'xz\' will fill the displacement caused by loads in the x and z directions, and \'loads_x\', \'loads_z\' will\n            be required by the sub-model\n        displacement_directions: str, optional (\'xyz\')\n            The displacement directions to find\n        periodic_axes: tuple, optional ((False, False))\n            For each True value the corresponding axis will be solved by circular convolution, meaning the result is\n            periodic in that direction\n        surfaces: tuple {1, 2, \'total\'}, optional ((\'total\', ))\n            The surface to find displacements on. A tuple containing any of the valid items or a single valid item.\n        overwrite: bool, optional (True)\n            If True any existing result will be over written, otherwise it will be added to.\n        """\n        requires = set(f\'loads_{d}\' for d in load_directions)\n        if isinstance(surfaces, str):\n            surfaces = (surfaces, )\n        provides = set()\n        self._surface_strs = []\n        for s in surfaces:\n            if s not in {1, 2, \'total\', \'1\', \'2\'}:\n                raise ValueError(f"Surface not recognised for fill displacements sub model, valid options are:"\n                                 f" 1, 2, \'total\', \'1\', \'2\'. Received {s}")\n            st = s if s == \'total\' else f\'surface_{s}\'\n            provides.update(st + \'_displacement_\' + d for d in displacement_directions)\n\n            self._surface_strs.append(st)\n        self.load_directions = load_directions\n        self._periodic_axes = periodic_axes\n        self._overwrite = overwrite\n        self._last_span = None\n        self._conv_funcs = dict()\n        self.components = [lo+d for lo, d in product(load_directions, displacement_directions)]\n        super().__init__(name, requires, provides)\n\n    def solve(self, current_state: dict) -> dict:\n        mat1 = self.model.surface_1.material\n        mat2 = self.model.surface_2.material\n        gs = self.model.surface_1.grid_spacing\n        assert isinstance(mat1, _IMMaterial), "Material for surface 1 is not influence matrix based"\n        assert isinstance(mat2, _IMMaterial), "Material for surface 2 is not influence matrix based"\n        shape = current_state[next(iter(self.requires))].shape\n        span = tuple([s*(2-pa) for s, pa in zip(shape, self._periodic_axes)])\n        loads_dict = {direction: current_state[f\'loads_{direction}\'] for direction in self.load_directions}\n        if self._last_span is None or span != self._last_span:\n            for st in self._surface_strs:\n                if st == \'total\':\n                    im1 = mat1.influence_matrix(self.components, (gs, gs), span)\n                    im2 = mat2.influence_matrix(self.components, (gs, gs), span)\n                    im = {key: im1[key] + im2[key] for key in self.components}\n                elif st[8] == \'1\':\n                    im = mat1.influence_matrix(self.components, (gs, gs), span)\n                elif st[8] == \'2\':\n                    im = mat2.influence_matrix(self.components, (gs, gs), span)\n                else:\n                    raise ValueError("Something unexpected happened, please report")\n\n                self._conv_funcs[st] = plan_coupled_convolve(loads_dict, im, None, self._periodic_axes)\n\n        rtn_dict = dict()\n        for st in self._surface_strs:\n            result = self._conv_funcs[st](loads_dict)\n            for key in result:\n                if self._overwrite:\n                    rtn_dict[st + \'_displacement_\' + key] = result[key]\n                else:\n                    if st + key in current_state:\n                        rtn_dict[st + \'_displacement_\' + key] = result[key] + current_state[st + key]\n                    else:\n                        rtn_dict[st + \'_displacement_\' + key] = result[key]\n        return rtn_dict\n', 'is_package': False},
    'slippy.contact.sub_models.friction_coulomb_model': {'source': 'from slippy.core import _SubModelABC\n\n__all__ = [\'FrictionCoulombSimple\']\n\n\nclass FrictionCoulombSimple(_SubModelABC):\n\n    def __init__(self, name: str, coefficient):\n        """ Simple coulomb friction, limiting friction is normal force multiplied by a coefficient for each point\n\n        Parameters\n        ----------\n        name: str\n            The name of the model, used for debugging\n        coefficient: float\n            The value of the friction coefficient, must be grater than 0\n\n        Notes\n        -----\n        This sub model finds the limiting friction force at each point on the surface. To apply the load a tangential\n        model describing how much of the contact is sliding should also be added.\n\n        Provides:\n        * \'maximum_tangential_force\': The maximum allowable tangential force at each point on the surface, aligned with\n            The points which are in contact, described by surface_1_points and surface_2_points\n        """\n        requires = {\'loads_z\'}\n        provides = {\'maximum_tangential_force\', \'coulomb_coefficient\'}\n        super().__init__(name, requires, provides)\n        self.coefficient = coefficient\n\n    def solve(self, current_state):\n        return {\'maximum_tangential_force\': current_state[\'loads_z\']*self.coefficient,\n                \'coulomb_coefficient\': self.coefficient}\n', 'is_package': False},
    'slippy.contact.sub_models.rigid_body_displacement': {'source': 'import numpy as np\nimport typing\nimport slippy\nfrom ._TransientSubModelABC import _TransientSubModelABC\nfrom slippy.core import _IMMaterial, plan_convolve, gmres\n\n__all__ = [\'RigidBodyDisplacementSliding\', \'RollingSliding1D\']\n\n\nclass RigidBodyDisplacementSliding(_TransientSubModelABC):\n    """Displacement from pure sliding\n\n    """\n\n    def __init__(self, distance_x: typing.Union[typing.Sequence[float], float] = 0,\n                 distance_y: typing.Union[typing.Sequence[float], float] = 0, name: str = \'Sliding\',\n                 interpolation_mode: str = \'linear\'):\n\n        super().__init__(name, {\'contact_nodes\'}, {\'rigid_body_displacement_x\', \'rigid_body_displacement_y\'},\n                         [distance_x, distance_y],\n                         [\'distance_x\', \'distance_y\'], interpolation_mode)\n\n    def _solve(self, current_state: dict, distance_x=None, distance_y=None, **kwargs) -> dict:\n        if distance_x is None or distance_y is None:\n            raise ValueError("Transient items not properly set")\n        if kwargs:\n            raise ValueError("Unexpected transient items")\n        current_state[\'rigid_body_displacement_x\'] = distance_x\n        current_state[\'rigid_body_displacement_y\'] = distance_y\n        return current_state\n\n\nclass RollingSliding1D(_TransientSubModelABC):\n    """Solve the one dimensional rolling sliding problem\n\n    Parameters\n    ----------\n    creep_or_speed_difference: float, 2 element sequence of floats\n        Either a float indicating constant 1D value, or a two element sequence of floats giving the value at the start\n        and end of the model step, or a 2 by n array of n values and n times respectively. The interpretation of this\n        parameter depends on the from_contact_time parameter. If the rigid body displacement is calculated from the\n        contact time this parameter represents the speed difference, otherwise the rigid body displacement is calculated\n        from the distance to the leading edge and this parameter represents the creep.\n    from_contact_time: bool, optional (False)\n        If true the creep will be calculated from the contact time for each element, in this case the\n        creep_or_speed_difference parameter is interpreted as the difference in speed between the bodies, otherwise it\n        is interpreted as the creep (difference in speed divided by the mean speed)\n    direction: {\'x\', \'y\'}, optional (\'x\')\n        The axis along which the creep is applied\n    name: str, optional (\'RollingSliding1D\')\n        The name of the sub model used for logging and debugging\n    interpolation_mode: str, optional (None)\n        The kind of interpolation to use for interpolating the creep values, and mode compatible with\n        scipy.interpolate.interp1d can be used\n    periodic_axes: tuple, optional ((False, False))\n        For each True value the corresponding axis will be solved by circular convolution, meaning the result is\n        periodic in that direction\n    tol: float, optional (1e-7)\n        The tolerance used for convergence of the GMRES iterations\n    max_inner_it: int, optional (None)\n        The maximum number of iterations for the GMRES solver, defaults to the problem size\n    restart: int, optional (20)\n        The number of iterations between restarts of the GMRES solver, a higher number generally gives faster\n        convergence but each iteration is more computationally costly\n    max_outer_it: int, optional (100)\n        The maximum number of iterations used for the outer loop (slip area determination)\n    add_to_existing:bool = True\n        If True the rigid body displacement will be added to the existing displacements in the current state, not\n        needed for matched materials\n\n    Notes\n    -----\n    This sub model will only run on the CPU\n\n    References\n    ----------\n\n    Examples\n    --------\n\n    """\n\n    def __init__(self, creep_or_speed_difference: typing.Union[typing.Sequence[float], float],\n                 from_contact_time: bool = False,\n                 direction: str = \'x\',\n                 name: str = \'RollingSliding1D\',\n                 interpolation_mode: str = \'linear\',\n                 periodic_axes: typing.Sequence[bool] = (False, False),\n                 tol: float = 1e-7, max_inner_it: int = None, restart: int = 20, max_outer_it: int = 100,\n                 add_to_existing: bool = True):\n        if direction not in {\'x\', \'y\'}:\n            raise ValueError("Creep direction should be \'x\' or \'y\'")\n        self.component = direction * 2\n        self.axis = int(direction == \'x\')  # 1 if x 0 if y\n        self.from_contact_time = from_contact_time\n        self._last_shape = None\n        self._pre_solve_checks = False\n        self._im_1 = None\n        self._im_2 = None\n        self._im_total = None\n        self._periodic_axes = periodic_axes\n        self._tol = tol\n        self._max_it = max_inner_it\n        self._restart = restart\n        self._max_outer_it = max_outer_it\n        self._base_conv_func = None\n        self.previous_result = None\n        self.previous_domain = -10\n        self.multiplier = 1.0\n        self._add_to_existing = add_to_existing\n        requires = {\'maximum_tangential_force\', \'contact_nodes\', \'time\'}\n        if from_contact_time:\n            requires.add(\'contact_time_1\')\n            requires.add(\'contact_time_2\')\n\n        super().__init__(name, requires,\n                         {f\'rigid_body_displacement_{direction}\',\n                          f\'loads_{direction}\',\n                          f\'total_displacement_{direction}\',\n                          f\'total_tangential_force_{direction}\',\n                          \'slip_nodes\', f\'{name}_failed\'},\n                         [creep_or_speed_difference, ],\n                         [\'creep\', ], interpolation_mode)\n\n    def _check(self, shape):\n        # check that both are im materials and store ims\n        if not self._pre_solve_checks or shape != self._last_shape:\n            if isinstance(self.model.surface_1.material, _IMMaterial) and \\\n               isinstance(self.model.surface_2.material, _IMMaterial):\n                span = tuple([s * (2 - pa) for s, pa in zip(shape, self._periodic_axes)])\n                im_1 = self.model.surface_1.material.influence_matrix([self.component],\n                                                                      [self.model.surface_1.grid_spacing] * 2,\n                                                                      span)[self.component]\n                im_2 = self.model.surface_2.material.influence_matrix([self.component],\n                                                                      [self.model.surface_1.grid_spacing] * 2,\n                                                                      span)[self.component]\n                self._im_1 = im_1\n                self._im_2 = im_2\n                self._im_total = im_1 + im_2\n                self._pre_solve_checks = True\n                self._base_conv_func = plan_convolve(np.zeros(shape), self._im_total,\n                                                     None, self._periodic_axes)\n                self._last_shape = shape\n            else:\n                raise ValueError("This sub model only supports influence matrix based materials")\n\n    def _solve(self, current_state: dict, creep=None) -> dict:\n        # get rigid body displacement (minus off set at first node)\n        if creep is None:\n            raise ValueError("Transient items not properly set")\n\n        if slippy.CUDA:\n            xp = slippy.xp\n        else:\n            xp = np\n\n        domain = xp.array(current_state[\'contact_nodes\'], dtype=bool)\n\n        if self.from_contact_time:\n            rbd = (current_state[\'contact_time_1\']+current_state[\'contact_time_2\']) * creep/2\n            first = xp.argmax(xp.logical_and(xp.array(rbd) == 0, domain))\n            if self.axis:\n                first_index = xp.arange(domain.shape[not self.axis], dtype=int), first\n            else:\n                first_index = first, xp.arange(domain.shape[not self.axis], dtype=int)\n        else:\n            x_1 = xp.asarray(self.model.surface_1.get_points_from_extent()[self.axis])\n            first = xp.argmax(domain, axis=self.axis)\n            if self.axis:\n                first_index = xp.arange(domain.shape[not self.axis], dtype=int), first\n            else:\n                first_index = first, xp.arange(domain.shape[not self.axis], dtype=int)\n            off_sets = xp.expand_dims(x_1[first_index], self.axis)\n            x_1 -= off_sets\n            rbd = x_1 * creep * domain\n        rbd = xp.array(rbd)\n        # checks for im materials makes self._base_conv_function if needed\n        self._check(domain.shape)\n\n        # prepare limits etc\n        limits_full = xp.array(current_state[\'maximum_tangential_force\'])\n        limits_full[first_index] = xp.inf\n        max_it = self._max_it or xp.sum(domain)\n        max_loads = xp.array(current_state[\'maximum_tangential_force\'])\n        max_loads[first_index] = 0\n        disp_guess = self._base_conv_func(max_loads)\n        disp_offsets = xp.expand_dims(disp_guess[first_index], self.axis)\n        max_def = disp_guess - disp_offsets\n        self.multiplier = xp.mean(disp_guess[first_index]) / np.mean(max_loads)\n\n        try:\n            if self.previous_result is None or xp.any(domain ^ self.previous_domain):\n                initial_guess = max_loads[domain]\n            else:\n                initial_guess = self.previous_result[domain]\n        except ValueError:\n            initial_guess = max_loads[domain]\n\n        # noinspection PyTypeChecker\n        if xp.all(max_def < rbd):\n            # full slip\n            print(\'full slip\')\n            sub_loads, failed = max_loads[domain], False\n            full_loads = max_loads\n            full_disp = disp_guess\n            disp_offsets = max_def\n            slip_nodes = domain\n        else:\n            conv_func = ConvFuncWrapper(self._base_conv_func, limits_full, domain,\n                                        self.axis, self.multiplier, xp)\n            n = xp.sum(domain)\n            n = int(n)\n            # noinspection PyArgumentList\n\n            domain_unsat = domain\n            failed = True\n            sub_loads = None\n            i = 0\n            while i < self._max_outer_it and n > 0:\n                sub_loads, failed = gmres(conv_func, initial_guess, rbd[domain_unsat] - conv_func.conv_sat(),\n                                          self._restart, max_it, self._tol)\n                if failed:\n                    raise ValueError(f"Sub model {self.name} failed to converge")\n                initial_guess, still_going, n = conv_func.update_saturated(sub_loads)\n                n = int(n)\n                if not still_going:\n                    break\n                # noinspection PyArgumentList\n                domain_unsat = conv_func.domain_unsat\n                print(\'iteration:\', i, \'domain_unsat:\', xp.sum(domain_unsat))\n                i += 1\n            full_loads, disp_offsets, full_disp = conv_func.get_full_pressures(sub_loads)\n            slip_nodes = conv_func.saturated_nodes\n\n        # cache result\n        if not failed:\n            self.previous_result = full_loads\n            self.previous_domain = domain\n\n        if failed:\n            print(f"Sub model {self.name} failed to converge")\n        else:\n            print(f"Sub model {self.name} converged successfully")\n\n        # if f\'total_displacement_{self.component[0]}\' in current_state and self._add_to_existing:\n        #     full_disp -= current_state[f\'total_displacement_{self.component[0]}\']\n        rbd -= xp.expand_dims(disp_offsets, self.axis)\n        gs = self.model.surface_1.grid_spacing\n\n        return {f\'loads_{self.component[0]}\': full_loads,\n                f\'total_displacement_{self.component[0]}\': full_disp,\n                f\'rigid_body_displacement_{self.component[0]}\': rbd,\n                f\'total_tangential_force_{self.component[0]}\': gs ** 2 * np.sum(full_loads),\n                f\'{self.name}_failed\': failed,\n                \'slip_nodes\': slip_nodes}\n\n\nclass ConvFuncWrapper:\n    def __init__(self, conv_func, max_loads, domain, direction: int, multiplier, xp):\n        self.first = xp.argmax(domain, axis=direction)\n        if direction:\n            self.first_index = xp.arange(domain.shape[not direction], dtype=int), self.first\n        else:\n            self.first_index = self.first, xp.arange(domain.shape[not direction], dtype=int)\n        self.conv_func = conv_func\n        self.max_loads = max_loads.copy()\n        self.max_loads[self.first_index] = xp.inf\n        self.domain = domain\n        self.multiplier = multiplier\n        self.saturated_nodes = xp.zeros_like(domain)\n        self.domain_unsat = domain\n        self.sat_pressures = []\n        self.direction = direction\n        self._xp = xp\n\n    def update_saturated(self, pressures):\n        new_sat = pressures >= self.max_loads[self.domain_unsat]\n        self.saturated_nodes[self.domain_unsat] = new_sat\n        condition = self._xp.all(self._xp.logical_not(self.saturated_nodes[self.first_index]))\n        if not condition:\n            print("Assertion failed")\n            assert condition\n        self.sat_pressures = self.max_loads[self.saturated_nodes]\n        self.domain_unsat = self._xp.logical_and(self.domain, self._xp.logical_not(self.saturated_nodes))\n        return pressures[self._xp.logical_not(new_sat)], self._xp.sum(new_sat), len(pressures) - self._xp.sum(new_sat)\n\n    def unsat_all(self):\n        self.saturated_nodes[:] = False\n        self.domain_unsat = self.domain\n        self.sat_pressures = []\n\n    def conv_sat(self):\n        full_loads = self._xp.zeros(self.domain.shape)\n        full_loads[self.saturated_nodes] = self.sat_pressures\n        full_disp = self.conv_func(full_loads)\n        return full_disp[self.domain_unsat]\n\n    def get_full_pressures(self, sub_loads, include_sat=True):\n        full_loads = self._xp.zeros(self.domain.shape)\n        full_loads[self.domain_unsat] = sub_loads.flatten()\n        if include_sat:\n            full_loads[self.saturated_nodes] = self.sat_pressures\n        disp_offsets = full_loads[self.first_index]\n        full_loads[self.first_index] = 0\n        full_disp = self.conv_func(full_loads)\n        return full_loads, disp_offsets, full_disp\n\n    def __call__(self, sub_loads):\n        sub_shape = sub_loads.shape\n        full_loads, disp_offsets, full_disp = self.get_full_pressures(sub_loads, False)\n        stripey = self._xp.expand_dims(disp_offsets, self.direction) * self.multiplier\n        full_disp += stripey\n        return full_disp[self.domain_unsat].reshape(sub_shape)\n', 'is_package': False},
    'slippy.contact.sub_models.shift_surface': {'source': 'from ._TransientSubModelABC import _TransientSubModelABC  # noqa: E402\n\n__all__ = [\'UpdateShiftRollingSurface\']\n\n\nclass UpdateShiftRollingSurface(_TransientSubModelABC):\n    """\n    Shifts a RollingSurface at a set speed\n    """\n\n    def __init__(self, name: str, surface_to_roll: int, speed_x: float = 0.0, speed_y: float = 0.0,\n                 interpolation_mode=\'linear\'):\n        super().__init__(name, {"time_step"}, {f"current_shift_{surface_to_roll}"}, (speed_x, speed_y),\n                         (f\'{name}_shift_speed_x\', f\'{name}_shift_speed_y\'), interpolation_mode)\n        if surface_to_roll not in {1, 2}:\n            raise ValueError(f"Surface to roll should be either 1 or 2, got {surface_to_roll}")\n        self._surface_to_roll = surface_to_roll\n\n    def _check(self):\n        if self._surface_to_roll == 1:\n            if not hasattr(self.model.surface_1, "shift"):\n                raise ValueError(f"Sub model {self.name} requires the surface to roll to be a RollingSurface")\n        else:\n            if not hasattr(self.model.surface_2, "shift"):\n                raise ValueError(f"Sub model {self.name} requires the surface to roll to be a RollingSurface")\n\n    def _solve(self, current_state: dict, **kwargs) -> dict:\n\n        print(current_state[\'time_step\'])\n        distance_x = kwargs[f\'{self.name}_shift_speed_x\'] * current_state[\'time_step\']\n        distance_y = kwargs[f\'{self.name}_shift_speed_y\'] * current_state[\'time_step\']\n\n        if self._surface_to_roll == 1:\n            self.model.surface_1.shift(distance_y, distance_x)\n            cs = self.model.surface_1.current_shift\n        else:\n            self.model.surface_2.shift(distance_y, distance_x)\n            cs = self.model.surface_2.current_shift\n        return {f"current_shift_{self._surface_to_roll}": cs}\n', 'is_package': False},
    'slippy.contact.sub_models.sub_surface_stress': {'source': 'import numpy as np\nimport slippy\nfrom itertools import product\nfrom collections import defaultdict\nfrom slippy.core import _SubModelABC, plan_multi_convolve, _IMMaterial, get_derived_stresses\nfrom typing import Sequence, Union\n\n__all__ = [\'SubsurfaceStress\']\n\n\nclass SubsurfaceStress(_SubModelABC):\n    """A sub model for subsurface stresses in influence matrix based materials\n\n    Parameters\n    ----------\n    z: np.array[float], optional (None)\n        The depths of interest in the material, defaults to half the span with the same spacing as the surface\n        grid spacing\n    surface: int or Sequence[int], optional ((1,2))\n        The surfaces for which the stress components are to be calculated\n    name: str, optional (\'sub_surface_stress\')\n        The name of the sub model, used for debugging\n    load_components: str, optional (\'z\')\n        The components of the surface loads to include in the calculation, eg \'xz\' indicates the normal loads (\'z\') and\n        tangential tractions in the x direction will be superimposed. The sub model will require the loads in each of\n        these directions to be in the current state when the model is run.\n    stress_components: str or Sequence[str], optional (\'all\', )\n        The components of stress to be found. Valid entries are: Cauchy stress tensor components: \'xx\', \'yy\', \'zz\',\n        \'xy\', \'yz\', \'xz\'. Principal stresses: \'1\', \'2\', \'3\'. Or von misses stress: \'vm\'. The model will provide\n        the requested components in the state dictionary. Requesting any of the principal stresses or the von mises\n        stress will compute the full tensor, however the the tensor components will not be added to the state dict\n        unless they are also requested. \'all\' will compute all Cauchy stress tensor components, but no other components.\n    keep_kernels: bool, optional (True)\n         If True the kernels will be cached for faster computation, if False they are deleted and re computed every time\n         the sub model is called, this will add time to computations, but reduce memory requirements.\n    cuda_convolutions: bool, optional (False)\n        If True the computations will be carried out on the GPU (if cupy can be imported), This may result in faster\n        computations depending on hardware but kernels and results must be stored on GPU memory.\n\n    Notes\n    -----\n    Memory requirements for this sub model are large, if stress components are not required for further computations\n    it may be faster to compute them after the model has run.\n\n    This model will add values to the state dict: surface_a_y for each surface (a) and stress component (y) (all lower\n    case).\n\n    Each value added to the dict will have shape: (len(z), loads.shape) where loads.shape is the shape of the loads\n    array.\n\n    This sub model requires the relevent sub surface stress function to be implemented and working for the material.\n\n    Examples\n    --------\n    The sub model:\n    >>>SubsurfaceStress(surface=1, stress_components=\'svm\')\n    Will find the Von Mises stress on the master surface in the model (surface 1), this will add the key \'surface_1_svm\'\n    to the state dict.\n    """\n\n    def __init__(self, z: np.array = None, surface: Union[int, Sequence[int]] = (1, 2),\n                 name: str = \'sub_surface_stress\', periodic_axes: Sequence[bool] = (False, False),\n                 load_components: str = \'z\', stress_components: Union[str, Sequence[str]] = (\'all\',),\n                 keep_kernels: bool = True, cuda_convolutions: bool = False):\n        if isinstance(surface, int):\n            surface = (surface,)\n        if isinstance(stress_components, str):\n            stress_components = (stress_components,)\n        for lc in load_components:\n            if lc not in \'xz\':\n                raise ValueError(f"Unrecognised load direction: {lc}, valid directions are: x, z")\n        requires = set(\'loads_\' + c for c in load_components)\n        tensor_terms = (\'xx\', \'yy\', \'zz\', \'xy\', \'yz\', \'xz\')\n        valid_stresses = (\'xx\', \'yy\', \'zz\', \'xy\', \'yz\', \'xz\', \'1\', \'2\', \'3\', \'vm\')\n        if \'all\' in stress_components:\n            full_sc = set(tensor_terms)\n            full_sc.update(stress_components)\n            full_sc.remove(\'all\')\n            stress_components = full_sc\n        for sc in stress_components:\n            if sc not in valid_stresses:\n                raise ValueError(f"Unrecognised stress component: {sc}, valid components are: {valid_stresses}")\n        provides = set(\'surface_\' + str(s) + \'_\' + sc for s, sc in product(surface, stress_components))\n        super().__init__(name, requires, provides)\n        self.surfaces = surface\n        self.load_components = load_components\n        self.stress_components = stress_components\n        self.keep_kernels = keep_kernels\n        self.cuda_convolutions = cuda_convolutions\n        self._kernel_cache = {s: dict() for s in surface}\n        self._cache_span = (0, 0)\n        self.z = z\n        calc_all = any(s in stress_components for s in (\'1\', \'2\', \'3\', \'vm\'))\n        self.comps_to_find = tensor_terms if calc_all else stress_components\n        self.periodic_axes = periodic_axes\n\n    def solve(self, current_state: dict) -> dict:\n        if self.cuda_convolutions:\n            xp = slippy.xp\n        else:\n            xp = np\n        example_loads = current_state[\'loads_\' + self.load_components[0]]\n        span = tuple([s*(2-pa) for s, pa in zip(example_loads.shape, self.periodic_axes)])\n        if self.z is None:\n            z_len = min(example_loads.shape)//2\n        else:\n            z_len = len(self.z)\n        out_put_shape = (z_len,) + example_loads.shape\n\n        def default_factory():\n            return xp.zeros(out_put_shape)\n\n        for surface_num in self.surfaces:\n            surface = self.model.__getattribute__(\'surface_\' + str(surface_num))\n            material = surface.material\n            grid_spacing = [surface.grid_spacing, ] * 2\n            assert (isinstance(material, _IMMaterial)), \'Sub surface stress only valid for influence matrix based \' \\\n                                                        \'materials\'\n            intermediate_results = defaultdict(default_factory)\n            for l_comp in self.load_components:\n                if self.keep_kernels and span == self._cache_span and l_comp in self._kernel_cache[surface_num]:\n                    conv_funcs = self._kernel_cache[surface_num][l_comp]\n                else:\n                    args = (self.comps_to_find, grid_spacing, span, self.z, self.cuda_convolutions)\n                    if l_comp == \'z\':\n                        im_comps = material.sss_influence_matrices_normal(*args)\n                    elif l_comp == \'x\':\n                        im_comps = material.sss_influence_matrices_tangential_x(*args)\n                    elif l_comp == \'y\':\n                        im_comps = material.sss_influence_matrices_tangential_y(*args)\n                    else:\n                        raise ValueError(f"Unrecognised load component requested: {l_comp}")\n                    conv_funcs = {key: plan_multi_convolve(example_loads, value, None, self.periodic_axes,\n                                                           self.cuda_convolutions) for\n                                  key, value in im_comps.items()}\n                    if self.keep_kernels:\n                        self._cache_span = span\n                        self._kernel_cache[surface_num][l_comp] = conv_funcs\n\n                for key, conv_func in conv_funcs.items():\n                    loads = current_state[\'loads_\' + l_comp]\n                    if l_comp in \'xy\' and surface_num == 2:\n                        loads = loads*-1\n                    intermediate_results[key] += conv_func(loads)\n\n            # find other stress components\n            intermediate_results.update(get_derived_stresses(intermediate_results, self.stress_components, True))\n\n            for key in self.stress_components:\n                current_state[\'surface_\' + str(surface_num) + \'_\' + key] = intermediate_results[key]\n        return current_state\n', 'is_package': False},
    'slippy.contact.sub_models.tangential_partial_slip': {'source': 'import typing\nimport numpy as np\nimport slippy\nfrom ._TransientSubModelABC import _TransientSubModelABC\nfrom slippy.core.materials import _IMMaterial\nfrom slippy.core.influence_matrix_utils import bccg, plan_convolve\n# TODO add from_offset option to get the displacement from the offset\n\n\nclass TangentialPartialSlip(_TransientSubModelABC):\n    """ Solves the partial slip problem\n\n    Parameters\n    ----------\n    axis: int\n        The axis along which the displacement will be applied (0 or 1).\n    displacement: float or sequence of floats\n        The rigid body displacement between the parts. Suitable values are:\n            - float: indicating a constant displacement\n            - sequence of 2 values indicating the values at the start and end of the model step, intermediate values\n              will be linearly interpolated.\n            - 2 by n array: of time points and displacement values, intermediate values will be interpolated by the\n              method specified by the interpolation_mode parameter (defaults to linear)\n            - None\n        If an array is supplied and it is too short it is extrapolated by repeating the final value, this produces a\n        warning. If neither are supplied this sub-model requires rigid_body_displacement to be provided by a further\n        sub-model\n    periodic_axes: 2 element sequence of bool, optional (False, False)\n        True for each axis which the solution should be periodic in, should match solving step\n    tol: float, optional (1e-7)\n        The tolerance used to declare convergence for the bccg iterations\n    max_it: int, optional (None)\n        The maximum number of iterations for the bccg iterations, defaults to the same as the number of contact nodes\n    interpolation_mode: str, optional (\'linear\')\n        The interpolation mode used when a 2 by n array of values, can be any method compatible with scipy.interp1d\n    name: str, optional ("TangentialPartialSlip")\n        The name of the sub model, used for debugging and in the log file\n    """\n\n    def __init__(self, axis: int,\n                 displacement: typing.Optional[typing.Union[float, typing.Sequence]],\n                 periodic_axes: typing.Sequence[bool] = (False, False),\n                 tol: float = 1e-7, max_it: int = None, interpolation_mode: str = \'linear\',\n                 name: str = "TangentialPartialSlip"):\n\n        requires = {\'maximum_tangential_force\', \'contact_nodes\', \'time\'}\n        self.direction = \'x\' if axis else \'y\'\n        if displacement is None:\n            self.displacement_from_sub_model = True\n            displacement = 0.0\n            requires.add(\'rigid_body_displacement_\' + self.direction)\n        else:\n            self.displacement_from_sub_model = False\n        provides = {\'slip_distance\', \'stick_nodes\', f\'loads_{self.direction}\', f\'total_displacement_{self.direction}\'}\n        super().__init__(name, requires, provides, transient_names=[f\'rigid_body_displacement_{self.direction}\'],\n                         transient_values=[displacement],\n                         interpolation_mode=interpolation_mode)\n\n        self.component = self.direction * 2\n        self._last_span = None\n        self._pre_solve_checks = False\n        self._im_1 = None\n        self._im_2 = None\n        self._im_total = None\n        self._periodic_axes = periodic_axes\n        self._tol = tol\n        self._max_it = max_it\n        self.previous_result = None\n\n    def _check(self, span):\n        # check that both are im materials and store ims\n        if isinstance(self.model.surface_1.material, _IMMaterial) and \\\n           isinstance(self.model.surface_2.material, _IMMaterial):\n            im_1 = self.model.surface_1.material.influence_matrix([self.component],\n                                                                  [self.model.surface_1.grid_spacing] * 2,\n                                                                  span)[self.component]\n            im_2 = self.model.surface_2.material.influence_matrix([self.component],\n                                                                  [self.model.surface_1.grid_spacing] * 2,\n                                                                  span)[self.component]\n            self._im_1 = im_1\n            self._im_2 = im_2\n            self._im_total = im_1 + im_2\n            self._pre_solve_checks = True\n        else:\n            raise ValueError("This sub model only supports influence matrix based materials")\n\n    def _solve(self, current_state: dict, **kwargs) -> dict:\n        span = [(2-pa) * s for pa, s in zip(self._periodic_axes, current_state[\'maximum_tangential_force\'].shape)]\n\n        if not self._pre_solve_checks or span != self._last_span:\n            self._check(span)\n            self._last_span = span\n\n        domain = current_state[\'contact_nodes\']\n\n        conv_func = plan_convolve(current_state[\'maximum_tangential_force\'], self._im_total, domain,\n                                  circular=self._periodic_axes)\n        # if the displacements are provided by another sub model or we have a set displacement we just have one set\n        # of bccg iterations:\n        if self.displacement_from_sub_model:\n            displacement = current_state[\'rigid_body_displacement_\' + self.direction]\n        else:\n            displacement = kwargs[f\'rigid_body_displacement_{self.direction}\']\n\n        set_displacement = float(displacement)*np.ones(current_state[\'maximum_tangential_force\'].shape)\n\n        x0 = self.previous_result if self.previous_result is not None else \\\n            current_state[\'maximum_tangential_force\']/2\n        min_pressure = np.array(-1*current_state[\'maximum_tangential_force\'][domain])\n        loads_in_domain, failed = bccg(conv_func, set_displacement[domain], self._tol,\n                                       self._max_it, x0[domain],\n                                       min_pressure,\n                                       current_state[\'maximum_tangential_force\'][domain])\n        loads_in_domain = slippy.asnumpy(loads_in_domain)\n        full_loads = np.zeros_like(current_state[\'maximum_tangential_force\'])\n        full_loads[domain] = loads_in_domain\n        stick_nodes = np.logical_and(domain, full_loads < (0.99 * current_state[\'maximum_tangential_force\']))\n        rtn_dict = dict()\n        rtn_dict[\'stick_nodes\'] = stick_nodes\n        tangential_deformation = slippy.asnumpy(conv_func(loads_in_domain, True))\n        rtn_dict[\'loads_\' + self.component[0]] = full_loads\n\n        if \'total_displacement_\' + self.component[0] in current_state:\n            rtn_dict[\'total_displacement_\' + self.component[0]] += tangential_deformation\n        else:\n            rtn_dict[\'total_displacement_\' + self.component[0]] = tangential_deformation\n\n        slip_distance = set_displacement-tangential_deformation\n        slip_distance[stick_nodes] = 0\n        slip_distance[np.logical_not(domain)] = 0\n        rtn_dict[\'slip_distance\'] = slip_distance\n        return rtn_dict\n', 'is_package': False},
    'slippy.contact.sub_models.tangential_pure_sliding': {'source': 'import typing\nimport numpy as np\nfrom slippy.core import _SubModelABC\n\n__all__ = [\'TangentialPureSliding\']\n\n\nclass TangentialPureSliding(_SubModelABC):\n    """ Fill forces and displacements due to pure sliding\n\n    Parameters\n    ----------\n    name: str\n        The name of the sub model, used for debugging\n    direction: {str, tuple}, optional (\'x\')\n        The direction of the sliding motion, either \'x\' or \'y\' or a vector defining a direction, \'x\' is equivalent\n        to: (0, 1)\n\n    Notes\n    -----\n    This sub model fills the \'loads\' result with loads due to pure sliding in the specified direction\n\n    This requires the normal component of the loads to be found\n\n    """\n\n    def __init__(self, name: str, direction: typing.Union[str, typing.Tuple[float]] = \'x\'):\n        requires = {\'maximum_tangential_force\'}\n        provides = {\'loads_x\', \'loads_y\'}\n        if isinstance(direction, str):\n            direction = direction.lower()\n            if direction == \'x\':\n                direction = (0, 1)\n            elif direction == \'y\':\n                direction = (1, 0)\n            else:\n                raise ValueError("Direction can only be \'x\' or \'y\' or vector defining a direction")\n        try:\n            length = len(direction)\n        except TypeError:\n            raise TypeError(f"direction not recognised, must be two element sequence or \'x\' or \'y\', "\n                            f"received {type(direction)}")\n        if length != 2:\n            raise ValueError("Direction vector must be 2 element sequence")\n\n        direction = np.array(direction)\n        self.direction = direction / np.linalg.norm(direction)\n        super().__init__(name, requires, provides)\n\n    def solve(self, current_state: dict) -> dict:\n        lf = current_state[\'maximum_tangential_force\']\n        return {\'loads_x\': self.direction[1] * lf,\n                \'loads_y\': self.direction[0] * lf}\n', 'is_package': False},
    'slippy.contact.sub_models.tests.test_contact_stiffness': {'source': 'import numpy as np\nimport numpy.testing as npt\nimport slippy.surface as s\nimport slippy.contact as c\n\n\ndef test_contact_stiffness():\n    """\n    Test the contact stiffness sub model against a known analytical result\n    Also tests the example\n    """\n    diameter = 1\n    resolution = 512\n    x, y = np.meshgrid(np.linspace(-diameter, diameter, resolution),\n                       np.linspace(-diameter, diameter, resolution))\n    indenter_profile = np.array((x ** 2 + y ** 2) < (diameter / 2) ** 2, dtype=np.float32)\n    grid_spacing = x[1, 1] - x[0, 0]\n    indenter = s.Surface(profile=indenter_profile, grid_spacing=grid_spacing)\n    half_space = s.FlatSurface(shape=(resolution, resolution), grid_spacing=grid_spacing,\n                               generate=True)\n\n    indenter.material = c.rigid\n    e, v = 200e9, 0.3\n    half_space.material = c.Elastic(\'steel\', {\'E\': e, \'v\': v})\n    reduced_modulus = 1 / ((1 - v ** 2) / e)\n\n    my_model = c.ContactModel(\'Contact_stiffness_example\', half_space, indenter)\n\n    step = c.StaticStep(\'loading\', interference=1e-4, periodic_geometry=True)\n    sub_model = c.sub_models.ResultContactStiffness(\'stiffness\', definition=\'far points\',\n                                                    loading=False)\n    step.add_sub_model(sub_model)\n    my_model.add_step(step)\n\n    # we don\'t need to solve the contact model we already know what the contact nodes will be\n\n    contact_nodes = (x ** 2 + y ** 2) < (diameter / 2) ** 2\n\n    current_state = {\'contact_nodes\': contact_nodes,\n                     \'loads_z\': np.zeros_like(contact_nodes)}\n\n    results = sub_model.solve(current_state)\n\n    numerical_stiffness = results[\'s_contact_stiffness_unloading_fp_z_0\'] * (2 * diameter) ** 2\n    analytical_stiffness = reduced_modulus * diameter\n\n    npt.assert_approx_equal(numerical_stiffness, analytical_stiffness, 2)\n', 'is_package': False},
    'slippy.contact.sub_models.tests.test_shift_surface': {'source': 'import numpy as np\nimport numpy.testing as npt\nimport slippy.surface as s\nimport slippy.contact as c\n\n\ndef test_shift_surface():\n    n = 10\n    flat1 = s.FlatSurface(shape=(n, n), grid_spacing=1, generate=True)\n    flat2 = s.FlatSurface(shape=(n, n), grid_spacing=1, generate=True)\n    roughness = s.FlatSurface(shape=(n, 2 * n), grid_spacing=1, generate=True)\n    rolling = s.RollingSurface(roughness, flat2)\n\n    model = c.ContactModel(\'test_mod\', rolling, flat1)\n\n    state = {"contact_nodes": np.ones(shape=(n, n)),\n             \'time_step\': 1.0,\n             \'surface_1_points\': rolling.get_points_from_extent(),\n             \'surface_2_points\': flat1.get_points_from_extent()}\n    step = c.RepeatingStateStep(\'\', time_steps=n, state=state)\n    model.add_step(step)\n\n    ct = c.sub_models.ResultContactTime(\'\', False)\n    shift = c.sub_models.UpdateShiftRollingSurface(\'\', 1, 1)\n    step.add_sub_model(ct)\n    step.add_sub_model(shift)\n\n    result = model.solve(skip_data_check=True)\n    npt.assert_array_equal(result[\'contact_time_1\'][0], np.flip(np.arange(1, 11)))\n    npt.assert_array_equal(result[\'contact_time_2\'], n * np.ones_like(result[\'contact_time_2\']))\n\n\ndef test_shift_surface_wrap():\n    n = 10\n    flat1 = s.FlatSurface(shape=(n, n), grid_spacing=1, generate=True)\n    flat2 = s.FlatSurface(shape=(n, n), grid_spacing=1, generate=True)\n    roughness = s.FlatSurface(shape=(n, 2 * n), grid_spacing=1, generate=True)\n    rolling = s.RollingSurface(roughness, flat2)\n\n    model = c.ContactModel(\'test_mod\', rolling, flat1)\n\n    state = {"contact_nodes": np.ones(shape=(n, n)),\n             \'time_step\': 1.0,\n             \'surface_1_points\': rolling.get_points_from_extent(),\n             \'surface_2_points\': flat1.get_points_from_extent()}\n    step = c.RepeatingStateStep(\'\', time_steps=n, state=state)\n    model.add_step(step)\n\n    ct = c.sub_models.ResultContactTime(\'\', False)\n    shift = c.sub_models.UpdateShiftRollingSurface(\'\', 1, 0.0, 1)\n    step.add_sub_model(ct)\n    step.add_sub_model(shift)\n\n    result = model.solve(skip_data_check=True)\n    npt.assert_array_equal(result[\'contact_time_1\'], n * np.ones((n, n)))\n    npt.assert_array_equal(result[\'contact_time_2\'], n * np.ones((n, n)))\n', 'is_package': False},
    'slippy.contact.unified_reynolds_solver': {'source': 'import typing\nfrom numba import njit\nimport numpy as np\nfrom ._lubrication_utils import tdma\n\nfrom slippy.core import _NonDimensionalReynoldSolverABC\n\n__all__ = [\'UnifiedReynoldsSolver\']\n\n\nclass UnifiedReynoldsSolver(_NonDimensionalReynoldSolverABC):\n    # noinspection SpellCheckingInspection\n    """\n        The unified reynolds solver for use in lubrication steps\n\n        Parameters\n        ----------\n        time_step: float\n            The dimentional time step for the calculation in seconds, minutes ... etc.\n        grid_spacing: float\n            The dimentional grid spacing of the master surface\n        hertzian_pressure: float\n            The static hertzian pressure of the contact, or any other representative pressure, this is used only to\n            non-dimentionalise the problem\n        radius_in_rolling_direction: float\n            The radius of the ball or dic in the rolling direction, again this is just used to non-dimentionalise the\n            problem, if it is not known a different representative length can be used\n        hertzian_half_width: float\n            The hertzian half width of the contact, this is used to non-dimentionalise the problem, if this is not known\n            another representative length can be used\n        dimentional_viscosity:float\n            The viscosity used to non-dimentionalise the problem, usually the viscosity when the pressure is 0.\n        dimentional_density: float\n            The density used to non-dimentionalise the problem, usually the density when the pressure is 0.\n        sweep_direction: str {\'forward\', \'backward\'}, optional (\'forward\')\n            The direction which the reynolds solver moves through the pressure array.\n        periodic: bool, optional (False)\n            Controls if the pressure soltuion is periodic or not, if it is, the material deformation solution must also\n            be periodic for proper results, this shoudl be set by the model step. This feature is experimental.\n\n        Attributes\n        ----------\n\n        time_step\n            The dimentionalised time step\n        nd_time_step: read only\n            The non dimentionalised time step\n        grid_spacing: read only\n            The dimentionalised grid spacing\n        nd_grid_spacing: read only\n            The non dimentionalised grid spacing\n        lambda_bar: read only\n            The lambda parameter for the problem\n        rolling_speed\n            The mean speed of the surfaces (u1+u2)/2\n        hertzian_pressure\n            The non dimentionalising pressure\n        hertzian_half_width\n            The non dimentionalising length\n\n        See Also\n        --------\n        IterSemiSystemLoad - semi system iteration lubrication step\n\n        Notes\n        -----\n        The units used for the input values do not matter but they must be consistent. eg if the time step is in seconds\n        and the hertzian half width is in meters the rolling speed must be in meters/second\n\n        Values for rolling speed and non dimentionalising values can be updated by the user or the step\n\n        Examples\n        --------\n        #TODO\n\n        References\n        ----------\n        Azam, A., Dorgham, A., Morina, A., Neville, A., & Wilson, M. C. T. (2019). A simple deterministic\n        plastoelastohydrodynamic lubrication (PEHL) model in mixed lubrication. Tribology International,\n        131(November 2018), 520–529. https://doi.org/10.1016/j.triboint.2018.11.011\n        """\n    requires = {\'nd_gap\', \'nd_pressure\', \'nd_viscosity\', \'nd_density\'}\n    provides = {\'nd_pressure\', \'previous_nd_gap\', \'previous_nd_density\'}\n    _row_order = None  # order the rows will be solved in, controlled by the sweep direction\n\n    _hertzian_pressure: float = None\n    _hertzian_half_width: float = None\n    _dimentional_viscosity: float = None\n    _dimentional_density: float = None\n    _rolling_speed: typing.Optional[float] = None\n    _lambda_bar: typing.Optional[float] = None\n    _radius: float = None\n\n    def __init__(self, time_step: float,\n                 grid_spacing: float,\n                 hertzian_pressure: float,\n                 radius_in_rolling_direction: float,\n                 hertzian_half_width: float,\n                 dimentional_viscosity: float,\n                 dimentional_density: float,\n                 sweep_direction: str = \'backward\',\n                 periodic: bool = False):\n        # these automatically calculate the non dimentional versions\n        self.grid_spacing = grid_spacing\n        self.time_step = time_step\n        self.periodic = periodic\n        # find lambda bar (all of these are properties apart from dimentional_density)\n        self.radius = radius_in_rolling_direction\n        self.hertzian_pressure = hertzian_pressure\n        self.hertzian_half_width = hertzian_half_width\n        self.dimentional_viscosity = dimentional_viscosity\n        self.dimentional_density = dimentional_density\n        self.rolling_speed = None\n\n        # get first 3 components of influence matrix\n        def stencil(x, y):\n            return x + np.sqrt(x ** 2 + y ** 2)\n\n        ak = np.zeros((3,))\n\n        for i in range(3):\n            xp = i + 0.5\n            xm = i - 0.5\n            ym = -0.5\n            yp = 0.5\n            a1 = stencil(yp, xp) / stencil(ym, xp)\n            a2 = stencil(xm, ym) / stencil(xp, ym)\n            a3 = stencil(ym, xm) / stencil(yp, xm)\n            a4 = stencil(xp, yp) / stencil(xm, yp)\n            ak[i] = xp * np.log(a1) + ym * np.log(a2) + xm * np.log(a3) + yp * np.log(a4)\n\n        self.ak00 = 2 / np.pi ** 2 * ak[0]\n        self.ak10 = 2 / np.pi ** 2 * ak[1]\n        self.ak20 = 2 / np.pi ** 2 * ak[2]\n\n        if sweep_direction == \'forward\':\n            self._step = 1\n        elif sweep_direction == \'backward\':\n            self._step = -1\n        else:\n            raise ValueError(f"Unrecognised sweep direction: {sweep_direction}")\n\n    @property\n    def nd_grid_spacing(self):\n        return self.grid_spacing / self.hertzian_half_width\n\n    @property\n    def nd_time_step(self):\n        return self.time_step * self.rolling_speed / self.hertzian_half_width\n\n    @property  # Lambda bar cannot be set directly\n    def lambda_bar(self):\n        if self._lambda_bar is not None:\n            return self._lambda_bar\n        else:\n            self._lambda_bar = (12 * self.rolling_speed * self.dimentional_viscosity * self.radius ** 2 /\n                                (self.hertzian_half_width ** 3 * self.hertzian_pressure))\n            return self._lambda_bar\n\n    # properties for everything that would change lambda bar if it changed\n    @property\n    def hertzian_pressure(self):\n        return self._hertzian_pressure\n\n    @hertzian_pressure.setter\n    def hertzian_pressure(self, value):\n        self._hertzian_pressure = value\n        self._lambda_bar = None\n\n    @property\n    def hertzian_half_width(self):\n        return self._hertzian_half_width\n\n    @hertzian_half_width.setter\n    def hertzian_half_width(self, value):\n        self._hertzian_half_width = value\n        self._lambda_bar = None\n\n    @property\n    def dimentional_viscosity(self):\n        return self._dimentional_viscosity\n\n    @dimentional_viscosity.setter\n    def dimentional_viscosity(self, value):\n        self._dimentional_viscosity = value\n        self._lambda_bar = None\n\n    @property\n    def rolling_speed(self):\n        return self._rolling_speed\n\n    @rolling_speed.setter\n    def rolling_speed(self, value):\n        self._rolling_speed = value\n        self._lambda_bar = None\n\n    @property\n    def radius(self):\n        return self._radius\n\n    @radius.setter\n    def radius(self, value):\n        self._radius = value\n        self._lambda_bar = None\n\n    def data_check(self, previous_state: set) -> set:\n        for requirement in self.requires:\n            if requirement not in previous_state:\n                raise ValueError(f"Unified reynolds solver requires {requirement}, but this is not provided by the "\n                                 "step")\n        previous_state = set(self.provides)\n        return previous_state\n\n    def solve(self, previous_state: dict, max_pressure: float) -> dict:\n        # rumble\n        nd_gap = previous_state[\'nd_gap\']\n        width, length = nd_gap.shape\n        pressure = previous_state[\'nd_pressure\'].copy()\n        current_state = dict()\n\n        if \'previous_nd_density\' not in previous_state:  # first time step\n            previous_state[\'previous_nd_density\'] = previous_state[\'nd_density\']\n            previous_state[\'previous_nd_gap\'] = previous_state[\'nd_gap\']\n\n        # These values are from the last time step not the last iteration\n        current_state[\'previous_nd_density\'] = previous_state[\'previous_nd_density\']\n        current_state[\'previous_nd_gap\'] = previous_state[\'previous_nd_gap\']\n\n        # pre calculate some values to save time\n        recip_dx_squared_rho = 1 / (self.nd_grid_spacing ** 2 * previous_state[\'nd_density\'])\n        recip_dx = 1 / self.nd_grid_spacing\n        recip_dt = 1 / self.nd_time_step if self.nd_time_step else 0.0\n\n        epsilon = self._get_epsilon(previous_state)\n\n        # sort out the row order\n        if not self._row_order:\n            if self._step == 1:\n                self._row_order = [1, length - 1]\n            elif self._step == -1:\n                self._row_order = [length - 2, 0]\n            else:\n                raise ValueError("Row step must be -1 or 1")\n            if self.periodic:\n                self._row_order[0] = self._row_order[0] - self._step\n                self._row_order[1] = self._row_order[1] + self._step\n\n        ak00 = self.ak00\n        ak10 = self.ak10\n        ak20 = self.ak20\n\n        nd_density = previous_state[\'nd_density\']\n        previous_nd_density = previous_state[\'previous_nd_density\']\n        previous_nd_gap = previous_state[\'previous_nd_gap\']\n\n        #  if self.periodic:\n        # a_all, c_all = np.zeros_like(epsilon[:, 0]), np.zeros_like(epsilon[:, 0])\n        # b_all, f_all = np.ones_like(epsilon[:, 0]), np.zeros_like(epsilon[:, 0])\n        # for row in range(self._row_order[0]-self._step, self._row_order[1]+self._step, self._step):\n        #     a_all, b_all, c_all, f_all = _solve_row_cyclic(epsilon, row, pressure, recip_dx_squared_rho, recip_dx,\n        #                                                    recip_dt, a_all, b_all, c_all, f_all, ak00, ak10, ak20,\n        #                                                    nd_gap, nd_density, previous_nd_density, previous_nd_gap)\n        #\n        #     p1d = cyclic_tdma(a_all, b_all, c_all, f_all)\n        #     #p1d = np.clip(raw_pressure, 0, max_pressure)\n        #\n        #     pressure[:, row] = p1d[:]\n        #\n        # solve line by line\n\n        a_all, c_all = np.zeros_like(epsilon[:-1, 0]), np.zeros_like(epsilon[:-1, 0])\n        b_all, f_all = np.ones_like(epsilon[:, 0]), np.zeros_like(epsilon[:, 0])\n\n        for row in range(self._row_order[0], self._row_order[1], self._step):\n            a_all, b_all, c_all, f_all = _solve_row(epsilon, row, pressure, recip_dx_squared_rho, recip_dx,\n                                                    recip_dt, a_all, b_all, c_all, f_all, ak00, ak10, ak20, nd_gap,\n                                                    nd_density, previous_nd_density, previous_nd_gap)\n\n            p1d = np.clip(tdma(a_all, b_all, c_all, f_all), 0, max_pressure)\n\n            pressure[1:-1, row] = p1d[1:-1]\n\n        current_state[\'nd_pressure\'] = pressure\n\n        return current_state\n\n    def _get_epsilon(self, previous_state: dict) -> np.ndarray:\n        nd_gap = previous_state[\'nd_gap\']\n        epsilon = previous_state[\'nd_density\'] * nd_gap ** 3 / previous_state[\'nd_viscosity\'] * (1 / self.lambda_bar)\n        epsilon[nd_gap < self.dimensionalise_gap(0.47e-9, True)] = 0\n        return epsilon\n\n    def dimensionalise_pressure(self, nd_pressure, un_dimensionalise: bool = False):\n        if un_dimensionalise:\n            return nd_pressure / self.hertzian_pressure\n        return nd_pressure * self.hertzian_pressure\n\n    def dimensionalise_viscosity(self, nd_viscosity, un_dimensionalise: bool = False):\n        if un_dimensionalise:\n            return nd_viscosity / self.dimentional_viscosity\n        return nd_viscosity * self.dimentional_viscosity\n\n    def dimensionalise_density(self, nd_density, un_dimensionalise: bool = False):\n        if un_dimensionalise:\n            return nd_density / self.dimentional_density\n        return nd_density * self.dimentional_density\n\n    def dimensionalise_gap(self, nd_gap, un_dimensionalise: bool = False):\n        if un_dimensionalise:\n            return self.radius / self.hertzian_half_width ** 2 * nd_gap\n        return self.hertzian_half_width ** 2 / self.radius * nd_gap\n\n    def dimensionalise_length(self, nd_length, un_dimensionalise: bool = False):\n        if un_dimensionalise:\n            return nd_length / self.hertzian_half_width\n        return nd_length * self.hertzian_half_width\n\n\n@njit\ndef _solve_row(epsilon, row, pressure, recip_dx_squared_rho, recip_dx, recip_dt, a_all, b_all, c_all, f_all,\n               ak00, ak10, ak20, nd_gap, nd_density, previous_nd_density, previous_nd_gap):\n    row_plus_1 = row + 1 if (row + 1) < len(epsilon[0, :]) else 0\n    d1 = 0.5 * (epsilon[1:-1, row] + epsilon[0:-2, row])\n    d2 = 0.5 * (epsilon[1:-1, row] + epsilon[2:, row])\n    d4 = 0.5 * (epsilon[1:-1, row] + epsilon[1:-1, row - 1])\n    d5 = 0.5 * (epsilon[1:-1, row] + epsilon[1:-1, row_plus_1])\n    d3 = d1 + d2 + d4 + d5\n\n    q1 = ak10 * pressure[0:-2, row] + ak00 * pressure[1:-1, row] + ak10 * pressure[2:, row]\n    q2 = ak00 * pressure[0:-2, row] + ak10 * pressure[1:-1, row] + ak20 * pressure[2:, row]\n\n    # Pressure flow terms\n    a_p = d1 * recip_dx_squared_rho[1:-1, row]\n    b_p = -d3 * recip_dx_squared_rho[1:-1, row]\n    c_p = d2 * recip_dx_squared_rho[1:-1, row]\n    f_p = -(d5 * pressure[1:-1, row_plus_1] + d4 * pressure[1:-1, row - 1]) * recip_dx_squared_rho[1:-1, row]\n\n    # Wedge flow terms\n    a_w = (ak00 - ak10) * recip_dx\n    b_w = (ak10 - ak00) * recip_dx\n    c_w = (ak20 - ak10) * recip_dx\n    f_w = (((nd_gap[1:-1, row] - q1) - (nd_gap[0:-2, row] - q2)) * recip_dx +\n           nd_gap[1:-1, row] * (1 - (nd_density[0:-2, row] / nd_density[1:-1, row])) * recip_dx)  # +\n    # recip_dx * (nd_gap[1:-1, row] - nd_gap[0:-2, row]))  # these two gaps were roughness in fortran code\n\n    # squeeze flow terms\n    a_s = -1 * ak10 * recip_dt\n    b_s = -1 * ak00 * recip_dt\n    c_s = -1 * ak10 * recip_dt\n    f_s = ((nd_gap[1:-1, row] - q1) - (previous_nd_density[1: -1, row] / nd_density[1:-1, row]) *\n           previous_nd_gap[1: -1, row]) * recip_dt\n\n    # add and apply boundary conditions here (a[-1] = c[0] = f[0 and -1] = 0, b[0 and -1] = 1)\n    a_all[:-1] = a_p + a_s + a_w\n    b_all[1:-1] = b_p + b_s + b_w\n    c_all[1:] = c_p + c_s + c_w\n    f_all[1:-1] = f_p + f_s + f_w\n\n    return a_all, b_all, c_all, f_all\n\n\n@njit\ndef _solve_row_cyclic(epsilon, row, pressure, recip_dx_squared_rho, recip_dx, recip_dt, a_all, b_all, c_all, f_all,\n                      ak00, ak10, ak20, nd_gap, nd_density, previous_nd_density, previous_nd_gap):\n    row_plus_1 = row + 1 if (row + 1) <= len(epsilon[0, :]) else 0\n    d1 = 0.5 * (epsilon[:, row] + np.roll(epsilon[:, row], 1))\n    d2 = 0.5 * (epsilon[:, row] + np.roll(epsilon[:, row], -1))\n    d4 = 0.5 * (epsilon[:, row] + epsilon[:, row - 1])\n    d5 = 0.5 * (epsilon[:, row] + epsilon[:, row_plus_1])\n    d3 = d1 + d2 + d4 + d5\n\n    q1 = ak10 * np.roll(pressure[:, row], 1) + ak00 * pressure[:, row] + ak10 * np.roll(pressure[:, row], -1)\n    q2 = ak00 * np.roll(pressure[:, row], 1) + ak10 * pressure[:, row] + ak20 * np.roll(pressure[:, row], -1)\n\n    # Pressure flow terms\n    a_p = d1 * recip_dx_squared_rho[:, row]\n    b_p = -d3 * recip_dx_squared_rho[:, row]\n    c_p = d2 * recip_dx_squared_rho[:, row]\n    f_p = -(d5 * pressure[:, row_plus_1] + d4 * pressure[:, row - 1]) * recip_dx_squared_rho[:, row]\n\n    # Wedge flow terms\n    a_w = (ak00 - ak10) * recip_dx\n    b_w = (ak10 - ak00) * recip_dx\n    c_w = (ak20 - ak10) * recip_dx\n    f_w = (((nd_gap[:, row] - q1) - (np.roll(nd_gap[:, row], 1) - q2)) * recip_dx +\n           nd_gap[:, row] * (1 - (np.roll(nd_density[:, row], 1) / nd_density[:, row])) * recip_dx)  # +\n    # recip_dx * (nd_gap[1:-1, row] - nd_gap[0:-2, row]))  # these two gaps were roughness in fortran code\n\n    # squeeze flow terms\n    a_s = -1 * ak10 * recip_dt\n    b_s = -1 * ak00 * recip_dt\n    c_s = -1 * ak10 * recip_dt\n    f_s = ((nd_gap[:, row] - q1) - (previous_nd_density[:, row] / nd_density[:, row]) *\n           previous_nd_gap[:, row]) * recip_dt\n\n    # add and apply boundary conditions here (a[-1] = c[0] = f[0 and -1] = 0, b[0 and -1] = 1)\n    a_all[:] = a_p + a_s + a_w\n    b_all[:] = b_p + b_s + b_w\n    c_all[:] = c_p + c_s + c_w\n    f_all[:] = f_p + f_s + f_w\n\n    return a_all, b_all, c_all, f_all\n', 'is_package': False},
    'slippy.core': {'source': '"""\nMinimal abstract base classes and core functionality to avoid circular imports while type checking\n"""\n\nfrom .abcs import (_SurfaceABC, _AdhesionModelABC, _MaterialABC, _StepABC, _FrictionModelABC, _WearModelABC,\n                   _ACFABC, _LubricantModelABC, _ContactModelABC, _ReynoldsSolverABC,\n                   _NonDimensionalReynoldSolverABC, _SubModelABC)\nfrom .materials import _IMMaterial, Rigid, rigid\nfrom .elastic_material import Elastic, elastic_influence_matrix_spatial, elastic_influence_matrix_frequency, \\\n    get_angular_velocity\nfrom .influence_matrix_utils import bccg, plan_convolve, guess_loads_from_displacement, plan_multi_convolve, \\\n    plan_coupled_convolve, polonsky_and_keer, rey, ConvolutionFunction\nfrom .outputs import OutputReader, OutputRequest, OutputSaver, read_output\nfrom ._stress_utils import get_derived_stresses, solve_cubic\nfrom .gmres import gmres\n\n\n__all__ = [\'_SurfaceABC\', \'_AdhesionModelABC\', \'_MaterialABC\', \'_StepABC\', \'_FrictionModelABC\', \'_WearModelABC\',\n           \'_ACFABC\', \'_LubricantModelABC\', \'_ContactModelABC\', \'_ReynoldsSolverABC\',\n           \'_NonDimensionalReynoldSolverABC\', \'_SubModelABC\', \'_IMMaterial\', \'Rigid\', \'rigid\', \'Elastic\',\n           \'bccg\', \'plan_convolve\', \'OutputReader\', \'OutputRequest\', \'OutputSaver\', \'guess_loads_from_displacement\',\n           \'elastic_influence_matrix_spatial\', \'elastic_influence_matrix_frequency\', \'get_angular_velocity\',\n           \'read_output\', \'plan_multi_convolve\', \'plan_coupled_convolve\', \'ConvolutionFunction\', \'rey\',\n           \'get_derived_stresses\', \'polonsky_and_keer\', \'gmres\', \'solve_cubic\']\n', 'is_package': True},
    'slippy.core._elastic_sub_surface_stresses': {'source': '"""\nSub surface stresses for elastic materials from love and lee\n"""\nimport numpy as np\nimport slippy\nfrom collections.abc import Sequence\n\n__all__ = [\'normal_conv_kernels\', \'tangential_conv_kernels\']\n\n\ndef normal_derivative_terms(x, y, z, grid_spacing, cuda):\n    if cuda:\n        xp = slippy.xp\n    else:\n        xp = np\n    a = grid_spacing[1] / 2\n    b = grid_spacing[0] / 2\n    a1 = xp.sqrt((y - b) ** 2 + (x - a) ** 2 + z ** 2)\n    b2 = xp.sqrt((y - b) ** 2 + (x + a) ** 2 + z ** 2)\n    c3 = xp.sqrt((y + b) ** 2 + (x + a) ** 2 + z ** 2)\n    d4 = xp.sqrt((y + b) ** 2 + (x - a) ** 2 + z ** 2)\n    chi_x_x = (xp.arctan((b - y) / (a - x)) + xp.arctan((b + y) / (a - x))\n               - xp.arctan(z * (b - y) / (a1 * (a - x))) - xp.arctan(z * (b + y) / (d4 * (a - x))) +\n               xp.arctan((b - y) / (a + x)) + xp.arctan((b + y) / (a + x))\n               - xp.arctan(z * (b - y) / (b2 * (a + x))) - xp.arctan(z * (b + y) / (c3 * (a + x))))\n    chi_y_y = (xp.arctan((a - x) / (b - y)) + xp.arctan((a + x) / (b - y))\n               - xp.arctan(z * (a - x) / (a1 * (b - y))) - xp.arctan(z * (a + x) / (b2 * (b - y))) +\n               xp.arctan((a - x) / (b + y)) + xp.arctan((a + x) / (b + y))\n               - xp.arctan(z * (a - x) / (d4 * (b + y))) - xp.arctan(z * (a + x) / (c3 * (b + y))))\n    z_2 = z ** 2\n    vee_z = -(2 * xp.pi\n              - xp.arccos(((a - x) * (b - y)) * ((a - x) ** 2 + z_2) ** -0.5 * ((b - y) ** 2 + z_2) ** -0.5)\n              - xp.arccos(((a - x) * (b + y)) * ((a - x) ** 2 + z_2) ** -0.5 * ((b + y) ** 2 + z_2) ** -0.5)\n              - xp.arccos(((a + x) * (b - y)) * ((a + x) ** 2 + z_2) ** -0.5 * ((b - y) ** 2 + z_2) ** -0.5)\n              - xp.arccos(((a + x) * (b + y)) * ((a + x) ** 2 + z_2) ** -0.5 * ((b + y) ** 2 + z_2) ** -0.5))\n    chi_x_y = xp.log(((z + a1) * (z + c3)) / ((z + b2) * (z + d4)))\n    vee_x_x = -((a - x) / ((a - x) ** 2 + z_2) * ((b - y) / a1 + (b + y) / d4) +\n                (a + x) / ((a + x) ** 2 + z_2) * ((b - y) / b2 + (b + y) / c3))\n    vee_y_y = -((b - y) / ((b - y) ** 2 + z_2) * ((a - x) / a1 + (a + x) / b2) +\n                (b + y) / ((b + y) ** 2 + z_2) * ((a - x) / d4 + (a + x) / c3))\n    vee_z_z = -vee_x_x - vee_y_y\n    vee_x_z = z / ((a - x) ** 2 + z_2) * ((b - y) / a1 + (b + y) / d4) - z / ((a + x) ** 2 + z_2) * (\n        (b - y) / b2 + (b + y) / c3)\n    vee_y_z = z / ((b - y) ** 2 + z_2) * ((a - x) / a1 + (a + x) / b2) - z / ((b + y) ** 2 + z_2) * (\n        (a - x) / d4 + (a + x) / c3)\n    vee_x_y = 1 / a1 + 1 / c3 - 1 / b2 - 1 / d4\n    return chi_x_x, chi_y_y, chi_x_y, vee_z, vee_x_x, vee_y_y, vee_z_z, vee_x_z, vee_y_z, vee_x_y\n\n\ndef normal_conv_kernels(span, z, grid_spacing, young, v, cuda=False) -> dict:\n    """Get the convolution kernels for the subsurface stresses cause by a normal load in an elastic material\n\n    Parameters\n    ----------\n    span: Sequence[int, int]\n        The span of the convolution kernels in the y and x directions\n    z: Sequence[float]\n        The heights of interest in the solid\n    grid_spacing: Sequence[float, float] or float\n        Either a two element sequence of floats, giving the grid spacing in each direction or, a single value,\n        indicating a square grid\n    young: float\n        The Young\'s modulus of the material\n    v: float\n        The Poisson\'s ratio of the material\n    cuda: bool, optional (False)\n        If True kernels will be made on the GPU\n\n    Returns\n    -------\n    dict with keys: sxx, syy, szz, sxy, syz, sxz\n        The influence matrices for each of the stress components, numpy arrays if cuda is set to false or cupy could not\n        be imported else cupy arrays\n\n    References\n    ----------\n    A. E. H., L. (1929). The stress produced in a semi-infinite solid by pressure on part of the boundary. Philosophical\n    Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character,\n    228(659–669), 377–420. https://doi.org/10.1098/rsta.1929.0009\n    """\n    if not isinstance(grid_spacing, Sequence):\n        grid_spacing = (grid_spacing, grid_spacing)\n    if len(grid_spacing) == 1:\n        grid_spacing = (grid_spacing[0], grid_spacing[0])\n    if len(grid_spacing) != 2:\n        raise ValueError("Grid spacing should be a number or two element sequence")\n\n    if cuda:\n        xp = slippy.xp\n    else:\n        xp = np\n\n    x = grid_spacing[1] * (xp.arange(span[1]) - span[1] // 2 + (1 - span[1] % 2))\n    y = grid_spacing[0] * (xp.arange(span[0]) - span[0] // 2 + (1 - span[0] % 2))\n    x = x.reshape((1, 1, -1))\n    y = y.reshape((1, -1, 1))\n    z = xp.array(z).reshape((-1, 1, 1))\n    chi_x_x, chi_y_y, chi_x_y, vee_z, vee_x_x, vee_y_y, vee_z_z, \\\n        vee_x_z, vee_y_z, vee_x_y = normal_derivative_terms(x, y, z, grid_spacing, cuda)\n    shear = young / (2 * (1 + v))\n    lam = young * v / ((1 + v) * (1 - 2 * v))\n    sxx = 1 / (2 * xp.pi) * (lam / (lam + shear) * vee_z - shear / (lam + shear) * chi_x_x - z * vee_x_x)\n    syy = 1 / (2 * xp.pi) * (lam / (lam + shear) * vee_z - shear / (lam + shear) * chi_y_y - z * vee_y_y)\n    szz = 1 / (2 * xp.pi) * (vee_z - z * vee_z_z)\n    syz = -1 / (2 * xp.pi) * z * vee_y_z\n    sxz = -1 / (2 * xp.pi) * z * vee_x_z\n    sxy = -1 / (2 * xp.pi) * (shear / (lam + shear) * chi_x_y + z * vee_x_y)\n    return {\'xx\': sxx, \'yy\': syy, \'zz\': szz, \'xy\': sxy, \'yz\': syz, \'xz\': sxz}\n\n\ndef tangential_derivative_terms(x, y, z, grid_spacing, cuda):\n    if cuda:\n        xp = slippy.xp\n    else:\n        xp = np\n    a = grid_spacing[1] / 2\n    b = grid_spacing[0] / 2\n    x1 = -a - x\n    x2 = a - x\n    y1 = -b - y\n    y2 = b - y\n    z2 = z ** 2\n    rho1 = xp.sqrt(x1 ** 2 + y1 ** 2 + z2)\n    rho2 = xp.sqrt(x1 ** 2 + y2 ** 2 + z2)\n    rho3 = xp.sqrt(x2 ** 2 + y1 ** 2 + z2)\n    rho4 = xp.sqrt(x2 ** 2 + y2 ** 2 + z2)\n    f_x_z = xp.log(rho3 + y1) + xp.log(rho2 + y2) - xp.log(rho1 + y1) - xp.log(rho4 + y2)\n    f_x_x_x = (y2 / (x2 ** 2 + y2 ** 2) - y1 / (x2 ** 2 + y1 ** 2) - y2 / (x1 ** 2 + y2 ** 2) + y1 / (x1 ** 2 + y1 ** 2)\n               - z * y2 * (rho4 ** 2 + x2 ** 2) / (rho4 * (y2 ** 2 * z2 + x2 ** 2 * rho4 ** 2))\n               + z * y1 * (rho3 ** 2 + x2 ** 2) / (rho3 * (y1 ** 2 * z2 + x2 ** 2 * rho3 ** 2))\n               + z * y2 * (rho2 ** 2 + x1 ** 2) / (rho2 * (y2 ** 2 * z2 + x1 ** 2 * rho2 ** 2))\n               - z * y1 * (rho1 ** 2 + x1 ** 2) / (rho1 * (y1 ** 2 * z2 + x1 ** 2 * rho1 ** 2)))\n    f1_x_x_x = (z * f_x_x_x\n                + xp.log((rho4 + y2) * (rho1 + y1) / ((rho2 + y2) * (rho3 + y1)))\n                + x2 ** 2 * (1 / (rho4 * (rho4 + y2)) - 1 / (rho3 * (rho3 + y1)))\n                - x1 ** 2 * (1 / (rho2 * (rho2 + y2)) - 1 / (rho1 * (rho1 + y1))))  # corrected from paper\n    f1_x_y_y = y2 / (rho4 + z) - y1 / (rho3 + z) - y2 / (rho2 + z) + y1 / (rho1 + z)\n    f1_x_x_y = x2 / (rho4 + z) - x1 / (rho2 + z) - x2 / (rho3 + z) + x1 / (rho1 + z)  # corrected from paper\n    f_x_y_y = -y2 / (rho4 * (rho4 + z)) + y1 / (rho3 * (rho3 + z)) + y2 / (rho2 * (rho2 + z)) - y1 / (rho1 * (rho1 + z))\n    f_x_x_y = -x2 / (rho4 * (rho4 + z)) + x1 / (rho2 * (rho2 + z)) + x2 / (rho3 * (rho3 + z)) - x1 / (\n        rho1 * (rho1 + z))  # corrected from paper\n    f_x_z_z = -z / (rho4 * (rho4 + y2)) + z / (rho3 * (rho3 + y1)) + z / (rho2 * (rho2 + y2)) - z / (rho1 * (rho1 + y1))\n    f_x_x_z = x2 / (rho4 * (rho4 + y2)) - x2 / (rho3 * (rho3 + y1)) - x1 / (rho2 * (rho2 + y2)) + x1 / (\n        rho1 * (rho1 + y1))\n    f_z_y = -xp.log(rho4 + x2) + xp.log(rho3 + x2) + xp.log(rho2 + x1) - xp.log(rho1 + x1)\n    f_z_z = (-xp.arctan(x2 * y2 / (z * rho4)) + xp.arctan(x2 * y1 / (z * rho3))\n             + xp.arctan(x1 * y2 / (z * rho2)) - xp.arctan(x1 * y1 / (z * rho1)))\n    f_x_y_z = 1 / rho4 - 1 / rho3 - 1 / rho2 + 1 / rho1\n    return f_x_z, f_x_x_x, f1_x_x_x, f1_x_y_y, f1_x_x_y, f_x_y_y, f_x_x_y, f_x_z_z, f_x_x_z, f_z_y, f_z_z, f_x_y_z\n\n\ndef tangential_conv_kernels(span, z, grid_spacing, v, cuda=False) -> dict:\n    """Get the convolution kernels for the subsurface stresses cause by a tangential traction in an elastic material\n\n    Parameters\n    ----------\n    span: Sequence[int, int]\n        The span of the convolution kernels in the y and x directions\n    z: Sequence[float]\n        The heights of interest in the solid\n    grid_spacing: Sequence[float, float] or float\n        Either a two element sequence of floats, giving the grid spacing in each direction or, a single value,\n        indicating a square grid\n    v: float\n        The Poisson\'s ratio of the material\n    cuda: bool, optional (False)\n        If True kernels will be made on the GPU\n\n    Returns\n    -------\n    dict with keys: sxx, syy, szz, sxy, syz, sxz\n        The influence matrices for each of the stress components, numpy arrays if cuda is set to false or cupy could not\n        be imported else cupy arrays\n\n    References\n    ----------\n    Lee, M. J., Gu, Y. P., & Jo, Y. J. (2000). The Stress Field in the Body by Tangential Loading of a Rectangular Patch\n    on a Semi-Infinite Solid. Transactions of the Korean Society of Mechanical Engineers A, 24(4), 1032-1038.\n    https://doi.org/10.22634/KSME-A.2000.24.4.1032 (In korean)\n\n    Notes\n    -----\n    Several changes from the original paper have been made for this implementation, these were assumed to be typos,\n    they are indicated in the code.\n    """\n    if not isinstance(grid_spacing, Sequence):\n        grid_spacing = (grid_spacing, grid_spacing)\n    if len(grid_spacing) == 1:\n        grid_spacing = (grid_spacing[0], grid_spacing[0])\n    if len(grid_spacing) != 2:\n        raise ValueError("Grid spacing should be a number or two element sequence")\n\n    if cuda:\n        xp = slippy.xp\n    else:\n        xp = np\n    x = grid_spacing[1] * (xp.arange(span[1]) - span[1] // 2 + (1 - span[1] % 2))\n    y = grid_spacing[0] * (xp.arange(span[0]) - span[0] // 2 + (1 - span[0] % 2))\n    x = x.reshape((1, 1, -1))\n    y = y.reshape((1, -1, 1))\n    z = xp.array(z).reshape((-1, 1, 1))\n    f_x_z, f_x_x_x, f1_x_x_x, f1_x_y_y, f1_x_x_y, f_x_y_y, f_x_x_y, f_x_z_z, f_x_x_z, f_z_y, \\\n        f_z_z, f_x_y_z = tangential_derivative_terms(x, y, z, grid_spacing, cuda)\n    pi = xp.pi\n    sxx = (v + 1) / pi * f_x_z + 1 / (2 * pi) * ((2 * v * f1_x_x_x) - z * f_x_x_x)\n    syy = v / pi * f_x_z + 1 / (2 * pi) * ((2 * v * f1_x_y_y) - z * f_x_y_y)\n    szz = -z / (2 * pi) * f_x_z_z\n    sxy = 1 / (2 * pi) * (f_z_y + 2 * v * f1_x_x_y - z * f_x_x_y)\n    syz = -z / (2 * pi) * f_x_y_z\n    sxz = 1 / (2 * pi) * (f_z_z - z * f_x_x_z)\n    return {\'xx\': sxx, \'yy\': syy, \'zz\': szz, \'xy\': sxy, \'yz\': syz, \'xz\': sxz}\n', 'is_package': False},
    'slippy.core._material_utils': {'source': 'import inspect\nfrom functools import wraps\n\n__all__ = [\'memoize_components\']\n\n\ndef memoize_components(static_method=True):\n    """ A decorator factory for memoizing the components of an influence matrix or other method with components\n\n    Parameters\n    ----------\n    static_method: bool, optional (True)\n        True if the object to be decorated is an instance or class method\n\n    Notes\n    -----\n    This returns a decorator that can be used to memoize a callable which finds components. The callable MUST:\n\n    Have it\'s first argument be the component\n    components must be hashable\n\n    The cache is a dict with the same keys as previously passed components, when any of the other input arguments change\n    the cache is deleted\n\n    The wrapped callable will have the additional attributes:\n\n    cache : dict\n        All of the cached values, use cache.clear() to remove manually\n    spec : list\n        The other arguments passed to the callable (if any of these change the cache is cleared)\n    """\n    if not isinstance(static_method, bool):\n        raise ValueError(\'memoize_components is a decorator factory, it cannot be applied as a decorator directly.\'\n                         \' static_method argument must be a bool\')\n\n    def outer(fn):\n        # non local variables spec is a list to ensure it\'s mutable\n\n        sig = inspect.signature(fn)\n\n        if static_method:\n            spec = []\n            cache = []\n\n            @wraps(fn)\n            def inner(component, *args, **kwargs):\n                nonlocal cache, spec, sig\n                new_spec = sig.bind(None, *args, **kwargs)\n                new_spec.apply_defaults()\n                try:\n                    index = spec.index(new_spec)\n                except ValueError:\n                    spec.append(new_spec)\n                    cache.append(dict())\n                    index = len(cache) - 1\n                if component not in cache[index]:\n                    cache[index][component] = fn(component, *args, **kwargs)\n                return cache[index][component]\n        else:\n            spec = dict()\n            cache = dict()\n\n            @wraps(fn)\n            def inner(self, components, *args, **kwargs):\n                nonlocal cache, spec, sig\n                if self.name not in cache:\n                    cache[self.name] = []\n                    spec[self.name] = []\n                new_spec = sig.bind(None, None, *args, **kwargs)\n                new_spec.apply_defaults()\n                try:\n                    index = spec[self.name].index(new_spec)\n                except ValueError:\n                    spec[self.name].append(new_spec)\n                    cache[self.name].append(dict())\n                    index = len(cache[self.name]) - 1\n                comps_to_find = [c for c in components if c not in cache[self.name][index]]\n                if comps_to_find:\n                    cache[self.name][index].update(fn(self, comps_to_find, *args, **kwargs))\n                return {comp: cache[self.name][index][comp] for comp in components}\n\n        inner.cache = cache\n        inner.spec = spec\n\n        return inner\n\n    return outer\n', 'is_package': False},
    'slippy.core._stress_utils': {'source': 'import numpy as np\nimport numba\nimport slippy\nfrom collections.abc import Sequence\n\n__all__ = [\'get_derived_stresses\', \'solve_cubic\']\n\n_cuda_cubic_cache = {}\n\ntry:\n    import cupy as cp\n\n    def _make_cuda_cubic_solver(dtype):\n        eps = slippy.CUBIC_EPS\n        s_dtype = str(dtype)\n        if not s_dtype.startswith("float"):\n            raise ValueError("can only make cubic solver for single and double floats")\n        single = \'f\' if str(s_dtype).endswith(\'32\') else \'\'\n        if not single and not str(s_dtype).endswith(\'64\'):\n            raise ValueError("can only make cubic solver for single and double floats")\n        cubic_kernel = cp.ElementwiseKernel(\n            "T b, T c, T d", "T r1, T r2, T r3",\n            f\'\'\'\n        if (fabs{single}(d) < {eps}) {{\n        // cancel and find remaining roots by quadratic formula\n        r1 = 0;\n        T diff = sqrt{single}(b*b-4*c)/2;\n        r2 = (-b)/2 + diff;\n        r3 = (-b)/2 - diff;\n        }} else {{\n        // convert to depressed cubic\n        T p = c-b*b/3;\n        T q = 2*b*b*b/27 - b*c/3 + d;\n        if (fabs{single}(p) < {eps}) {{\n        r1 = cbrt{single}(-q) - b/3;\n        r2 = r1;\n        r3 = r1;\n        }} else if (fabs{single}(q) < {eps}) {{\n            r3 = - b/3;\n            if (p<0) {{\n                T diff = sqrt{single}(-p);\n                r2 = diff - b/3;\n                r1 = - diff - b/3;\n            }} else {{\n                r1 = r3;\n                r2 = r3;\n            }}\n        }} else {{\n        T e = q*q/4 + p*p*p/27;\n\n        if (fabs{single}(e) < {eps}) {{ // two roots\n            r2 = -1.5*q/p - b/3;\n            r3 = 3*q/p - b/3;\n            T f_prime2 = 3*r2*r3 + 2*b*r2+c;\n            T f_prime3 = 3*r3*r3 + 2*b*r3+c;\n            if (fabs{single}(f_prime2) < fabs{single}(f_prime3)) {{\n                r1 = r2;\n            }} else {{\n                r1 = r3;\n            }}\n        }} else if (e>0) {{\n            // one root\n            T u = cbrt{single}(-q/2 - sqrt{single}(e));\n            r1 = u - p/(3*u) - b/3;\n            r2 = r1;\n            r3 = r1;\n        }} else {{\n            T u = 2*sqrt{single}(-p/3);\n            T t = acos{single}(3*q/p/u)/3;\n            T k = 2*3.14159265358979311599796346854/3;\n            r1 = u*cos{single}(t) - b/3;\n            r2 = u*cos{single}(t-k) - b/3;\n            r3 = u*cos{single}(t-2*k) - b/3;\n        }}\n        }}\n        }}\n        // sort the roots\n        T temp;\n        if (r1<r2) {{\n            if (r2>r3) {{\n                if (r1<r3) {{\n                    temp = r2;\n                    r2 = r3;\n                    r3 = temp;\n                }} else {{\n                    temp = r1;\n                    r1 = r3;\n                    r3 = r2;\n                    r2 = temp;\n                }}\n            }}\n        }} else {{\n            if (r2<r3) {{\n                if (r1<r3) {{\n                    temp = r1;\n                    r1 = r2;\n                    r2 = temp;\n                }} else {{\n                    temp = r1;\n                    r1 = r2;\n                    r2 = r3;\n                    r3 = temp;\n                }}\n            }} else {{\n                temp = r1;\n                r1 = r3;\n                r3 = temp;\n            }}\n        }}\n        return;\n        \'\'\', \'solve_cubic\', return_tuple=True)\n        return cubic_kernel\n\n    def _solve_cubic_cuda(b, c, d):\n        assert isinstance(b, cp.ndarray) and isinstance(c, cp.ndarray) and isinstance(d, cp.ndarray), \\\n            "Arrays must all be cupy arrays"\n        assert b.dtype == c.dtype == d.dtype, "Array dtypes must match"\n        if b.dtype not in _cuda_cubic_cache:\n            _cuda_cubic_cache[b.dtype] = _make_cuda_cubic_solver(b.dtype)\n        return _cuda_cubic_cache[b.dtype](b, c, d)\n\nexcept ImportError:\n    cp = None\n    _solve_cubic_cuda = None\n\n\ndef _make_numba_cubic_solver(dtype):\n    eps = slippy.CUBIC_EPS\n    s_dtype = str(dtype)\n    if not s_dtype.startswith("float"):\n        raise ValueError("can only make cubic solver for single and double floats")\n\n    def solve_cubic_numba_base(b, c, d, r1, r2, r3):\n        for i in range(len(b)):\n            if np.abs(d[i]) < eps:\n                # cancel and find remaining roots by quadratic formula\n                r1[i] = 0\n                diff = np.sqrt(b[i] * b[i] - 4 * c[i]) / 2\n                r2[i] = (-b[i]) / 2 + diff\n                r3[i] = (-b[i]) / 2 - diff\n            else:\n                # convert to depressed cubic\n                p = c[i] - b[i] ** 2 / 3\n                q = 2 * b[i] ** 3 / 27 - b[i] * c[i] / 3 + d[i]\n                if np.abs(p) < eps:\n                    r1[i] = np.sign(-q) * np.abs(q) ** (1 / 3) - b[i] / 3\n                    r2[i] = r1[i]\n                    r3[i] = r1[i]\n                elif np.abs(q) < eps:\n                    r3[i] = - b[i] / 3\n                    if p < 0:\n                        diff = np.sqrt(-p)\n                        r2[i] = diff - b[i] / 3\n                        r1[i] = - diff - b[i] / 3\n                    else:\n                        r1[i] = r3[i]\n                        r2[i] = r3[i]\n                else:\n                    e = q * q / 4 + p * p * p / 27\n                    if np.abs(e) < eps:\n                        r2[i] = -1.5 * q / p - b[i] / 3\n                        r3[i] = 3 * q / p - b[i] / 3\n                        f_prime2 = 3 * r2[i] ** 2 + 2 * b[i] * r2[i] + c[i]\n                        f_prime3 = 3 * r3[i] ** 2 + 2 * b[i] * r3[i] + c[i]\n                        if np.abs(f_prime2) < np.abs(f_prime3):\n                            r1[i] = r2[i]\n                        else:\n                            r1[i] = r3[i]\n                    elif e > 0:\n                        u = -q / 2 - np.sqrt(e)\n                        u = np.sign(u) * np.abs(u) ** (1 / 3)\n                        r1[i] = u - p / (3 * u) - b[i] / 3\n                        r2[i] = r1[i]\n                        r3[i] = r1[i]\n                    else:\n                        u = 2 * np.sqrt(-p / 3)\n                        t = np.arccos(3 * q / p / u) / 3\n                        k = 2 * np.pi / 3\n                        r1[i] = u * np.cos(t) - b[i] / 3\n                        r2[i] = u * np.cos(t - k) - b[i] / 3\n                        r3[i] = u * np.cos(t - 2 * k) - b[i] / 3\n            # sort the array\n            r1[i], r2[i], r3[i] = np.sort(np.array([r1[i], r2[i], r3[i]]))\n\n    numba_type = numba.__getattribute__(s_dtype)\n    raw_func = numba.guvectorize([(numba_type[:], numba_type[:], numba_type[:],\n                                   numba_type[:], numba_type[:], numba_type[:])],\n                                 "(n),(n),(n)->(n),(n),(n)",\n                                 nopython=True)(solve_cubic_numba_base)\n\n    def full_func(b, c, d):\n        r1 = np.zeros_like(b)\n        r2 = np.zeros_like(b)\n        r3 = np.zeros_like(b)\n        raw_func(b, c, d, r1, r2, r3)\n        return r1, r2, r3\n\n    return full_func\n\n\n_numba_cubic_cache = {}\n\n\ndef _solve_cubic_numba(b, c, d):\n    assert isinstance(b, np.ndarray) and isinstance(c, np.ndarray) and isinstance(d, np.ndarray), \\\n        "Arrays must all be numpy arrays"\n    assert b.dtype == c.dtype == d.dtype, "Array dtypes must match"\n    if b.dtype not in _numba_cubic_cache:\n        _numba_cubic_cache[b.dtype] = _make_numba_cubic_solver(b.dtype)\n    return _numba_cubic_cache[b.dtype](b, c, d)\n\n\ndef solve_cubic(b, c, d):\n    """ Find roots of cubic equation x^3 + bx^2 + cx + d = 0\n\n    Parameters\n    ----------\n    b, c, d: either numpy or cupy arrays\n        Equation coefficients, must all have the same dtype and the same shape, currently supports any floats for numpy\n        arrays and single or double floats for cupy arrays\n    Returns\n    -------\n    r1, r2, r3: arrays\n        Roots of the equation in ascending size order, arrays will match size, type and dtype of the input. All arrays\n        will always be filled, if only a single root is found this will be repeated, where there are 2 roots, the root\n        which does not represent a zero crossing will be repeated.\n    Notes\n    -----\n    Both the cuda and numba versions use just in time compilation, functions are also cached for future calls\n\n    """\n    if isinstance(b, np.ndarray):\n        return _solve_cubic_numba(b, c, d)\n    elif cp is not None:\n        if isinstance(b, cp.ndarray):\n            return _solve_cubic_cuda(b, c, d)\n    raise TypeError(f"Cannot solve cubic, unrecognised type {str(type(b))}")\n\n\ndef get_derived_stresses(tensor_components: dict, required_components: Sequence, delete: bool = True) -> dict:\n    """Finds derived stress terms from the full stress tensor\n\n    Parameters\n    ----------\n    tensor_components: dict\n        The stress tensor components must have keys: \'xx\', \'yy\', \'zz\', \'xy\', \'yz\', \'xz\' all should be equal size\n        arrays\n    required_components: Sequence\n        The required derived stresses, valid items are: \'1\', \'2\', \'3\' and/or \'vm\', relating to principal stresses and\n        von mises stress respectively. If tensor components are also present these will not be deleted if delete is\n        set to True\n    delete: bool, optional (True)\n        If True the tensor components will be deleted after computation with the exception of components who\'s names\n        are in required_components\n\n    Returns\n    -------\n    dict of derived components\n\n    """\n    if not all([rc in {\'1\', \'2\', \'3\', \'vm\'} for rc in required_components]):\n        raise ValueError("Unrecognised derived stress component, allowed components are: \'1\', \'2\', \'3\', \'vm\'")\n\n    if isinstance(tensor_components[\'xx\'], np.ndarray):\n        xp = np\n    else:\n        try:\n            float(tensor_components[\'xx\'])\n            xp = np\n        except TypeError:\n            xp = slippy.xp\n    rtn_dict = dict()\n    if \'vm\' in required_components:\n        rtn_dict[\'vm\'] = xp.sqrt(((tensor_components[\'xx\'] - tensor_components[\'yy\']) ** 2 +\n                                  (tensor_components[\'yy\'] - tensor_components[\'zz\']) ** 2 +\n                                  (tensor_components[\'zz\'] - tensor_components[\'xx\']) ** 2 +\n                                  6 * (tensor_components[\'xy\'] ** 2 +\n                                       tensor_components[\'yz\'] ** 2 +\n                                       tensor_components[\'xz\'] ** 2)) / 2)\n    if \'1\' in required_components or \'2\' in required_components or \'3\' in required_components:\n        b = -(tensor_components[\'xx\'] + tensor_components[\'yy\'] + tensor_components[\'zz\'])\n        c = (tensor_components[\'xx\'] * tensor_components[\'yy\'] +\n             tensor_components[\'yy\'] * tensor_components[\'zz\'] +\n             tensor_components[\'xx\'] * tensor_components[\'zz\'] -\n             tensor_components[\'xy\'] ** 2 - tensor_components[\'xz\'] ** 2 - tensor_components[\n                 \'yz\'] ** 2)\n        d = -((tensor_components[\'xx\'] * tensor_components[\'yy\'] * tensor_components[\'zz\'] +\n               2 * tensor_components[\'xy\'] * tensor_components[\'xz\'] * tensor_components[\'yz\'] -\n               tensor_components[\'xx\'] * tensor_components[\'yz\'] ** 2 -\n               tensor_components[\'yy\'] * tensor_components[\'xz\'] ** 2 -\n               tensor_components[\'zz\'] * tensor_components[\'xy\'] ** 2))\n\n        rtn_dict[\'3\'], rtn_dict[\'2\'], rtn_dict[\'1\'] = solve_cubic(b, c, d)\n    return rtn_dict\n', 'is_package': False},
    'slippy.core.abcs': {'source': '"""\nMinimal abstract base classes please don\'t add any code to these, they are strictly to avoid circular imports,\nthis module should be as minimal as possible as it will be imported every time any sub package is imported\n"""\n\nimport abc\n\n__all__ = [\'_SurfaceABC\', \'_AdhesionModelABC\', \'_MaterialABC\', \'_StepABC\', \'_FrictionModelABC\', \'_WearModelABC\',\n           \'_ACFABC\', \'_LubricantModelABC\', \'_ContactModelABC\', \'_ReynoldsSolverABC\',\n           \'_NonDimensionalReynoldSolverABC\', \'_SubModelABC\']\n\n\nclass _LubricantModelABC(abc.ABC):\n    pass\n\n\nclass _MaterialABC(abc.ABC):\n\n    @abc.abstractmethod\n    def loads_from_surface_displacement(self, displacements_z, grid_spacing: float,\n                                        other: \'_MaterialABC\', current_state: dict, **material_options):\n        pass\n\n    @abc.abstractmethod\n    def displacement_from_surface_loads(self, loads_z, grid_spacing: float,\n                                        other: \'_MaterialABC\', current_state: dict, **material_options):\n        pass\n\n\nclass _SurfaceABC(abc.ABC):\n    profile = None\n    moving_surface = False\n    grid_spacing: float\n    material: _MaterialABC\n    shape: tuple\n\n    def max_shape(self):  # To be over written by the rolling surface\n        return self.shape\n\n    def wear(self, name, x_pts, y_pts, depth):\n        pass\n\n    def convert_coordinates(self, y_coord, x_coord):  # converts coordinates to the roughness, only for rolling surfaces\n        return y_coord, x_coord\n\n\nclass _AdhesionModelABC(abc.ABC):\n\n    @abc.abstractmethod\n    def energy_gradient(self, gap):\n        pass\n\n    def __call__(self, gap):\n        return self.energy_gradient(gap)\n\n    def __bool__(self):\n        return True\n\n\nclass _StepABC(abc.ABC):\n    max_time: float\n    pass\n\n\nclass _ContactModelABC(abc.ABC):\n    surface_1: _SurfaceABC\n    surface_2: _SurfaceABC\n    current_step: _StepABC\n    current_step_start_time: float\n\n    _lubricant: _LubricantModelABC = None\n\n    @property\n    def lubricant_model(self):\n        return self._lubricant\n\n    @lubricant_model.setter\n    def lubricant_model(self, value):\n        if issubclass(type(value), _LubricantModelABC) or value is None:\n            self._lubricant = value\n        else:\n            raise ValueError("Unable to set lubricant, expected lubricant "\n                             "object, received %s" % str(type(value)))\n\n    @lubricant_model.deleter\n    def lubricant_model(self):\n        # noinspection PyTypeChecker\n        self._lubricant = None\n\n\nclass _FrictionModelABC(abc.ABC):\n    pass\n\n\nclass _WearModelABC(abc.ABC):\n    pass\n\n\nclass _ACFABC(abc.ABC):\n    pass\n\n\nclass _ReynoldsSolverABC(abc.ABC):\n\n    @abc.abstractmethod\n    def solve(self, previous_state: dict, max_pressure: float) -> dict:\n        pass\n\n    @abc.abstractmethod\n    def data_check(self, previous_state: set) -> set:\n        pass\n\n\nclass _NonDimensionalReynoldSolverABC(_ReynoldsSolverABC):\n    provides: set\n    requires: set\n    rolling_speed: float\n\n    @abc.abstractmethod\n    def dimensionalise_pressure(self, nd_pressure, un_dimensionalise: bool = False):\n        pass\n\n    @abc.abstractmethod\n    def dimensionalise_viscosity(self, nd_viscosity, un_dimensionalise: bool = False):\n        pass\n\n    @abc.abstractmethod\n    def dimensionalise_density(self, nd_density, un_dimensionalise: bool = False):\n        pass\n\n    @abc.abstractmethod\n    def dimensionalise_gap(self, nd_gap, un_dimensionalise: bool = False):\n        pass\n\n    @abc.abstractmethod\n    def dimensionalise_length(self, nd_length, un_dimensionalise: bool = False):\n        pass\n\n\nclass _SubModelABC(abc.ABC):\n    name: str\n    requires: set\n    provides: set\n    model: _ContactModelABC = None\n    no_time: bool = False\n\n    def __init__(self, name: str, requires: set, provides: set):\n        if isinstance(name, str):\n            self.name = name\n        else:\n            raise ValueError(f"Name of sub model must be a string, received: {type(name)}")\n        if isinstance(requires, set):\n            self.requires = requires\n        else:\n            raise ValueError(f"Requires property must be a set, received: {type(requires)}")\n        if isinstance(provides, set):\n            self.provides = provides\n        else:\n            raise ValueError(f"Requires property must be a set, received: {type(provides)}")\n\n    @abc.abstractmethod\n    def solve(self, current_state: dict) -> dict:\n        """Solve the sub model\n\n        Parameters\n        ----------\n        current_state: dict\n            The current model state\n\n        Returns\n        -------\n        dict\n            dict of found parameters, current state will be updated with these after running the model\n\n        """\n', 'is_package': False},
    'slippy.core.elastic_material': {'source': 'import numpy as np\nimport typing\nfrom collections import namedtuple\nfrom .materials import _IMMaterial\nfrom ._elastic_sub_surface_stresses import normal_conv_kernels, tangential_conv_kernels\n\n__all__ = [\'Elastic\', \'elastic_influence_matrix_spatial\', \'elastic_influence_matrix_frequency\', \'get_angular_velocity\']\n\nElasticProps = namedtuple(\'ElasticProperties\', \'K E v Lam M G\', defaults=(None,) * 6)\n\n\n# noinspection PyPep8Naming\nclass Elastic(_IMMaterial):\n    """ A Class for defining elastic materials\n\n    Parameters\n    ----------\n    name: str\n        The name of the material\n    properties: dict\n        dict of properties, dicts must have exactly 2 items.\n        Allowed keys are : \'E\', \'v\', \'G\', \'K\', \'M\', \'Lam\'\n        See notes for definitions\n    max_load: float, optional (float(\'inf\'))\n        The maximum load on the surface, loads above this will be cropped during analysis, if this is specified a\n        plastic deformation sub model should be added to the end of each model step to make the deformation permanent\n    use_frequency_domain: bool, optional (True)\n        If True the frequency domain definition of the influence matrix is used, otherwise the spatial domain definition\n        is used.\n    periodic_im_repeats: tuple, optional (1,1)\n        The number of times the influence matrix should be wrapped in each dimension, used with spatially defined\n        influence matrices and to set the zero frequency value for frequency domain influence matrices. Should not\n        be used with non periodic contacts, for periodic contacts the total size should match the physical size. This\n        is necessary to ensure truly periodic behaviour, no physical limit exists:\n        (an infinitely long contact with any load per unit length will cause infinite displacement).\n    zero_frequency_value: float, optional (None)\n        If the frequency domain influence matrix is used the zero frequency value can be set, this defaults to the sum\n        of the spatial influence matrix of the correct size. Should be set to 0 for fully periodic contacts.\n\n    Methods\n    -------\n    speed_of_sound\n\n    See Also\n    --------\n\n    Notes\n    -----\n\n    Keys refer to:\n        - E   - Young\'s modulus\n        - v   - Poission\'s ratio\n        - K   - Bulk Modulus\n        - Lam - Lame\'s first parameter\n        - G   - Shear modulus\n        - M   - P wave modulus\n\n    Examples\n    --------\n    >>> # Make a material model for elastic steel\n    >>> steel = Elastic(\'steel\', {\'E\': 200e9, \'v\': 0.3})\n    >>> # Find it\'s p-wave modulus:\n    >>> pwm = steel.M\n    >>> # Find the speeds of sound:\n    >>> sos = steel.speed_of_sound(7890)\n    """\n\n    material_type = \'Elastic\'\n\n    _properties = {\'E\': None,\n                   \'v\': None,\n                   \'G\': None,\n                   \'K\': None,\n                   \'Lam\': None,\n                   \'M\': None, }\n\n    _last_set = []\n    density = None\n\n    def __init__(self, name: str, properties: dict, max_load: float = np.inf,\n                 use_frequency_domain: bool = True, periodic_im_repeats: tuple = (1, 1),\n                 zero_frequency_value: float = None):\n        super().__init__(name, use_frequency_domain, max_load,\n                         periodic_im_repeats, zero_frequency_value)\n\n        if len(properties) > 2:\n            raise ValueError("Too many properties supplied, must be 1 or 2")\n\n        for item in properties.items():\n            self._set_props(*item)\n\n    def _influence_matrix_spatial(self, components: typing.Union[typing.Sequence[str], str],\n                                  grid_spacing: {typing.Sequence[float], float}, span: typing.Sequence[int]):\n        """\n        Influence matrix for an elastic material\n\n        Parameters\n        ----------\n        grid_spacing: tuple\n            The spacing between grid points in the x and y directions\n        span: tuple\n            The span required in the x and y directions in number of grid points\n        components: str or Sequence {\'xx\',\'xy\',\'xz\',\'yx\',\'yy\',\'yz\',\'zx\',\'zy\',\'zz\',\'all\'}\n            The required components eg the \'xy\' component represents the x\n            deflection caused by loads in the y direction\n\n        Returns\n        -------\n        dict\n            dict of the requested influence matrix or matrices\n\n        See Also\n        --------\n        elastic_loading\n        elastic_deflection\n\n        Notes\n        -----\n\n        K^{ij i\'j\'}_zz=(1-v)/(2*pi*G)*Czz\n\n        Czz=(hx*(k*log((m+sqrt(k**2+m**2))/(n+sqrt(k**2+n**2)))+\n                 l*log((n+sqrt(l**2+n**2))/(m+sqrt(l**2+m**2))))+\n             hy*(m*log((k+sqrt(k**2+m**2))/(l+sqrt(l**2+m**2)))+\n                 n*log((l+sqrt(l**2+n**2))/(k+sqrt(k**2+n**2)))))\n\n        In which:\n\n        k=i\'-i+0.5\n        l=i\'-i-0.5\n        m=j\'-j+0.5\n        n=j\'-j-0.5\n        hx=grid_spacing[0]\n        hy=grid_spacing[1]\n\n        If both shear_modulus_2 and v_2 are supplied and are not None the combined IM is returned for the surface\n        pair\n\n        Examples\n        --------\n\n\n        References\n        ----------\n        Complete boundary element method formulation for normal and tangential\n        contact problems\n\n        """\n        shear_modulus_2 = None\n        v_2 = None\n\n        shear_modulus = self.G\n        v = self.v\n\n        components = {comp: elastic_influence_matrix_spatial(comp, span, grid_spacing, shear_modulus, v,\n                                                             shear_mod_2=shear_modulus_2, v_2=v_2) for comp in\n                      components}\n\n        return components\n\n    def _influence_matrix_frequency(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                    span: typing.Sequence[int]):\n        x_omega, y_omega = get_angular_velocity(span, grid_spacing)\n        norm_2 = x_omega ** 2 + y_omega ** 2\n        norm = np.sqrt(norm_2)\n        rtn_dict = {key: elastic_influence_matrix_frequency(y_omega, x_omega, norm, norm_2, key, self.E, self.v)\n                    for key in components}\n        return rtn_dict\n\n    def _del_props(self, prop):\n        # delete any of the material properties\n        keys = list(self._properties.keys())\n        if self._last_set == prop:\n            self._properties = {key: None for key in keys}\n            self._last_set = None\n        else:\n            self._properties = {key: None for key in keys\n                                if not key == self._last_set}\n\n    def _set_props(self, prop, value):\n        allowed_props = [\'E\', \'v\', \'G\', \'K\', \'Lam\', \'M\']\n        if prop not in allowed_props:\n            msg = (f\'property {prop} not recognised allowed propertied are: \' +\n                   \' \'.join(allowed_props))\n            raise ValueError(msg)\n\n        self._properties[prop] = np.float64(value)\n\n        if len(self._last_set) == 0:\n            self._last_set.append(prop)  # if none ever set just set it\n        elif self._last_set[-1] != prop:\n            self._last_set.append(prop)  # if the last set is different replace it\n\n        if len(self._last_set) > 1:  # if 2 props have been set update all\n            set_props = {prop: np.float64(value),\n                         self._last_set[-2]: self._properties[self._last_set[-2]]}\n            self._properties = _get_properties(set_props)\n        return\n\n    @property\n    def E(self):\n        """The Young\'s modulus of the material"""\n        return self._properties[\'E\']\n\n    @E.deleter\n    def E(self):\n        self._del_props(\'E\')\n\n    @E.setter\n    def E(self, value):\n        self._set_props(\'E\', value)\n\n    @property\n    def v(self):\n        """The Poissions\'s ratio of the material"""\n        return self._properties[\'v\']\n\n    @v.deleter\n    def v(self):\n        self._del_props(\'v\')\n\n    @v.setter\n    def v(self, value):\n        self._set_props(\'v\', value)\n\n    @property\n    def G(self):\n        """The shear modulus of the material"""\n        return self._properties[\'G\']\n\n    @G.deleter\n    def G(self):\n        self._del_props(\'G\')\n\n    @G.setter\n    def G(self, value):\n        self._set_props(\'G\', value)\n\n    @property\n    def K(self):\n        """The bulk modulus of the material"""\n        return self._properties[\'K\']\n\n    @K.deleter\n    def K(self):\n        self._del_props(\'K\')\n\n    @K.setter\n    def K(self, value):\n        self._set_props(\'K\', value)\n\n    @property\n    def Lam(self):\n        """Lame\'s first parameter for the material"""\n        return self._properties[\'Lam\']\n\n    @Lam.deleter\n    def Lam(self):\n        self._del_props(\'Lam\')\n\n    @Lam.setter\n    def Lam(self, value):\n        self._set_props(\'Lam\', value)\n\n    @property\n    def M(self):\n        """The p wave modulus of the material"""\n        return self._properties[\'M\']\n\n    @M.deleter\n    def M(self):\n        self._del_props(\'M\')\n\n    @M.setter\n    def M(self, value):\n        self._set_props(\'M\', value)\n\n    def speed_of_sound(self, density: float = None):\n        """find the speed of sound in the material\n\n        Parameters\n        ----------\n        density : float optional (None)\n            The density of the material\n\n        Returns\n        -------\n\n        speeds : dict\n            With keys \'s\' and \'p\' giving the s and p wave speeds\n\n        Notes\n        -----\n\n        Finds speeds according to the following equations:\n\n        Vs=sqrt(G/rho)\n        Vp=sqrt(M/rho)\n\n        Where rho is the density, G is the shear modulus and M is the p wave\n        modulus\n\n        Examples\n        --------\n        >>> # Find the speed of sound in steel\n        >>> my_material = Elastic({\'E\': 200e9, \'v\': 0.3})\n        >>> my_material.speed_of_sound(7850)\n\n        """\n        if density is not None:\n            self.density = density\n        elif self.density is None:\n            raise ValueError("Density not given or set")\n\n        speeds = {\'s\': np.sqrt(self.G / self.density),\n                  \'p\': np.sqrt(self.M / self.density)}\n\n        return speeds\n\n    def sss_influence_matrices_normal(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                      span: typing.Sequence[int], z: typing.Sequence[float] = None, cuda: bool = False):\n        if z is None:\n            z_len = min(span)\n            print(span)\n            gs = grid_spacing[span.index(z_len)]\n            print(gs)\n            z = gs * np.arange(z_len // 2)\n            z[0] = z[1] * 1e-4\n        all_matrices = normal_conv_kernels(span, z, grid_spacing, self.E, self.v, cuda=cuda)\n        return {comp: all_matrices[comp] for comp in components}\n\n    def sss_influence_matrices_tangential_x(self, components: typing.Sequence[str],\n                                            grid_spacing: typing.Sequence[float], span: typing.Sequence[int],\n                                            z: typing.Sequence[float] = None, cuda: bool = False):\n        if z is None:\n            z_len = min(span)\n            gs = grid_spacing[span.index(z_len)]\n            z = gs * np.arange(z_len // 2)\n            z[0] = z[1] * 1e-4\n        all_matrices = tangential_conv_kernels(span, z, grid_spacing, self.v, cuda=cuda)\n        return {comp: all_matrices[comp] for comp in components}\n\n    def __repr__(self):\n        return "Elastic(name = \'" + self.name + f"\', properties = {{ \'E\':{self.E}, \'v\':{self.v} }}"\n\n\ndef _get_properties(set_props: dict):\n    """Get all elastic properties from any pair\n\n    Parameters\n    ----------\n    set_props : dict\n        dict of properties must have exactly 2 members valid keys are: \'K\',\n        \'E\', \'v\', \'Lam\', \'M\', \'G\'\n\n    Returns\n    -------\n    out : dict\n        dict of all material properties keys are: \'K\', \'E\', \'v\', \'Lam\', \'M\', \'G\'\n\n    Notes\n    -----\n\n    Keys refer to:\n        - E - Young\'s modulus\n        - v - Poission\'s ratio\n        - K - Bulk Modulus\n        - Lam - Lame\'s first parameter\n        - G - Shear modulus\n        - M - P wave modulus\n\n    """\n    if len(set_props) != 2:\n        raise ValueError("Exactly 2 properties must be set,"\n                         " {} found".format(len(set_props)))\n\n    valid_keys = [\'K\', \'E\', \'v\', \'G\', \'Lam\', \'M\']\n\n    set_params = [key for key in list(set_props.keys()) if key in valid_keys]\n\n    if len(set_params) != 2:\n        msg = ("Invalid keys in set_props keys found are: " +\n               "{}".format(set_props.keys()) +\n               ". Valid keys are: " + " ".join(valid_keys))\n        raise ValueError(msg)\n\n    out = set_props.copy()\n\n    set_params = list(set_props.keys())\n    set_params.sort()\n    # p is properties this saves a lot of space\n    p = ElasticProps(**set_props)\n\n    if set_params[0] == \'E\':\n        if set_params[1] == \'G\':\n            out[\'K\'] = p.E * p.G / (3 * (3 * p.G - p.E))\n            out[\'Lam\'] = p.G * (p.E - 2 * p.G) / (3 * p.G - p.E)\n            out[\'M\'] = p.G * (4 * p.G - p.E) / (3 * p.G - p.E)\n            out[\'v\'] = p.E / (2 * p.G) - 1\n        elif set_params[1] == \'K\':\n            out[\'G\'] = 3 * p.K * p.E / (9 * p.K - p.E)\n            out[\'Lam\'] = 3 * p.K * (3 * p.K - p.E) / (9 * p.K - p.E)\n            out[\'M\'] = 3 * p.K * (3 * p.K + p.E) / (9 * p.K - p.E)\n            out[\'v\'] = (3 * p.K - p.E) / (6 * p.K)\n        elif set_params[1] == \'Lam\':\n            R = np.sqrt(p.E ** 2 + 9 * p.Lam ** 2 + 2 * p.E * p.Lam)\n            out[\'G\'] = (p.E - 3 * p.Lam + R) / 4\n            out[\'K\'] = (p.E + 3 * p.Lam + R) / 6\n            out[\'M\'] = (p.E - p.Lam + R) / 2\n            out[\'v\'] = 2 * p.Lam / (p.E + p.Lam + R)\n        elif set_params[1] == \'M\':\n            S = np.sqrt(p.E ** 2 + 9 * p.M ** 2 - 10 * p.E * p.M)\n            out[\'G\'] = (3 * p.M + p.E - S) / 8\n            out[\'K\'] = (3 * p.M - p.E + S) / 6\n            out[\'Lam\'] = (p.M - p.E + S) / 4\n            out[\'v\'] = (p.E - p.M + S) / (4 * p.M)\n        else:  # set_params[1]==\'v\'\n            out[\'G\'] = p.E / (2 * (1 + p.v))\n            out[\'K\'] = p.E / (3 * (1 - 2 * p.v))\n            out[\'Lam\'] = p.E * p.v / ((1 + p.v) * (1 - 2 * p.v))\n            out[\'M\'] = p.E * (1 - p.v) / ((1 + p.v) * (1 - 2 * p.v))\n    elif set_params[0] == \'G\':\n        if set_params[1] == \'K\':\n            out[\'E\'] = 9 * p.K * p.G / (3 * p.K + p.G)\n            out[\'Lam\'] = p.K - 2 * p.G / 3\n            out[\'M\'] = p.K + 4 * p.G / 3\n            out[\'v\'] = (3 * p.K - 2 * p.G) / (2 * (3 * p.K + p.G))\n        elif set_params[1] == \'Lam\':\n            out[\'E\'] = p.G * (3 * p.Lam + 2 * p.G) / (p.Lam + p.G)\n            out[\'K\'] = p.Lam + 2 * p.G / 3\n            out[\'M\'] = p.Lam + 2 * p.G\n            out[\'v\'] = p.Lam / (2 * (p.Lam + p.G))\n        elif set_params[1] == \'M\':\n            out[\'E\'] = p.G * (3 * p.M - 4 * p.G) / (p.M - p.G)\n            out[\'K\'] = p.M - 4 * p.G / 3\n            out[\'Lam\'] = p.M - 2 * p.G\n            out[\'v\'] = (p.M - 2 * p.G) / (2 * p.M - 2 * p.G)\n        else:  # set_params[1]==\'v\'\n            out[\'E\'] = 2 * p.G * (1 + p.v)\n            out[\'K\'] = 2 * p.G * (1 + p.v) / (3 * (1 - 2 * p.v))\n            out[\'Lam\'] = 2 * p.G * p.v / (1 - 2 * p.v)\n            out[\'M\'] = 2 * p.G * (1 - p.v) / (1 - 2 * p.v)\n    elif set_params[0] == \'K\':\n        if set_params[1] == \'Lam\':\n            out[\'E\'] = 9 * p.K * (p.K - p.Lam) / (3 * p.K - p.Lam)\n            out[\'G\'] = 3 * (p.K - p.Lam) / 2\n            out[\'M\'] = 3 * p.K - 2 * p.Lam\n            out[\'v\'] = p.Lam / (3 * p.K - p.Lam)\n        elif set_params[1] == \'M\':\n            out[\'E\'] = 9 * p.K * (p.M - p.K) / (3 * p.K + p.M)\n            out[\'G\'] = 3 * (p.M - p.K) / 4\n            out[\'Lam\'] = (3 * p.K - p.M) / 2\n            out[\'v\'] = (3 * p.K - p.M) / (3 * p.K + p.M)\n        else:  # set_params[1]==\'v\'\n            out[\'E\'] = 3 * p.K * (1 - 2 * p.v)\n            out[\'G\'] = (3 * p.K * (1 - 2 * p.v)) / (2 * (1 + p.v))\n            out[\'Lam\'] = 3 * p.K * p.v / (1 + p.v)\n            out[\'M\'] = 3 * p.K * (1 - p.v) / (1 + p.v)\n    elif set_params[0] == \'Lam\':\n        if set_params[1] == \'M\':\n            out[\'E\'] = (p.M - p.Lam) * (p.M + 2 * p.Lam) / (p.M + p.Lam)\n            out[\'G\'] = (p.M - p.Lam) / 2\n            out[\'K\'] = (p.M + 2 * p.Lam) / 3\n            out[\'v\'] = p.Lam / (p.M + p.Lam)\n        else:\n            out[\'E\'] = p.Lam * (1 + p.v) * (1 - 2 * p.v) / p.v\n            out[\'G\'] = p.Lam(1 - 2 * p.v) / (2 * p.v)\n            out[\'K\'] = p.Lam * (1 + p.v) / (3 * p.v)\n            out[\'M\'] = p.Lam * (1 - p.v) / p.v\n    else:\n        out[\'E\'] = p.M * (1 + p.v) * (1 - 2 * p.v) / (1 - p.v)\n        out[\'G\'] = p.M * (1 - 2 * p.v) / (2 * (1 - p.v))\n        out[\'K\'] = p.M * (1 + p.v) / (3 * (1 - p.v))\n        out[\'Lam\'] = p.M * p.v / (1 - p.v)\n\n    return out\n\n\ndef get_angular_velocity(span, gs):\n    r_omega = np.fft.fftfreq(span[1], d=gs[1]) * (2 * np.pi)\n    c_omega = np.fft.fftfreq(span[0], d=gs[0]) * (2 * np.pi)\n    return np.meshgrid(r_omega, c_omega)\n\n\ndef elastic_influence_matrix_frequency(y_omega, x_omega, norm, norm_2, comp: str, e: float, v: float):\n    """\n\n    Parameters\n    ----------\n    y_omega: np.ndarray\n        rotational velocity components in the y direction\n    x_omega: np.ndarray\n        rotational velocity components in the x direction\n    norm: np.ndarray\n        The norm of the velocity vectors\n    norm_2: np.ndarray\n        The squared norm of the velocity vectors\n    comp: str\n        The component to find for example \'xy\' gives the deformations in the y direction caused by a load in the x\n        direction\n    e: float\n        The Young\'s modulus of the material\n    v: float\n        The Poission\'s ratio of the material\n\n    Returns\n    -------\n    The influence matrix component in the frequency domain\n\n    """\n    with np.errstate(divide=\'ignore\', invalid=\'ignore\'):\n        if comp == \'zz\':\n            fact = 2 * (1 - v ** 2)\n        elif comp == \'yy\':\n            fact = 2 * (1 + v) * (1 - v * y_omega ** 2 / norm_2)\n        elif comp == \'xx\':\n            fact = 2 * (1 + v) * (1 - v * x_omega ** 2 / norm_2)\n        elif comp in (\'xy\', \'yx\'):\n            fact = y_omega * x_omega * 2 * v * (1 + v) / norm_2\n        elif comp in (\'yz\', \'zy\'):\n            fact = 1j * y_omega * (1 + v) * (1 - 2 * v) / norm * (-1 if comp == \'zy\' else 1)\n        elif comp in (\'xz\', \'zx\'):\n            fact = 1j * x_omega * (1 + v) * (1 - 2 * v) / norm * (-1 if comp == \'zx\' else 1)\n        else:\n            raise ValueError(\'component name not recognised: \' + comp + \', components must be lower case\')\n        rtn = fact * (1 / (e * norm))\n    rtn[0, 0] = 0.0\n    return rtn\n\n\n# noinspection PyTypeChecker\ndef elastic_influence_matrix_spatial(comp: str, span: typing.Sequence[int], grid_spacing: typing.Sequence[float],\n                                     shear_mod: float, v: float,\n                                     shear_mod_2: typing.Optional[float] = None,\n                                     v_2: typing.Optional[float] = None) -> np.array:\n    """Find influence matrix components for an elastic contact problem\n\n    Parameters\n    ----------\n    comp : str {\'xx\',\'xy\',\'xz\',\'yx\',\'yy\',\'yz\',\'zx\',\'zy\',\'zz\'}\n        The component to be returned\n    span: Sequence[int]\n        The span of the influence matrix in the x and y directions\n    grid_spacing: Sequence[float]\n        The grid spacings in the x and y directions\n    shear_mod : float\n        The shear modulus of the surface material\n    v : float\n        The Poission\'s ratio of the surface material\n    shear_mod_2: float (optional) None\n        The shear modulus of the second surface for a combined stiffness matrix\n    v_2: float (optional) None\n        The Poisson\'s ratio of the second surface for a combined stiffness matrix\n    fft: bool\n        If true the fft of the influence matrix will be returned\n\n    Returns\n    -------\n    C : array\n        The influence matrix component requested\n\n    See Also\n    --------\n    elastic_im\n\n    Notes\n    -----\n\n    Don\'t use this function, used by: elastic_im\n\n    References\n    ----------\n    Complete boundary element method formulation for normal and tangential\n    contact problems\n\n    """\n    span = tuple(span)\n    try:\n        # lets just see how this changes\n        # i\'-i and j\'-j\n        idmi = (np.arange(span[1]) - span[1] // 2 + (1 - span[1] % 2))\n        jdmj = (np.arange(span[0]) - span[0] // 2 + (1 - span[0] % 2))\n        mesh_idmi = np.tile(idmi, (span[0], 1))\n        mesh_jdmj = np.tile(np.expand_dims(jdmj, -1), (1, span[1]))\n\n    except TypeError:\n        raise TypeError("Span should be a tuple of integers")\n\n    k = mesh_idmi + 0.5\n    el = mesh_idmi - 0.5\n    m = mesh_jdmj + 0.5\n    n = mesh_jdmj - 0.5\n\n    hy = grid_spacing[1]\n    hx = grid_spacing[0]\n\n    second_surface = (shear_mod_2 is not None) and (v_2 is not None)\n    if not second_surface:\n        v_2 = 1\n        shear_mod_2 = 1\n\n    if (shear_mod_2 is not None) != (v_2 is not None):\n        raise ValueError(\'Either both or neither of the second surface parameters must be set\')\n\n    if comp == \'zz\':\n        c_zz = (hx * (k * np.log((m + np.sqrt(k ** 2 + m ** 2)) / (n + np.sqrt(k ** 2 + n ** 2))) +\n                      el * np.log((n + np.sqrt(el ** 2 + n ** 2)) / (m + np.sqrt(el ** 2 + m ** 2)))) +\n                hy * (m * np.log((k + np.sqrt(k ** 2 + m ** 2)) / (el + np.sqrt(el ** 2 + m ** 2))) +\n                      n * np.log((el + np.sqrt(el ** 2 + n ** 2)) / (k + np.sqrt(k ** 2 + n ** 2)))))\n\n        const = (1 - v) / (2 * np.pi * shear_mod) + second_surface * ((1 - v_2) / (2 * np.pi * shear_mod_2))\n        ret = const * c_zz\n    elif comp == \'xx\':\n        c_xx = (hx * (1 - v) * (k * np.log((m + np.sqrt(k ** 2 + m ** 2)) / (n + np.sqrt(k ** 2 + n ** 2))) +\n                                el * np.log(\n                (n + np.sqrt(el ** 2 + n ** 2)) / (m + np.sqrt(el ** 2 + m ** 2)))) +\n                hy * (m * np.log((k + np.sqrt(k ** 2 + m ** 2)) / (el + np.sqrt(el ** 2 + m ** 2))) +\n                      n * np.log((el + np.sqrt(el ** 2 + n ** 2)) / (k + np.sqrt(k ** 2 + n ** 2)))))\n        const = 1 / (2 * np.pi * shear_mod) + second_surface * (1 / (2 * np.pi * shear_mod_2))\n        ret = const * c_xx\n    elif comp == \'yy\':\n        c_yy = (hx * (k * np.log((m + np.sqrt(k ** 2 + m ** 2)) / (n + np.sqrt(k ** 2 + n ** 2))) +\n                      el * np.log((n + np.sqrt(el ** 2 + n ** 2)) / (m + np.sqrt(el ** 2 + m ** 2)))) +\n                hy * (1 - v) * (m * np.log((k + np.sqrt(k ** 2 + m ** 2)) / (el + np.sqrt(el ** 2 + m ** 2))) +\n                                n * np.log((el + np.sqrt(el ** 2 + n ** 2)) / (k + np.sqrt(k ** 2 + n ** 2)))))\n        const = 1 / (2 * np.pi * shear_mod) + second_surface * (1 / (2 * np.pi * shear_mod_2))\n        ret = const * c_yy\n    elif comp in [\'xz\', \'zx\']:\n        c_xz = (hy / 2 * (m * np.log((k ** 2 + m ** 2) / (el ** 2 + m ** 2)) +\n                          n * np.log((el ** 2 + n ** 2) / (k ** 2 + n ** 2))) +\n                hx * (k * (np.arctan(m / k) - np.arctan(n / k)) +\n                      el * (np.arctan(n / el) - np.arctan(m / el))))\n        const = ((2 * v - 1) / (4 * np.pi * shear_mod) + second_surface * (\n            (2 * v_2 - 1) / (4 * np.pi * shear_mod_2))) * (-1 if comp == \'zx\' else 1)\n        ret = const * c_xz\n    elif comp in [\'yx\', \'xy\']:\n        c_yx = (np.sqrt(hy ** 2 * n ** 2 + hx ** 2 * k ** 2) -\n                np.sqrt(hy ** 2 * m ** 2 + hx ** 2 * k ** 2) +\n                np.sqrt(hy ** 2 * m ** 2 + hx ** 2 * el ** 2) -\n                np.sqrt(hy ** 2 * n ** 2 + hx ** 2 * el ** 2))\n        const = v / (2 * np.pi * shear_mod) + second_surface * (v_2 / (2 * np.pi * shear_mod_2))\n        ret = const * c_yx\n    elif comp in [\'zy\', \'yz\']:\n        c_zy = (hx / 2 * (k * np.log((k ** 2 + m ** 2) / (n ** 2 + k ** 2)) +\n                          el * np.log((el ** 2 + n ** 2) / (m ** 2 + el ** 2))) +\n                hy * (m * (np.arctan(k / m) - np.arctan(el / m)) +\n                      n * (np.arctan(el / n) - np.arctan(k / n))))\n        const = ((1 - 2 * v) / (4 * np.pi * shear_mod) + second_surface * (1 - 2 * v_2) / (\n            4 * np.pi * shear_mod_2)) * (-1 if comp == \'zy\' else 1)\n        ret = const * c_zy\n    else:\n        ValueError(\'component name not recognised: \' + comp + \', components must be lower case\')\n    return ret\n', 'is_package': False},
    'slippy.core.gmres': {'source': 'import slippy\nimport typing\nimport numpy as np\n\n__all__ = [\'gmres\']\n\ntry:\n    import cupy as cp\n\n    def _cuda_rotmat(a: float, b: float) -> (float, float):\n        """ Find the given\'s rotation matrix\n        """\n        t = cp.sqrt(a ** 2 + b ** 2)\n        c = a / t\n        s = b / t\n        return c, s\n\n    def _cuda_gmres(f: typing.Callable, x: cp.ndarray, b: cp.ndarray, restart: int, max_it: int, tol: float,\n                    m_inv: typing.Callable = None):\n        x = cp.array(x)\n        n = x.size\n        b = cp.array(b)\n        precon = m_inv is not None\n        it_num = 0\n        flag = 0\n        norm_b = cp.linalg.norm(b) or 1.0\n        r = b - f(x)\n        if precon:\n            r = m_inv(r)\n        error = cp.linalg.norm(r) / norm_b\n        if error <= tol:\n            return x, error, it_num, flag\n        m = restart\n        V = cp.zeros((n, m + 1))\n        H = cp.zeros((m + 1, m))\n        cs = cp.zeros(m)\n        sn = cp.zeros(m)\n        e1 = cp.zeros(n)\n        e1[0] = 1.0\n        while True:\n            r = b - f(x)\n            if precon:\n                r = m_inv(r)\n            norm_r = cp.linalg.norm(r)\n            V[:, 0] = r / norm_r\n            s = norm_r * e1\n            for i in range(m):\n                w = f(V[:, i])\n                if precon:\n                    w = m_inv(w)\n                for k in range(i + 1):\n                    H[k, i] = cp.dot(w, V[:, k])\n                    w = w - H[k, i] * V[:, k]\n                H[i + 1, i] = cp.linalg.norm(w)\n                V[:, i + 1] = w / H[i + 1, i]\n                for k in range(i):\n                    temp = cs[k] * H[k, i] + sn[k] * H[k + 1, i]\n                    H[k + 1, i] = -sn[k] * H[k, i] + cs[k] * H[k + 1, i]\n                    H[k, i] = temp\n                cs[i], sn[i] = _cuda_rotmat(H[i, i], H[i + 1, i])\n                temp = cs[i] * s[i]\n                norm_r = -sn[i] * s[i]\n                if i + 1 < m:\n                    s[i + 1] = norm_r\n                s[i] = temp\n                H[i, i] = cs[i] * H[i, i] + sn[i] * H[i + 1, i]\n                H[i + 1, i] = 0.0\n                error = cp.abs(norm_r) / norm_b\n                if error <= tol:\n                    y = cp.linalg.lstsq(H[:i + 1, :i + 1], s[:i + 1], rcond=None)[0]\n                    x = x + cp.dot(V[:, :i + 1], y).flatten()\n                    break\n            if error <= tol:\n                break\n            y = cp.linalg.lstsq(H[:m + 1, :m + 1], s[:m + 1], rcond=None)[0]\n            x = x + cp.dot(V[:, :m], y).flatten()\n            r = b - f(x)\n            if precon:\n                r = m_inv(r)\n            error = cp.linalg.norm(r) / norm_b\n            if i + 1 < n:\n                s[i + 1] = cp.linalg.norm(r)\n            if error <= tol:\n                break\n            if max_it is not None and it_num >= max_it:\n                break\n            it_num += 1\n        if error > tol:\n            flag = 1\n        return x, error, it_num, flag\n\nexcept ImportError:\n    _cuda_gmres = None\n    cp = None\n\n\ndef _rotmat(a: float, b: float) -> (float, float):\n    """ Find the given\'s rotation matrix\n    """\n    t = np.sqrt(a**2 + b**2)\n    c = a/t\n    s = b/t\n    return c, s\n\n\ndef _fftw_gmres(f: typing.Callable, x: np.ndarray, b: np.ndarray, restart: int, max_it: int, tol: float,\n                m_inv: typing.Callable = None):\n    x = np.array(x)\n    n = x.size\n    b = np.array(b)\n    precon = m_inv is not None\n    it_num = 0\n    flag = 0\n    norm_b = np.linalg.norm(b) or 1.0\n    r = b - f(x)\n    if precon:\n        r = m_inv(r)\n    error = np.linalg.norm(r) / norm_b\n    if error <= tol:\n        return x, error, it_num, flag\n    m = restart\n    V = np.zeros((n, m + 1))\n    H = np.zeros((m + 1, m))\n    cs = np.zeros(m)\n    sn = np.zeros(m)\n    e1 = np.zeros(n)\n    e1[0] = 1.0\n    while True:\n        r = b - f(x)\n        if precon:\n            r = m_inv(r)\n        norm_r = np.linalg.norm(r)\n        V[:, 0] = r / norm_r\n        s = norm_r * e1\n        for i in range(m):\n            w = f(V[:, i])\n            if precon:\n                w = m_inv(w)\n            for k in range(i + 1):\n                H[k, i] = np.dot(w, V[:, k])\n                w = w - H[k, i] * V[:, k]\n            H[i + 1, i] = np.linalg.norm(w)\n            V[:, i + 1] = w / H[i + 1, i]\n            for k in range(i):\n                temp = cs[k] * H[k, i] + sn[k] * H[k + 1, i]\n                H[k + 1, i] = -sn[k] * H[k, i] + cs[k] * H[k + 1, i]\n                H[k, i] = temp\n            cs[i], sn[i] = _rotmat(H[i, i], H[i + 1, i])\n            temp = cs[i] * s[i]\n            norm_r = -sn[i] * s[i]\n            if i + 1 < m:\n                s[i + 1] = norm_r\n            s[i] = temp\n            H[i, i] = cs[i] * H[i, i] + sn[i] * H[i + 1, i]\n            H[i + 1, i] = 0.0\n            error = np.abs(norm_r) / norm_b\n            if error <= tol:\n                y = np.linalg.lstsq(H[:i + 1, :i + 1], s[:i + 1], rcond=None)[0]\n                x = x + np.dot(V[:, :i + 1], y).flatten()\n                break\n        if error <= tol:\n            break\n        y = np.linalg.lstsq(H[:m + 1, :m + 1], s[:m + 1], rcond=None)[0]\n        x = x + np.dot(V[:, :m], y).flatten()\n        r = b - f(x)\n        if precon:\n            r = m_inv(r)\n        error = np.linalg.norm(r) / norm_b\n        if i + 1 < n:\n            s[i + 1] = np.linalg.norm(r)\n        if error <= tol:\n            break\n        if max_it is not None and it_num >= max_it:\n            break\n        it_num += 1\n    if error > tol:\n        flag = 1\n    return x, error, it_num, flag\n\n\ndef gmres(f: typing.Callable, x0, b, restart: int, max_it: int, tol: float,\n          m_inv: typing.Callable = None, override_cuda: bool = False):\n    """Generalised minimum residual solver\n\n    Parameters\n    ----------\n    f: callable\n        A callable representing the matrix vector product of a linear transformation, if the matrix has been\n        preconditioned m_inv should also be supplied\n    x0: array like\n        An initial guess for the solution to the linear system\n    b: array like\n        The right hand side of the system\n    restart: int\n        The number of iterations between each restart of the solver. A higher number of iterations generally leads to\n        faster convergence but iterations are more computationally costly.\n    max_it: int\n        The maximum number of restarts used, note: the total number of iterations will be max_it*restart\n    tol: float\n        The normalised residual used for convergence. When norm(residual)/ norm(b) is smaller than this\n        tolerance the solver will exit.\n    m_inv: callable, optional (None)\n        An optional inverse preconditioner\n    override_cuda: bool, optional (False)\n        If True this method will only use the CPU implementation, regardless of the slippy.CUDA property, otherwise uses\n        the GPU implementation if slippy.CUDA is True\n    Returns\n    -------\n    x: array like\n        The solution vector\n    failed: bool\n        True of the solver failed to converge, otherwise False\n\n    Examples\n    --------\n    >>> n = 6\n    >>> A = np.tril(np.ones((n,n)))\n    >>> b = np.ones(n)\n    >>> x0 = b*0\n    >>> f = lambda x: np.dot(A,x)\n    >>> x, failed = gmres(f, x0, b, 4, n, 1e-6)\n    x = array([ 1.00000160e+00, -1.62101904e-06,  2.15819307e-08, -1.05948284e-06, 2.47057595e-06, -1.95291141e-06])\n    """\n    if slippy.CUDA and not override_cuda:\n        x, _, _, failed = _cuda_gmres(f, x0, b, restart, max_it, tol, m_inv)\n    else:\n        x, _, _, failed = _fftw_gmres(f, x0, b, restart, max_it, tol, m_inv)\n    return x, failed\n', 'is_package': False},
    'slippy.core.influence_matrix_utils': {'source': 'import numpy as np\nimport typing\nimport warnings\nimport slippy\nimport functools\nimport abc\n\n__all__ = [\'guess_loads_from_displacement\', \'bccg\', \'plan_convolve\', \'plan_multi_convolve\', \'plan_coupled_convolve\',\n           \'polonsky_and_keer\', \'rey\', \'ConvolutionFunction\']\n\n\ndef guess_loads_from_displacement(displacements_z: np.array, zz_component: np.array) -> np.array:\n    """\n    Defines the starting point for the default loads from displacement method\n\n    Parameters\n    ----------\n    displacements_z: np.array\n        The point wise displacement\n    zz_component: dict\n        Dict of influence matrix components\n\n    Returns\n    -------\n    guess_of_loads: np.array\n        A named tuple of the loads\n    """\n\n    max_im = max(zz_component)\n    return displacements_z / max_im\n\n\nclass ConvolutionFunction(abc.ABC):\n    def __init__(self):\n        pass\n\n    @abc.abstractmethod\n    def inner_with_domain(self, sub_loads, ignore_domain=False):\n        pass\n\n    @abc.abstractmethod\n    def inner_no_domain(self, full_loads, _):\n        pass\n\n    @abc.abstractmethod\n    def inverse_conv(self, deformations, ignore_domain):\n        pass\n\n    @abc.abstractmethod\n    def change_domain(self, new_domain):\n        pass\n\n    @abc.abstractmethod\n    def __call__(self, loads, ignore_domain):\n        pass\n\n\ntry:\n    import cupy as cp\n\n    def n_pow_2(a):\n        return 2 ** int(np.ceil(np.log2(a)))\n\n    class CudaConvolutionFunction(ConvolutionFunction):\n\n        def __init__(self, loads: np.ndarray, im: np.ndarray, domain: np.ndarray,\n                     circular: typing.Sequence[bool], fft_im: bool = True):\n            """Plans an FFT convolution, CUDA implementation\n\n            Parameters\n            ----------\n            loads: np.ndarray\n                An example of a loads array, this is not altered or stored\n            im: np.ndarray\n                The influence matrix component for the transformation, this is not altered but it\'s fft is stored to\n                save time during convolution, this must be larger in every dimension than the loads array\n            domain: np.ndarray, optional\n                Array with same shape as loads filled with boolean values. If supplied this function will return a\n                function which first fills the supplied loads into the domain then computes the convolution.\n                This is typically used for finding loads from set displacements as the displacements are often not set\n                over the whole surface.\n            circular: Sequence[bool], optional (False)\n                If True the circular convolution will be calculated, to be used for periodic simulations\n\n            Notes\n            -----\n            This function uses CUDA to run on a GPU if your computer dons\'t have cupy installed this should not have\n            loaded if it is for some reason, this can be manually overridden by first importing slippy then setting the\n            CUDA variable to False:\n\n            >>> import slippy\n            >>> slippy.CUDA = False\n            >>> import slippy.contact\n            >>> ...\n\n            Examples\n            --------\n            >>> import numpy as np\n            >>> import slippy.contact as c\n            >>> result = c.hertz_full([1,1], [np.inf, np.inf], [200e9, 200e9], [0.3, 0.3], 1e4)\n            >>> X,Y = np.meshgrid(*[np.linspace(-0.005,0.005,256)]*2)\n            >>> grid_spacing = X[1][1]-X[0][0]\n            >>> loads = result[\'pressure_f\'](X,Y)\n            >>> disp_analytical = result[\'surface_displacement_b_f\'][0](X,Y)[\'uz\']\n            >>> im = c.elastic_influence_matrix_spatial(\'zz\', (512,512), (grid_spacing,grid_spacing),\n            >>>                                         200e9/(2*(1+0.3)), 0.3)\n            >>> convolve_func = plan_convolve(loads, im, None, [False, False])\n            >>> disp_numerical = convolve_func(loads)\n\n            """\n            super().__init__()\n            loads = cp.asarray(loads)\n            im = cp.asarray(im)\n            im_shape_orig = im.shape\n            if domain is not None:\n                domain = cp.asarray(domain)\n            self._domain = domain\n            input_shape = []\n            for i in range(2):\n                if circular[i]:\n                    assert loads.shape[i] == im.shape[i], "For circular convolution loads and im must be same shape"\n                    input_shape.append(loads.shape[i])\n                else:\n                    msg = "For non circular convolution influence matrix must be double loads"\n                    assert loads.shape[i] == im.shape[i] // 2, msg\n                    input_shape.append(loads.shape[i])\n            input_shape = tuple(input_shape)\n            fft_shape = [max(i, f) for i, f in zip(input_shape, im_shape_orig)]\n            self.forward_trans = functools.partial(cp.fft.fft2, s=fft_shape)\n            self.backward_trans = functools.partial(cp.fft.ifft2, s=fft_shape)\n            self.norm_inv = (input_shape[0] * input_shape[1]) ** 0.5\n            norm = 1 / self.norm_inv\n            self.norm = norm\n            if fft_im:\n                self.fft_im = im\n            else:\n                im = cp.roll(im, tuple(-((sz - 1) // 2) for sz in im_shape_orig), (-2, -1))\n                self.fft_im = self.forward_trans(im)\n            self.inv_fft_im = 1 / self.fft_im\n\n            if cp.isinf(self.inv_fft_im[0, 0]):\n                self.inv_fft_im[0, 0] = 0.0\n\n            self.shape = loads.shape\n            self.dtype = loads.dtype\n\n            if domain is None:\n                self.callback = self.inner_no_domain\n            else:\n                self.callback = self.inner_with_domain\n\n        def inner_with_domain(self, sub_loads, ignore_domain=False):\n            full_loads = cp.zeros(self.shape, dtype=self.dtype)\n            full_loads[self._domain] = sub_loads\n            fft_loads = self.forward_trans(full_loads)\n            full = cp.real(self.backward_trans(fft_loads * self.fft_im))\n            full = full[:full_loads.shape[0], :full_loads.shape[1]]\n            if ignore_domain:\n                return full\n            return full[self._domain]\n\n        def inner_no_domain(self, full_loads, _):\n            full_loads = cp.asarray(full_loads)\n            if full_loads.shape == self.shape:\n                flat = False\n            else:\n                full_loads = cp.reshape(full_loads, self.shape)\n                flat = True\n            fft_loads = self.forward_trans(full_loads)\n            full = cp.real(self.backward_trans(fft_loads * self.fft_im))\n            full = full[:full_loads.shape[0], :full_loads.shape[1]]\n            if flat:\n                full = full.flatten()\n            return full\n\n        def inverse_conv(self, deformations, ignore_domain):\n            if self._domain is not None:\n                full_defs = cp.zeros(self.shape, dtype=self.dtype)\n                full_defs[self._domain] = deformations\n                flat = False\n            else:\n                full_defs = deformations\n                if full_defs.shape == self.shape:\n                    flat = False\n                else:\n                    full_defs = cp.reshape(full_defs, self.shape)\n                    flat = True\n            fft_defs = self.forward_trans(full_defs)\n            full = cp.real(self.backward_trans(fft_defs * self.inv_fft_im))\n            full = full[:full_defs.shape[0], :full_defs.shape[1]]\n            if ignore_domain:\n                return full\n            if flat:\n                return full.flatten()\n            return full[self._domain]\n\n        def change_domain(self, new_domain):\n            self._domain = new_domain\n\n        def __call__(self, loads, ignore_domain=False):\n            return self.callback(loads, ignore_domain)\n\n    def _plan_cuda_multi_convolve(loads: np.ndarray, ims: np.ndarray, domain: np.ndarray = None,\n                                  circular: typing.Sequence[bool] = (False, False), fft_im: bool = True):\n        """Plans an FFT convolution, returns a function to carry out the convolution\n        CUDA implementation\n\n        Parameters\n        ----------\n        loads: np.ndarray\n            An example of a loads array, this is not altered or stored\n        ims: np.ndarray\n            The influence matrix component for the transformation, this is not altered but it\'s fft is stored to\n            save time during convolution, this must be larger in every dimension than the loads array\n        domain: np.ndarray, optional\n            Array with same shape as loads filled with boolean values. If supplied this function will return a\n            function which first fills the supplied loads into the domain then computes the convolution.\n            This is typically used for finding loads from set displacements as the displacements are often not set\n            over the whole surface.\n        circular: Sequence[bool], optional (False)\n            If True the circular convolution will be calculated, to be used for periodic simulations\n        fft_im: bool, optional (True)\n            True if the supplied influence matrix is already in the frequency domain, note the full fft is expected,\n            including redundant elements\n\n        Returns\n        -------\n        function\n            A function which takes a single input of loads and returns the result of the convolution with the original\n            influence matrix. If a domain was not supplied the input to the returned function must be exactly the same\n            shape as the loads array used in this function. If a domain was specified the length of the loads input to\n            the returned function must be the same as the number of non zero elements in domain.\n\n        Notes\n        -----\n        This function uses CUDA to run on a GPU if your computer dons\'t have cupy installed this should not have loaded\n        if it is for some reason, this can be manually overridden by first importing slippy then setting the CUDA\n        variable to False:\n\n        >>> import slippy\n        >>> slippy.CUDA = False\n        >>> import slippy.contact\n        >>> ...\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import slippy.contact as c\n        >>> result = c.hertz_full([1,1], [np.inf, np.inf], [200e9, 200e9], [0.3, 0.3], 1e4)\n        >>> X,Y = np.meshgrid(*[np.linspace(-0.005,0.005,256)]*2)\n        >>> grid_spacing = X[1][1]-X[0][0]\n        >>> loads = result[\'pressure_f\'](X,Y)\n        >>> disp_analytical = result[\'surface_displacement_b_f\'][0](X,Y)[\'uz\']\n        >>> im = c.elastic_influence_matrix_spatial(\'zz\', (512,512), (grid_spacing,grid_spacing), 200e9/(2*(1+0.3)), 0.3)\n        >>> convolve_func = plan_convolve(loads, im, None, [False, False])\n        >>> disp_numerical = convolve_func(loads)\n\n        """\n        loads = cp.asarray(loads)\n        im = cp.asarray(ims[0])\n        im_shape_orig = im.shape\n        if domain is not None:\n            domain = cp.asarray(domain)\n        input_shape = []\n        for i in range(2):\n            if circular[i]:\n                assert loads.shape[i] == im.shape[i], "For circular convolution loads and im must be same shape"\n                input_shape.append(loads.shape[i])\n            else:\n                msg = "For non circular convolution influence matrix must be double loads"\n                assert loads.shape[i] == im.shape[i] // 2, msg\n                input_shape.append(n_pow_2(max(loads.shape[i], im.shape[i])))\n\n        input_shape = tuple(input_shape)\n        fft_shape = tuple([input_shape[0], input_shape[1]])\n        forward_trans = functools.partial(cp.fft.fft2, s=fft_shape)\n        backward_trans = functools.partial(cp.fft.ifft2, s=input_shape)\n        shape_diff = [[0, (b - a)] for a, b in zip(im.shape, input_shape)]\n\n        norm_inv = (input_shape[0] * input_shape[1]) ** 0.5\n        norm = 1 / norm_inv\n        if fft_im:\n            fft_ims = cp.asarray(ims * norm)\n        else:\n            fft_ims = cp.zeros((len(ims), *input_shape), dtype=cp.complex128)\n            for i in range(len(ims)):\n                im = cp.asarray(ims[i])\n                im = cp.pad(im, shape_diff, mode=\'constant\')\n                im = cp.roll(im, tuple(-((sz - 1) // 2) for sz in im_shape_orig), (-2, -1))\n                fft_ims[i] = forward_trans(im) * norm\n        shape = loads.shape\n        dtype = loads.dtype\n\n        def inner_no_domain(full_loads):\n            full_loads = cp.asarray(full_loads)\n            all_results = cp.zeros((len(fft_ims), *full_loads.shape))\n            if full_loads.shape == shape:\n                flat = False\n            else:\n                full_loads = cp.reshape(full_loads, loads.shape)\n                flat = True\n            fft_loads = forward_trans(full_loads)\n            for i in range(len(ims)):\n                full = norm_inv * cp.real(backward_trans(fft_loads * fft_ims[i]))\n                full = full[:full_loads.shape[0], :full_loads.shape[1]]\n                if flat:\n                    full = full.flatten()\n                all_results[i] = full\n            return all_results\n\n        def inner_with_domain(sub_loads, ignore_domain=False):\n            full_loads = cp.zeros(shape, dtype=dtype)\n            full_loads[domain] = sub_loads\n\n            if ignore_domain:\n                all_results = cp.zeros((len(fft_ims), *full_loads.shape))\n            else:\n                all_results = cp.zeros((len(fft_ims), *sub_loads.shape))\n\n            fft_loads = forward_trans(full_loads)\n            for i in range(len(ims)):\n                full = norm_inv * cp.real(backward_trans(fft_loads * fft_ims[i]))\n                full = full[:full_loads.shape[0], :full_loads.shape[1]]\n                if ignore_domain:\n                    all_results[i] = full\n                else:\n                    all_results[i] = full[domain]\n            return all_results\n\n        if domain is None:\n            return inner_no_domain\n        else:\n            return inner_with_domain\n\nexcept ImportError:\n    cp = None\n    _plan_cuda_convolve = None\n    _plan_cuda_multi_convolve = None\n\ntry:\n    import pyfftw\n\n    class FftwConvolutionFunction(ConvolutionFunction):\n        def __init__(self, loads: np.ndarray, im: np.ndarray, domain: np.ndarray, circular: typing.Sequence[bool],\n                     fft_im: bool = True):\n            """Plans an FFT convolution, returns a function to carry out the convolution\n            FFTW implementation\n\n            Parameters\n            ----------\n            loads: np.ndarray\n                An example of a loads array, this is not altered or stored\n            im: np.ndarray\n                The influence matrix component for the transformation, this is not altered but it\'s fft is stored to\n                save time during convolution, this must be larger in every dimension than the loads array\n            domain: np.ndarray, optional (None)\n                Array with same shape as loads filled with boolean values. If supplied this function will return a\n                function which first fills the supplied loads into the domain then computes the convolution.\n                This is typically used for finding loads from set displacements as the displacements are often not set\n                over the whole surface.\n            circular: Sequence[bool]\n                If True the circular convolution will be calculated, to be used for periodic simulations\n            fft_im: bool, optional (True)\n\n\n            Notes\n            -----\n            This function uses FFTW, if you want to use the CUDA implementation make sure that cupy is installed and\n            importable. If cupy can be imported slippy will use the CUDA implementations by default\n\n            Examples\n            --------\n            >>> import numpy as np\n            >>> import slippy.contact as c\n            >>> result = c.hertz_full([1,1], [np.inf, np.inf], [200e9, 200e9], [0.3, 0.3], 1e4)\n            >>> X,Y = np.meshgrid(*[np.linspace(-0.005,0.005,256)]*2)\n            >>> grid_spacing = X[1][1]-X[0][0]\n            >>> loads = result[\'pressure_f\'](X,Y)\n            >>> disp_analytical = result[\'surface_displacement_b_f\'][0](X,Y)[\'uz\']\n            >>> im = c.elastic_influence_matrix_spatial(\'zz\', (512,512), (grid_spacing,grid_spacing),\n            >>>                                         200e9/(2*(1+0.3)), 0.3)\n            >>> convolve_func = plan_convolve(loads, im, None, [False, False])\n            >>> disp_numerical = convolve_func(loads)\n\n            """\n            super().__init__()\n            loads = np.asarray(loads)\n            self._loads_shape = loads.shape\n            im = np.asarray(im)\n            im_shape_orig = im.shape\n            if domain is not None:\n                domain = np.asarray(domain, dtype=bool)\n            self._domain = domain\n            input_shape = []\n            for i in range(2):\n                if circular[i]:\n                    assert loads.shape[i] == im.shape[i], "For circular convolution loads and im must be same shape"\n                    input_shape.append(im.shape[i])\n                else:\n                    msg = "For non circular convolution influence matrix must be double loads"\n                    assert loads.shape[i] == im.shape[i] // 2, msg\n                    input_shape.append(im.shape[i])\n            input_shape = tuple(input_shape)\n\n            fft_shape = [input_shape[0], input_shape[1] // 2 + 1]\n            in_empty = pyfftw.empty_aligned(input_shape, dtype=loads.dtype)\n            out_empty = pyfftw.empty_aligned(fft_shape, dtype=\'complex128\')\n            ret_empty = pyfftw.empty_aligned(input_shape, dtype=loads.dtype)\n            self.forward_trans = pyfftw.FFTW(in_empty, out_empty, axes=(0, 1),\n                                             direction=\'FFTW_FORWARD\', threads=slippy.CORES)\n            self.backward_trans = pyfftw.FFTW(out_empty, ret_empty, axes=(0, 1),\n                                              direction=\'FFTW_BACKWARD\', threads=slippy.CORES)\n            self.norm_inv = self.forward_trans.N ** 0.5\n            norm = 1 / self.norm_inv\n            self.norm = norm\n\n            if fft_im:\n                self.fft_im = im[:fft_shape[0], :fft_shape[1]]\n            else:\n                im = np.roll(im, tuple(-((sz - 1) // 2) for sz in im_shape_orig), (-2, -1))\n                self.fft_im = self.forward_trans(im).copy()\n\n            with np.errstate(divide=\'ignore\'):\n                self.inv_fft_im = 1/self.fft_im\n            if np.isinf(self.inv_fft_im[0, 0]):\n                self.inv_fft_im[0, 0] = 0.0\n\n            self._shape_diff_loads = [[0, (b - a)] for a, b in zip(loads.shape, input_shape)]\n\n            self.shape = loads.shape\n            self.dtype = loads.dtype\n            self.all_circ = circular[0] and circular[1]\n\n            if domain is None:\n                self.callback = self.inner_no_domain\n            else:\n                self.callback = self.inner_with_domain\n\n        def inner_with_domain(self, sub_loads, ignore_domain=False):\n            full_loads = np.zeros(self.shape, dtype=self.dtype)\n            full_loads[self._domain] = sub_loads\n            loads_pad = np.pad(full_loads, self._shape_diff_loads, \'constant\')\n            full = self.backward_trans(self.forward_trans(loads_pad) * self.fft_im)\n            same = full[:full_loads.shape[0], :full_loads.shape[1]].copy()\n            if ignore_domain:\n                return same\n            return same[self._domain]\n\n        def inner_no_domain(self, full_loads, _):\n            if full_loads.shape == self.shape:\n                flat = False\n            else:\n                full_loads = np.reshape(full_loads, self.shape)\n                flat = True\n            loads_pad = np.pad(full_loads, self._shape_diff_loads, \'constant\')\n            full = self.backward_trans(self.forward_trans(loads_pad) * self.fft_im)\n            full = full[:full_loads.shape[0], :full_loads.shape[1]].copy()\n            if flat:\n                full = full.flatten()\n            return full\n\n        def inverse_conv(self, deformations, ignore_domain):\n            if not self.all_circ:\n                raise ValueError("Inverse convolution only possible with fully periodic contacts")\n            if self._domain is not None:\n                full_defs = np.zeros(self.shape, dtype=self.dtype)\n                full_defs[self._domain] = deformations\n                flat = False\n            else:\n                full_defs = deformations\n                if full_defs.shape == self.shape:\n                    flat = False\n                else:\n                    full_defs = np.reshape(full_defs, self.shape)\n                    flat = True\n            defs_pad = np.pad(full_defs, self._shape_diff_loads, \'constant\')\n            full = self.backward_trans(self.forward_trans(defs_pad) * self.inv_fft_im)\n            full = full[:self.shape[0], :self.shape[1]].copy()\n            if ignore_domain:\n                return full\n            if flat:\n                return full.flatten()\n            return full[self._domain]\n\n        def change_domain(self, new_domain):\n            self._domain = new_domain\n\n        def __call__(self, loads, ignore_domain=False):\n            return self.callback(loads, ignore_domain)\n\n    def _plan_fftw_multi_convolve(loads: np.ndarray, ims: np.ndarray, domain: np.ndarray = None,\n                                  circular: typing.Sequence[bool] = (False, False), fft_im: bool = True):\n        """Plans an FFT convolution, returns a function to carry out the convolution\n        FFTW implementation\n\n        Parameters\n        ----------\n        loads: np.ndarray\n            An example of a loads array, this is not altered or stored\n        ims: np.ndarray\n            The influence matrix components for the transformation, this is not altered but it\'s fft is stored to\n            save time during convolution, this must be larger in every dimension than the loads array\n        domain: np.ndarray, optional (None)\n            Array with same shape as loads filled with boolean values. If supplied this function will return a\n            function which first fills the supplied loads into the domain then computes the convolution.\n            This is typically used for finding loads from set displacements as the displacements are often not set\n            over the whole surface.\n        circular: Sequence[bool]\n            If True the circular convolution will be calculated, to be used for periodic simulations\n        fft_im: bool, optional (True)\n            True if the supplied influence matix is already in the frequency domain, note, the full fft inlcuding\n            redundant elementes is required\n\n        Returns\n        -------\n        function\n            A function which takes a single input of loads and returns the result of the convolution with the original\n            influence matrix. If a domain was not supplied the input to the returned function must be exactly the same\n            shape as the loads array used in this function. If a domain was specified the length of the loads input to\n            the returned function must be the same as the number of non zero elements in domain.\n\n        Notes\n        -----\n        This function uses FFTW, if you want to use the CUDA implementation make sure that cupy is installed and\n        importable. If cupy can be imported slippy will use the CUDA implementations by default\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import slippy.contact as c\n        >>> result = c.hertz_full([1,1], [np.inf, np.inf], [200e9, 200e9], [0.3, 0.3], 1e4)\n        >>> X,Y = np.meshgrid(*[np.linspace(-0.005,0.005,256)]*2)\n        >>> grid_spacing = X[1][1]-X[0][0]\n        >>> loads = result[\'pressure_f\'](X,Y)\n        >>> disp_analytical = result[\'surface_displacement_b_f\'][0](X,Y)[\'uz\']\n        >>> im = c.elastic_influence_matrix_spatial(\'zz\', (512,512), (grid_spacing,grid_spacing), 200e9/(2*(1+0.3)), 0.3)\n        >>> convolve_func = plan_convolve(loads, im, None, [False, False])\n        >>> disp_numerical = convolve_func(loads)\n\n        """\n        loads = slippy.asnumpy(loads)\n        im = np.asarray(ims[0])\n        im_shape_orig = im.shape\n        if domain is not None:\n            domain = slippy.asnumpy(domain)\n        input_shape = []\n        for i in range(2):\n            if circular[i]:\n                assert loads.shape[i] == im.shape[i], "For circular convolution loads and im must be same shape"\n                input_shape.append(loads.shape[i])\n            else:\n                msg = "For non circular convolution influence matrix must be double loads"\n                assert loads.shape[i] == im.shape[i] // 2, msg\n                input_shape.append(im.shape[i])\n        input_shape = (len(ims),) + tuple(input_shape)\n\n        fft_shape = [input_shape[0], input_shape[1], input_shape[2] // 2 + 1]\n        ims_in_empty = pyfftw.empty_aligned(input_shape, dtype=\'float64\')\n        ims_out_empty = pyfftw.empty_aligned(fft_shape, dtype=\'complex128\')\n        loads_in_empty = pyfftw.empty_aligned(input_shape[-2:], dtype=\'float64\')\n        loads_out_empty = pyfftw.empty_aligned(fft_shape[-2:], dtype=\'complex128\')\n        ret_empty = pyfftw.empty_aligned(input_shape, dtype=\'float64\')\n\n        forward_trans_ims = pyfftw.FFTW(ims_in_empty, ims_out_empty, axes=(1, 2),\n                                        direction=\'FFTW_FORWARD\', threads=slippy.CORES)\n        forward_trans_loads = pyfftw.FFTW(loads_in_empty, loads_out_empty, axes=(0, 1),\n                                          direction=\'FFTW_FORWARD\', threads=slippy.CORES)\n        backward_trans_ims = pyfftw.FFTW(ims_out_empty, ret_empty, axes=(1, 2),\n                                         direction=\'FFTW_BACKWARD\', threads=slippy.CORES)\n        norm_inv = forward_trans_loads.N ** 0.5\n        norm = 1 / norm_inv\n\n        if fft_im:\n            fft_ims = ims[:, :fft_shape[1], :fft_shape[2]] * norm\n        else:\n            shape_diff = [[0, (b - a)] for a, b in zip((len(ims),) + im.shape, input_shape)]\n            ims = np.pad(ims, shape_diff, \'constant\')\n            ims = np.roll(ims, tuple(-((sz - 1) // 2) for sz in im_shape_orig), (-2, -1))\n            fft_ims = forward_trans_ims(ims) * norm\n\n        shape_diff_loads = [[0, (b - a)] for a, b in zip(loads.shape, input_shape[1:])]\n\n        shape = loads.shape\n        dtype = loads.dtype\n\n        def inner_no_domain(full_loads):\n            if not isinstance(full_loads, np.ndarray):\n                full_loads = slippy.asnumpy(full_loads)\n            if full_loads.shape == shape:\n                flat = False\n            else:\n                full_loads = np.reshape(full_loads, shape)\n                flat = True\n            loads_pad = np.pad(full_loads, shape_diff_loads, \'constant\')\n            fft_loads = np.expand_dims(forward_trans_loads(loads_pad), 0)\n            full = backward_trans_ims(fft_loads * fft_ims)\n            full = norm_inv * full[:, :full_loads.shape[0], :full_loads.shape[1]]\n            if flat:\n                return full.reshape((len(fft_ims), -1))\n            return full\n\n        def inner_with_domain(sub_loads, ignore_domain=False):\n            if not isinstance(sub_loads, np.ndarray):\n                sub_loads = slippy.asnumpy(sub_loads)\n            full_loads = np.zeros(shape, dtype=dtype)\n            full_loads[domain] = sub_loads\n\n            loads_pad = np.pad(full_loads, shape_diff_loads, \'constant\')\n            fft_loads = np.expand_dims(forward_trans_loads(loads_pad), 0)\n            full = backward_trans_ims(fft_loads * fft_ims)\n            same = norm_inv * full[:, :full_loads.shape[0], :full_loads.shape[1]]\n            if ignore_domain:\n                return same\n            else:\n                return same[:, domain]\n\n        if domain is None:\n            return inner_no_domain\n        else:\n            return inner_with_domain\n\nexcept ImportError:\n    _plan_fftw_convolve = None\n    _plan_fftw_multi_convolve = None\n\n\ndef plan_convolve(loads, im, domain: np.ndarray = None, circular: typing.Union[bool, typing.Sequence[bool]] = False,\n                  fft_im: bool = True) -> ConvolutionFunction:\n    """Plans an FFT convolution, returns a function to carry out the convolution\n    CUDA / FFTW implementation\n\n    Parameters\n    ----------\n    loads: np.ndarray\n        An example of a loads array, this is not altered or stored\n    im: np.ndarray\n        The influence matrix component for the transformation, this is not altered but it\'s fft is stored to\n        save time during convolution, this must be larger in every dimension than the loads array\n    domain: np.ndarray, optional (None)\n        Array with same shape as loads filled with boolean values. If supplied this function will return a\n        function which first fills the supplied loads into the domain then computes the convolution.\n        This is typically used for finding loads from set displacements as the displacements are often not set\n        over the whole surface.\n    circular: bool or sequence of bool, optional (False)\n        If True the circular convolution will be computed, to be used for periodic simulations. Alternatively a 2\n        element sequence of bool can be provided specifying which axes are to be treated as periodic.\n    fft_im: bool, optional (True)\n        True if the supplied influence matrix is in the frequency domain, false if it is in the spatial domain\n\n    Returns\n    -------\n    ConvolutionFunction\n        A function which takes a single input of loads and returns the result of the convolution with the original\n        influence matrix. If a domain was not supplied the input to the returned function must be exactly the same\n        shape as the loads array used in this function. If a domain was specified the length of the loads input to\n        the returned function must be the same as the number of non zero elements in domain.\n\n    Notes\n    -----\n    By default this function uses CUDA to run on a GPU if your computer dosn\'t have cupy installed this should not\n    have loaded if it is for some reason, this can be manually overridden by first importing slippy then patching the\n    CUDA variable to False:\n\n    >>> import slippy\n    >>> slippy.CUDA = False\n    >>> import slippy.contact\n    >>> ...\n\n    If the CUDA version is used cp.asnumpy() will need to be called on the output for compatibility with np arrays,\n    Likewise the inputs to the convolution function should be cupy arrays.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import slippy.contact as c\n    >>> result = c.hertz_full([1,1], [np.inf, np.inf], [200e9, 200e9], [0.3, 0.3], 1e4)\n    >>> X,Y = np.meshgrid(*[np.linspace(-0.005,0.005,256)]*2)\n    >>> grid_spacing = X[1][1]-X[0][0]\n    >>> loads = result[\'pressure_f\'](X,Y)\n    >>> disp_analytical = result[\'surface_displacement_b_f\'][0](X,Y)[\'uz\']\n    >>> im = c.elastic_influence_matrix_spatial(\'zz\', (512,512), (grid_spacing,grid_spacing), 200e9/(2*(1+0.3)), 0.3)\n    >>> convolve_func = plan_convolve(loads, im)\n    >>> disp_numerical = convolve_func(loads)\n\n    """\n    if isinstance(circular, int):\n        circular = [circular, ] * 2\n    try:\n        length = len(circular)\n    except TypeError:\n        raise TypeError(\'Type of circular not recognised, should be a bool or a 2 element sequence of bool\')\n\n    if length != 2:\n        raise ValueError(f"Circular must be a bool or a 2 element list of bool, length was {length}")\n\n    if slippy.CUDA:\n        return CudaConvolutionFunction(loads, im, domain, circular, fft_im)\n    else:\n        return FftwConvolutionFunction(loads, im, domain, circular, fft_im)\n\n\ndef plan_multi_convolve(loads, ims: np.array, domain: np.ndarray = None,\n                        circular: typing.Union[bool, typing.Sequence[bool]] = False,\n                        cuda: bool = None, fft_ims: bool = True):\n    """Plans a set of FFT convolutions, returns a function to carry out the convolution\n    CUDA / FFTW implementation\n\n    Parameters\n    ----------\n    loads: np.ndarray\n        An example of a loads array, this is not altered or stored\n    ims: np.ndarray\n        The influence matrix components for the transformation, this is not altered but it\'s fft is stored to\n        save time during convolution, this must be larger or equal in every dimension than the loads array.\n        The first axis should index the compoents, eg a shape of (8, 64, 64), represents 8 kernels which are 64 by 64\n        each.\n    domain: np.ndarray, optional (None)\n        Array with same shape as loads filled with boolean values. If supplied this function will return a\n        function which first fills the supplied loads into the domain then computes the convolution.\n        This is typically used for finding loads from set displacements as the displacements are often not set\n        over the whole surface.\n    circular: bool or sequence of bool, optional (False)\n        If True the circular convolution will be computed, to be used for periodic simulations. Alternatively a 2\n        element sequence of bool can be provided specifying which axes are to be treated as periodic.\n    cuda: bool, optional (None)\n        If False the computation will be completed on the CPU, if True or None computation will be completed on the\n        gpu if slippy.CUDA is True\n    fft_ims: bool, optional (True)\n        True if the supplied influence matricies are in the frequency domain, note that the full fft of the influnce\n        matix is required, including redundant elements\n\n    Returns\n    -------\n    function\n        A function which takes a single input of loads and returns the result of the convolutions with the original\n        influence matrcies. If a domain was not supplied the input to the returned function must be exactly the same\n        shape as the loads array used in this function. If a domain was specified the length of the loads input to\n        the returned function must be the same as the number of non zero elements in domain. In every case the output\n        will be the same shape as the input, with an added first axis with the same length as the number of influence\n        matricies supplied.\n\n    Notes\n    -----\n    By default this function uses CUDA to run on a GPU if your computer dons\'t have cupy installed this should not\n    have loaded if it is for some reason, this can be manually overridden by first importing slippy then patching the\n    CUDA variable to False:\n\n    >>> import slippy\n    >>> slippy.CUDA = False\n    >>> import slippy.contact\n    >>> ...\n\n    If the CUDA version is used cp.asnumpy() or slippy.asnumpy() will need to be called on the output for compatibility\n    with numpy arrays.\n\n    Examples\n    --------\n    """\n    if isinstance(circular, int):\n        circular = [circular, ] * 2\n    try:\n        length = len(circular)\n    except TypeError:\n        raise TypeError(\'Type of circular not recognised, should be a bool or a 2 element sequence of bool\')\n\n    if length != 2:\n        raise ValueError(f"Circular must be a bool or a 2 element list of bool, length was {length}")\n\n    if cuda is None:\n        cuda = slippy.CUDA\n\n    if cuda:\n        return _plan_cuda_multi_convolve(loads, ims, domain, circular, fft_im=fft_ims)\n    else:\n        return _plan_fftw_multi_convolve(loads, ims, domain, circular, fft_im=fft_ims)\n\n\ndef polonsky_and_keer(f: typing.Callable, p0: typing.Sequence, just_touching_gap: typing.Sequence,\n                      target_load: float, grid_spacing: typing.Union[typing.Sequence[float], float],\n                      eps_0: float = 1e-6, max_it: int = None):\n    """ The Polonsky and Keer CG method for solving elastic contact (cuda and fftw versions)\n\n    Parameters\n    ----------\n    f: Callable\n        A function equivalent to multiplication by a non negative n by n matrix must work with cupy arrays.\n        Typically this function will be generated by slippy.contact.plan_convolve, this will guarantee\n        compatibility with different versions of this function (FFTW and CUDA).\n    p0: array\n        An initial guess of the pressure distribution, must not be all zeros\n    just_touching_gap: array\n        The gap function at the point of first contact between the surfaces, cen be generated by get_gap_from_model\n    target_load: float\n        The total target load (not average pressure)\n    grid_spacing: float or sequence of float\n        Either a float indicating a square grid, or a two element sequence indicating the dimensions of the rectangles\n        in the y and x directions respectively\n    eps_0: float\n        The error used as a convergence criterion\n    max_it: int, optional (None)\n        The maximum number of iterations used, defaults to the problem size\n\n    Returns\n    -------\n    failed: bool\n        True if the process failed to converge\n    pij: array\n        The pressure result on each point of the surface\n    gij: array\n        The deformed gap function\n\n    Notes\n    -----\n    This method does not directly calculate the rigid body approach\n\n    Examples\n    --------\n    >>> import slippy.core as core\n    >>> import slippy.surface as s\n    >>> import slippy.contact as c\n    >>> n = 128\n    >>> total_load = 100\n    >>> p = np.zeros((n,n))\n    >>> flat_surface = s.FlatSurface(shift=(0,0))\n    >>> round_surface = s.RoundSurface((1,1,1), extent = (0.0035, 0.0035),\n    >>>                                shape = (n, n), generate = True)\n    >>> gs = round_surface.grid_spacing\n    >>> e1 = 200e9; v1 = 0.3\n    >>> e2 = 70e9; v2 = 0.33\n    >>> im_1 = core.elastic_influence_matrix_spatial(\'zz\', span = (n*2,n*2), grid_spacing=(gs, gs),\n    >>>                                      shear_mod=e1/(2*(1+v1)), v=0.3)\n    >>> im_2 = core.elastic_influence_matrix_spatial(\'zz\', span = (n*2,n*2), grid_spacing=(gs, gs),\n    >>>                                      shear_mod=e2/(2*(1+v2)), v=0.33)\n    >>> im = im_1+im_2\n    >>> f = core.plan_convolve(p, im, domain=None, circular=False)\n    >>> model = c.ContactModel(\'model_1\', round_surface, flat_surface)\n    >>> just_touching_gap = c._model_utils.get_gap_from_model(model)[0]\n    >>> gs = [round_surface.grid_spacing, ]*2\n    >>> p0 = np.ones_like(just_touching_gap)\n    >>> failed, numerical_pressure, deformed_gap = polonsky_and_keer(f, p0, just_touching_gap,\n    >>>                                                              total_load, gs, eps_0=1e-7)\n\n    References\n    ----------\n    I.A. Polonsky, L.M. Keer,\n    A numerical method for solving rough contact problems based on the multi-level multi-summation and conjugate\n    gradient techniques, Wear, Volume 231, Issue 2, 1999, Pages 206-219, ISSN 0043-1648,\n    https://doi.org/10.1016/S0043-1648(99)00113-1. (https://www.sciencedirect.com/science/article/pii/S0043164899001131)\n\n    """\n    if np.sum(slippy.asnumpy(p0)) == 0:\n        raise ValueError("Initial pressure guess cannot sum to zero for polonsky_and_keer")\n    try:\n        float(grid_spacing)\n        grid_spacing = [grid_spacing, ] * 2\n    except TypeError:\n        pass\n\n    try:\n        assert len(grid_spacing) == 2, "Grid spacing must be a two element sequence or a number"\n    except TypeError:\n        raise ValueError("Grid spacing must be a two element sequence or a number")\n\n    if slippy.CUDA and cp is not None:\n        xp = cp\n    else:\n        xp = np\n\n    just_touching_gap = xp.array(just_touching_gap)\n    p0 = xp.array(p0)\n    if max_it is None:\n        max_it = just_touching_gap.size\n    # init\n    pij = p0 / xp.mean(p0) * target_load\n    delta = 0\n    g_big_old = 1\n    tij = 0\n    it_num = 0\n    element_area = grid_spacing[0] * grid_spacing[1]\n    while True:\n        uij = f(pij)\n        gij = uij + just_touching_gap\n        current_touching = pij > 0\n        g_bar = xp.mean(gij[current_touching])\n        gij = gij - g_bar\n        g_big = xp.sum(gij[current_touching] ** 2)\n        if it_num == 0:\n            tij = gij\n        else:\n            tij = gij + delta * (g_big / g_big_old) * tij\n        tij[xp.logical_not(current_touching)] = 0\n        g_big_old = g_big\n        rij = f(tij)\n        r_bar = xp.mean(rij[current_touching])\n        rij = rij - r_bar\n        if not xp.linalg.norm(rij):\n            tau = 0\n        else:\n            tau = (xp.dot(gij[current_touching], tij[current_touching]) /\n                   xp.dot(rij[current_touching], tij[current_touching]))\n        pij_old = pij\n        pij = pij - tau * tij\n        pij = xp.clip(pij, 0, xp.inf)\n        iol = xp.logical_and(pij == 0, gij < 0)\n        if xp.any(iol):\n            delta = 0\n            pij[iol] = pij[iol] - tau * gij[iol]\n        else:\n            delta = 1\n        p_big = element_area * xp.sum(pij)\n        pij = pij / p_big * target_load\n        eps = (element_area / target_load) * xp.sum(xp.abs(pij - pij_old))\n        if eps < eps_0:\n            failed = False\n            break\n        it_num += 1\n        if it_num > max_it:\n            failed = True\n            break\n        if xp.any(xp.isnan(pij)):\n            failed = True\n            break\n    return failed, pij, gij\n\n\ndef bccg(f: typing.Callable, b: np.ndarray, tol: float, max_it: int, x0: np.ndarray,\n         min_pressure: float = 0.0, max_pressure: float = np.inf, k_inn=1) -> typing.Tuple[np.ndarray, bool]:\n    """\n    The Bound-Constrained Conjugate Gradient Method for Non-negative Matrices\n\n    Parameters\n    ----------\n    f: Callable\n        A function equivalent to multiplication by a non negative n by n matrix must work with cupy arrays.\n        Typically this function will be generated by slippy.contact.plan_convolve, this will guarantee\n        compatibility with different versions of this function (FFTW and CUDA).\n    b: array\n        1 by n array of displacements\n    tol: float\n        The tolerance on the result\n    max_it: int\n        The maximum number of iterations used\n    x0: array\n        An initial guess of the solution\n    min_pressure: float, optional (0)\n        The minimum allowable pressure at each node, defaults to 0\n    max_pressure: float, optional (inf)\n        The maximum allowable pressure at each node, defaults to inf, for purely elastic contacts\n    k_inn: int\n\n    Returns\n    -------\n    x: cp.array/ np.array\n        The solution to the system f(x)-b = 0 with the constraints applied.\n    failed: bool\n        True if the solution failed to converge, this will also produce a warning\n\n    Notes\n    -----\n    This function uses the method described in the reference below, with some modification.\n    Firstly, this method allows both a minimum and maximum force to be set simulating quasi plastic regimes. The\n    code has also been optimised in several places and importantly this version has also been modified to run\n    on a GPU through cupy.\n\n    If you do not have a CUDA compatible GPU, slippy can be imported while falling back to the fftw version\n    by first importing slippy then patching the CUDA variable to False:\n\n    >>> import slippy\n    >>> slippy.CUDA = False\n    >>> import slippy.contact\n    >>> ...\n\n    Though this should happen automatically if you don\'t have cupy installed.\n\n    References\n    ----------\n    Vollebregt, E.A.H. The Bound-Constrained Conjugate Gradient Method for Non-negative Matrices. J Optim\n    Theory Appl 162, 931–953 (2014). https://doi.org/10.1007/s10957-013-0499-x\n\n    Examples\n    --------\n\n    """\n    if max_it is None:\n        max_it = x0.size\n    if slippy.CUDA and cp is not None:\n        xp = cp\n    else:\n        xp = np\n\n    try:\n        float(max_pressure)\n        max_is_float = True\n    except TypeError:\n        max_is_float = False\n        max_pressure = xp.array(max_pressure)\n\n    try:\n        float(min_pressure)\n        min_is_float = True\n    except TypeError:\n        min_is_float = False\n        min_pressure = xp.array(min_pressure)\n\n    # initialize\n    b = xp.asarray(b)\n    x = xp.clip(xp.asarray(x0), min_pressure, max_pressure)\n    g = f(x) - b\n    msk_bnd_0 = xp.logical_and(x <= 0, g >= 0)\n    msk_bnd_max = xp.logical_and(x >= max_pressure, g <= 0)\n    n_bound = xp.sum(msk_bnd_0) + xp.sum(msk_bnd_max)\n    n = b.size\n    n_free = n - n_bound\n    small = 1e-14\n    it = 0\n    it_inn = 0\n    rho_prev = xp.nan\n    rho = 0.0\n    r, p, r_prev = 0, 0, 0\n    failed = False\n\n    while True:\n        it += 1\n        it_inn += 1\n        x_prev = x\n        if it > 1:\n            r_prev = r\n            rho_prev = rho\n        r = -g\n        r[msk_bnd_0] = 0\n        r[msk_bnd_max] = 0\n        rho = xp.dot(r, r)\n        if it > 1:\n            beta_pr = (rho - xp.dot(r, r_prev)) / rho_prev\n            p = r + max([beta_pr, 0]) * p\n        else:\n            p = r\n        p[msk_bnd_0] = 0\n        p[msk_bnd_max] = 0\n        # compute tildex optimisation ignoring the bounds\n        q = f(p)\n        if it_inn < k_inn:\n            q[msk_bnd_0] = xp.nan\n            q[msk_bnd_max] = xp.nan\n        alpha = xp.dot(r, p) / xp.dot(p, q)\n        x = x + alpha * p\n\n        rms_xk = xp.linalg.norm(x) / xp.sqrt(n_free)\n        rms_upd = xp.linalg.norm(x - x_prev) / xp.sqrt(n_free)\n        upd = rms_upd / rms_xk\n\n        # project onto feasible domain\n        changed = False\n        outer_it = it_inn >= k_inn or upd < tol\n\n        if outer_it:\n            msk_prj_0 = x < min_pressure - small\n            if xp.any(msk_prj_0):\n                if min_is_float:\n                    x[msk_prj_0] = min_pressure\n                else:\n                    x[msk_prj_0] = min_pressure[msk_prj_0]\n                msk_bnd_0[msk_prj_0] = True\n                changed = True\n            msk_prj_max = x >= max_pressure * (1 + small)\n            if xp.any(msk_prj_max):\n                if max_is_float:\n                    x[msk_prj_max] = max_pressure\n                else:\n                    x[msk_prj_max] = max_pressure[msk_prj_max]\n                msk_bnd_max[msk_prj_max] = True\n                changed = True\n\n        if changed or (outer_it and k_inn > 1):\n            g = f(x) - b\n        else:\n            g = g + alpha * q\n\n        check_grad = outer_it\n\n        if check_grad:\n            msk_rel = xp.logical_or(xp.logical_and(msk_bnd_0, g < -small), xp.logical_and(msk_bnd_max, g > small))\n            if xp.any(msk_rel):\n                msk_bnd_0[msk_rel] = False\n                msk_bnd_max[msk_rel] = False\n                changed = True\n\n        if changed:\n            n_free = n - xp.sum(msk_bnd_0) - xp.sum(msk_bnd_max)\n\n        if not n_free:\n            print("No free nodes")\n            warnings.warn("No free nodes for BCCG iterations")\n            failed = True\n            break\n\n        if outer_it:\n            it_inn = 0\n\n        if it > max_it:\n            print("Max iterations")\n            warnings.warn("Bound constrained conjugate gradient iterations failed to converge")\n            failed = True\n            break\n\n        if outer_it and (not changed) and upd < tol:\n            break\n\n    return x, bool(failed)\n\n\ndef plan_coupled_convolve(loads: dict, components: dict, domain=None,\n                          periodic_axes: typing.Sequence[bool] = (False, False)):\n    """Plans a set of convolutions between a dict of loads and a dict of im components\n\n    Parameters\n    ----------\n    loads: dict\n         A dict of arrays with keys \'x\', \'y\' and/or \'z\'\n    components: dict\n        A dict of arrays with keys like \'xz\' etc. These must describe a square system if the function is to be used with\n        bccg iterations. the \'xz\' component gives the z displacement caused by pressures in the x direction.\n    domain: np.array, optional (None)\n        A boolean array of contacting nodes\n    periodic_axes: Sequence of bool, optional (False, False)\n        Strictly 2 elements, convolutions will be periodic along axes corresponding to True values\n    Returns\n    -------\n    callable:\n\n    """\n    component_names = list(components.keys())\n    load_dirs = list(set(n[0] for n in component_names))\n    load_dirs.sort()\n    load_shape = loads[load_dirs[0]].shape\n    conv_funcs = dict()\n    component_names_d = dict()\n    if domain is not None:\n        domain_sum = np.sum(domain)\n    else:\n        domain_sum = 0\n\n    for direction in load_dirs:\n        names = [name for name in component_names if name.startswith(direction)]\n        comps = np.array([components[name] for name in names])\n        conv_funcs[direction] = plan_multi_convolve(loads[direction], comps, None, periodic_axes)\n        component_names_d[direction] = names\n\n    def inner_no_domain(loads_dict: dict):\n        all_deflections = dict()\n        for direction in load_dirs:\n            all_deflections.update({n: d for n, d in zip(component_names_d[direction],\n                                                         conv_funcs[direction](loads_dict[direction]))})\n        deflections = dict()\n        for key, value in all_deflections.items():\n            if key[-1] in deflections:\n                deflections[key[-1]] += value\n            else:\n                deflections[key[-1]] = value\n        return deflections\n\n    def inner_with_domain(loads_in_domain: np.array, ignore_domain: bool = False):\n        full_loads = dict()\n        for i in range(len(load_dirs)):\n            full_loads[load_dirs[i]] = slippy.xp.zeros(load_shape, loads_in_domain.dtype)\n            full_loads[load_dirs[i]][domain] = loads_in_domain[i * domain_sum:(i + 1) * domain_sum]\n        full_deflections = inner_no_domain(full_loads)\n        if ignore_domain:\n            return full_deflections\n        deflections_in_domain = slippy.xp.zeros_like(loads_in_domain)\n        for i in range(len(load_dirs)):\n            deflections_in_domain[i * domain_sum:(i + 1) * domain_sum] = full_deflections[load_dirs[i]][domain]\n        return deflections_in_domain\n\n    if domain is None:\n        return inner_no_domain\n    return inner_with_domain\n\n\ndef rey(h: np.ndarray, f: ConvolutionFunction, adhesion_energy_derivative: typing.Callable, error: float,\n        max_it: int = None, mean_gap: float = None, mean_pressure: float = None):\n    """ Rey adhesive solver\n\n    Parameters\n    ----------\n    h: np.ndarray\n        The just touching gap\n    f: ConvolutionFunction\n        A convolution function made by plan_convolve\n    adhesion_energy_derivative: Callable\n        A function which returns the derivative of the adhesion potential at a specified gap value\n    error: float\n        The error used for a convergence criterion\n    max_it: int\n        The maximum number of iterations, defaults to the problem size\n    mean_gap, mean_pressure: float, optional (None)\n        Exactly one of these must be set, the converged solution will fit this value exactly if mean gap is used.\n\n    Returns\n    -------\n    failed: bool\n        True if the iterations failed to converge\n    pressure: array\n        The normal contact pressure\n    gap: array\n        The deformed gap\n    total_displacement: array\n        The total normal displacement of the surfaces\n    contact_nodes: array\n        Boolean array of surface nodes which are in contact\n\n    """\n    if not ((mean_gap is None) ^ (mean_pressure is None)):\n        raise ValueError("Either the mean pressure or mean gap must be set (not both)")\n    if max_it is None:\n        max_it = h.size\n\n    if adhesion_energy_derivative is None:\n        def adhesion_energy_derivative(_):\n            return 0\n\n    if slippy.CUDA and cp is not None:\n        xp = cp\n    else:\n        xp = np\n\n    if mean_gap is None:\n        gap_constrained = False\n        target = mean_pressure\n    else:\n        gap_constrained = True\n        target = mean_gap\n\n    h = xp.asarray(h)\n    h = -h\n    n = h.size\n    std = xp.std(h)\n    # g = -h/np.mean(-h)*mean_gap\n    it_num = 0\n    big_r_old = 1\n    delta = 0\n    t = xp.zeros_like(h)\n    if gap_constrained:\n        g = xp.ones_like(h) * target\n    else:\n        g = xp.ones_like(h) * std\n    failed = True\n    print("Begin rey solver")\n    while True:\n        # compute functional gradf\n        u = g + h\n        q = f.inverse_conv(u, True)\n        q += adhesion_energy_derivative(g)\n        # mean on unsaturated (primal is gap)\n        non_contact_nodes = g > 0\n        q_bar = xp.mean(q[non_contact_nodes])\n        if gap_constrained:\n            q -= q_bar\n        else:\n            q += 2 * target + q_bar\n        # compute squared norm\n        big_r = xp.sum(q[non_contact_nodes] ** 2)\n        # update search direction\n        t[xp.logical_not(non_contact_nodes)] = 0\n        t[non_contact_nodes] = (q[non_contact_nodes] +\n                                delta * (big_r / big_r_old) * t[non_contact_nodes])\n        big_r_old = big_r\n        # compute critical step\n        r = f.inverse_conv(t, True)\n        r_bar = xp.mean(r[non_contact_nodes])\n        if gap_constrained:\n            r -= r_bar\n        else:\n            r += 2 * target + r_bar\n        tau = (xp.sum(q[non_contact_nodes] * t[non_contact_nodes]) /\n               xp.sum(r[non_contact_nodes] * t[non_contact_nodes]))\n        # update primal\n        g = g - tau * t\n        xp.clip(g, 0, None, g)\n        non_admissible_nodes = xp.logical_and(g == 0, q < 0)\n        if xp.any(non_admissible_nodes):\n            delta = 0\n            g[non_admissible_nodes] = g[non_admissible_nodes] - tau * q[non_admissible_nodes]\n        else:\n            delta = 1\n        # enforce mean value\n        if gap_constrained:\n            g = target / xp.mean(g) * g\n        # compute error\n        q -= xp.min(q)\n        er = xp.sum(g * q)\n        norm = xp.sum(q) * std\n        eps = er / (norm * n)\n\n        # if not it_num % 100:\n        #     cost = 0.5 * xp.sum(q * (g + h)) / n ** 2\n        #     print(f"it:{it_num}\\teps:{eps}\\tcost:{cost}")\n        if eps < error and it_num:\n            failed = False\n            print("Rey Converged")\n            break\n        it_num += 1\n        if it_num > max_it:\n            print(f"Rey failed to converge: Max it (iterations: {max_it}, error: {eps})")\n            break\n        if xp.isnan(eps):\n            print("Rey failed to converge: Nan\'s detected")\n            break\n    u = g + h\n    q1 = f.inverse_conv(u, True)\n    q = q1 + adhesion_energy_derivative(g)\n    min_q = xp.min(q)\n    p = q1 - min_q\n    return failed, p, g, u, g <= 0.0\n', 'is_package': False},
    'slippy.core.materials': {'source': 'import abc\nimport itertools\nimport typing\nimport slippy\nimport numpy as np\nimport warnings\nfrom collections.abc import Sequence\nfrom .abcs import _MaterialABC\nfrom .influence_matrix_utils import plan_convolve, plan_coupled_convolve, bccg\nfrom ._material_utils import memoize_components\n\n__all__ = ["_IMMaterial", "Rigid", "rigid"]\n\n\ndef _raise_not_implemented_factory(msg):\n    def raise_not_implemented(*args, **kwargs):\n        raise NotImplementedError(msg)\n    return raise_not_implemented\n\n\nclass _IMMaterial(_MaterialABC):\n    """ A class for describing material behaviour"""\n    material_type: str\n    name: str\n    _subclass_registry = []\n    _fft: bool = True\n    _spatial: bool = True\n\n    def __init__(self, name: str, default_fft: bool = True, max_load: float = np.inf,\n                 periodic_im_repeats: tuple = (1, 1), zero_frequency_value: float = None):\n        if name in slippy.material_names:\n            raise ValueError(f"Materials must have unique names, currently in use names are: {slippy.material_names}")\n        slippy.material_names.append(name)\n        self.name = name\n        self.material_type = self.__class__.__name__\n        self.max_load = max_load\n        if (self.fft and default_fft) or not self.spatial:\n            self.use_frequency = True\n        else:\n            self.use_frequency = False\n        self.periodic_im_repeats = periodic_im_repeats\n        self.zero_frequency_value = zero_frequency_value\n\n    # keeps a registry of the materials\n    @classmethod\n    def __init_subclass__(cls, is_abstract=False, **kwargs):\n        super().__init_subclass__(**kwargs)\n        if not is_abstract:\n            _IMMaterial._subclass_registry.append(cls)\n        spatial_abstract = cls._influence_matrix_spatial is _IMMaterial._influence_matrix_spatial\n        fft_abstract = cls._influence_matrix_frequency is _IMMaterial._influence_matrix_frequency\n        if spatial_abstract and fft_abstract and not is_abstract:\n            raise ValueError("One of the influence matrix methods must be implemented")\n        if spatial_abstract:\n            cls._spatial = False\n            msg = f"Spatial domain influence matrix is not implemented for material type: {cls.__name__}"\n            cls._influence_matrix_spatial = _raise_not_implemented_factory(msg)\n        if fft_abstract:\n            cls._fft = False\n            msg = f"Frequency domain influence matrix is not implemented for material type: {cls.__name__}"\n            cls._influence_matrix_frequency = _raise_not_implemented_factory(msg)\n\n    @property\n    def fft(self):\n        return self._fft\n\n    @property\n    def spatial(self):\n        return self._spatial\n\n    # should memoize the results so that the deflection from loads method can be called directly\n    @abc.abstractmethod\n    def _influence_matrix_spatial(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                  span: typing.Sequence[int]):\n        pass\n\n    @abc.abstractmethod\n    def _influence_matrix_frequency(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                    span: typing.Sequence[int]):\n        pass\n\n    @memoize_components(False)\n    def influence_matrix(self, components: typing.Sequence[str],\n                         grid_spacing: typing.Union[typing.Sequence[float], float],\n                         span: typing.Union[typing.Sequence[int], int],\n                         fft: bool = True):\n        """\n        Find the influence matrix components for the material relating surface pressures to\n\n        Parameters\n        ----------\n        span: Sequence[int]\n            The span of the influence matrix (pts_in_y_direction, pts_in_x_direction)\n        grid_spacing: float\n            The distance between grid points of the parent surface\n        components: Sequence[str]\n            The required components of the influence matrix such as: [\'xx\', \'xy\', \'xz\'] which would be the components\n            which relate loads in the x direction with displacements in each direction\n        periodic_strides: Sequence[int], optional ((1,1))\n            The influence matrix is wrapped this number of times to ensure results represent truly periodic behaviour.\n            Both elements must be odd integers. For example if (1, 3) is given with (128, 128) span: a (128, 128*3) size\n            influence matrix is calculated, 128 by 128 blocks are then summed to give the 128 by 128 result.\n        zero_frequency_value: dict, optional (None)\n            If the material provides a frequency domain influence matrix and this is requested to be used, the value\n            for the DC component of the frequency domain influence matrix, for fully periodic analyses this is often set\n            to 0 as there is no stationary reference point. If the material provides both types of influence matrices\n            setting to None uses the sum of the spatial influence matrix including the periodic strides, if the material\n            only provides a frequency domain influence matrix, the default value (None) sets the zero frequency\n            component to 0\n        fft: bool, optional (True)\n            If True the fft of the influence matrix will be returned\n\n        Returns\n        -------\n        dict of components\n\n        Notes\n        -----\n        """\n        periodic_strides = self.periodic_im_repeats\n        zero_frequency_value = self.zero_frequency_value\n\n        if not isinstance(span, Sequence):\n            try:\n                span = int(span)\n                span = (span, span)\n            except TypeError:\n                raise ValueError("span not recognised type")\n        if not isinstance(grid_spacing, Sequence):\n            try:\n                grid_spacing = float(grid_spacing)\n                grid_spacing = (grid_spacing, grid_spacing)\n            except TypeError:\n                raise ValueError("grid_spacing not recognised type")\n\n        if len(span) == 1:\n            span *= 2\n        if len(grid_spacing) == 1:\n            grid_spacing *= 2\n\n        if components == \'all\':\n            components = [\'xx\', \'xy\', \'xz\', \'yx\', \'yy\', \'yz\', \'zx\', \'zy\', \'zz\']\n\n        ps = []\n        for s in periodic_strides:\n            try:\n                s = int(s)\n            except ValueError:\n                raise ValueError(f"Periodic strides must be odd integers, received: {s}")\n            if not s % 2:\n                raise ValueError(f"Periodic strides must be odd integers, received: {s}")\n            ps.append(s)\n        total_span_spatial = [sp * s for sp, s in zip(span, ps)]\n\n        if self.use_frequency:\n            rtn_dict = self._influence_matrix_frequency(components, grid_spacing, span)\n            done_zero = False\n            if zero_frequency_value is None:\n                if self.spatial:\n                    spatial_dict = self._influence_matrix_spatial(components, grid_spacing, total_span_spatial)\n                    for key in rtn_dict:\n                        rtn_dict[key][0, 0] = np.sum(spatial_dict[key])\n                    done_zero = True\n                else:\n                    zero_frequency_value = 0.0\n            if not done_zero:\n                if isinstance(zero_frequency_value, dict):\n                    for key in rtn_dict:\n                        rtn_dict[key][0, 0] = zero_frequency_value[key]\n                else:\n                    try:\n                        zero_frequency_value = float(zero_frequency_value)\n                        for key in rtn_dict:\n                            rtn_dict[key][0, 0] = zero_frequency_value\n                    except TypeError:\n                        raise TypeError(f"Unsupported type for zero frequency value {type(zero_frequency_value)}")\n            if fft:\n                return rtn_dict\n            else:\n                spatial_dict = {key: np.roll(np.fft.ifft2(value), tuple(((sz - 1) // 2) for sz in value.shape),\n                                             (-2, -1)) for key, value in rtn_dict.items()}\n                return spatial_dict\n\n        if zero_frequency_value is not None:\n            warnings.warn("Zero frequency value has no effect if the material is spatially defined")\n        rtn_dict = self._influence_matrix_spatial(components, grid_spacing, total_span_spatial)\n        for key in rtn_dict:\n            original = rtn_dict[key]\n            rtn_dict[key] = np.zeros(span, slippy.dtype)\n            for i in range(periodic_strides[0]):\n                for j in range(periodic_strides[1]):\n                    rtn_dict[key] += original[i*span[0]:(i+1)*span[0], j*span[1]:(j+1)*span[1]]\n        if not fft:\n            return rtn_dict\n        fft_dict = {key: np.fft.fft2(np.roll(value, tuple(-((sz - 1) // 2) for sz in value.shape), (-2, -1)))\n                    for key, value in rtn_dict.items()}\n        return fft_dict\n\n    @abc.abstractmethod\n    def sss_influence_matrices_normal(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                      span: typing.Sequence[int], z: typing.Sequence[float] = None,\n                                      cuda: bool = False) -> dict:\n        """\n        Optional, should give the sub surface stress influence matrix components\n\n        Parameters\n        ----------\n        span: Sequence[int]\n            The span of the influence matrix (pts_in_y_direction, pts_in_x_direction)\n        grid_spacing\n            The distance between grid points of the parent surface\n        components\n            The required components of the influence matrix such as: [\'xx\', \'xy\', \'xz\'] which would be components\n            relating pressure in the z direction to the stress tensor terms xx, xy and xz. Shear stress terms should be\n            in alphabetical order only; as in: s_xy, and not: s_yx.\n        z: Sequence[float], optional (None)\n            The depths of interest in the material, if none a grid of half the shortest dimension in the span is used.\n        cuda: bool, optional (False)\n\n        Returns\n        -------\n        dict of components with same keys as components arg\n\n        Notes\n        -----\n        Do not memoize results from this method, there are more options in sub models etc, to allow users to control\n        memory usage\n        """\n        pass\n\n    @abc.abstractmethod\n    def sss_influence_matrices_tangential_x(self, components: typing.Sequence[str],\n                                            grid_spacing: typing.Sequence[float], span: typing.Sequence[int],\n                                            z: typing.Sequence[float] = None, cuda: bool = False) -> dict:\n        """\n        Optional, should give the sub surface stress influence matrix components\n\n        Parameters\n        ----------\n        span: Sequence[int]\n            The span of the influence matrix (pts_in_y_direction, pts_in_x_direction)\n        grid_spacing\n            The distance between grid points of the parent surface\n        components\n            The required components of the influence matrix such as: [\'xx\', \'xy\', \'xz\'] which would be components\n            relating traction in the x direction to the stress tensor terms xx, xy and xz. Shear stress terms should be\n            in alphabetical order only; as in: xy, and not: yx.\n        z: Sequence[float], optional (None)\n            The depths of interest in the material, if none a grid of half the shortest dimension in the span is used.\n        cuda: bool, optional (False)\n\n        Returns\n        -------\n        dict of components with same keys as components arg\n\n        Notes\n        -----\n        Do not memoize results from this method, there are more options in sub models etc, to allow users to control\n        memory usage\n        """\n        pass\n\n    def sss_influence_matrices_tangential_y(self, components: typing.Sequence[str],\n                                            grid_spacing: typing.Sequence[float], span: typing.Sequence[int],\n                                            z: typing.Sequence[float] = None, cuda: bool = False) -> dict:\n        """\n        Optional, overwrite only for non homogenous materials\n\n        Parameters\n        ----------\n        span: Sequence[int]\n            The span of the influence matrix (pts_in_y_direction, pts_in_x_direction)\n        grid_spacing\n            The distance between grid points of the parent surface\n        components\n            The required components of the influence matrix such as: [\'xx\', \'xy\', \'xz\'] which would be components\n            relating traction in the x direction to the stress tensor terms xx, xy and xz. Shear stress terms should be\n            in alphabetical order only; as in: xy, and not: yx.\n        z: Sequence[float], optional (None)\n            The depths of interest in the material, if none a grid of half the shortest dimension in the span is used.\n        cuda: bool, optional (False)\n\n        Returns\n        -------\n        dict of components with same keys as components arg\n\n        Notes\n        -----\n        Do not memoize results from this method, there are more options in sub models etc, to allow users to control\n        memory usage\n        """\n        span = tuple(reversed(span))\n        grid_spacing = tuple(reversed(grid_spacing))\n        replace = {\'x\': \'y\', \'y\': \'x\', \'z\': \'z\'}\n        new_comps = [\'\'.join(sorted(replace[comp[0]] + replace[comp[1]])) for comp in components]\n        comps = self.sss_influence_matrices_tangential_x(new_comps, grid_spacing, span, z, cuda)\n        rtn_dict = dict()\n        for key, comp in comps.items():\n            new_key = components[new_comps.index(key)]\n            rtn_dict[new_key] = comp.swapaxes(1, 2)\n        return rtn_dict\n\n    def displacement_from_surface_loads(self, loads: dict,\n                                        grid_spacing: float,\n                                        deflections: str = \'xyz\',\n                                        simple: bool = True,\n                                        periodic_axes: typing.Sequence[bool] = (True, True)):\n        load_dirs = [key for key in loads if key in \'xyz\']\n        load_dirs.sort()\n        shape = loads[load_dirs[0]].shape\n        if isinstance(grid_spacing, Sequence):\n            if len(grid_spacing) < 2:\n                grid_spacing = (grid_spacing, grid_spacing)\n            elif len(grid_spacing) > 2:\n                raise ValueError("Grid spacing should be a number or a two element sequence of numbers")\n        else:\n            grid_spacing = (grid_spacing, grid_spacing)\n\n        if simple:\n            component_names = [2 * dir for dir in load_dirs]\n        else:\n            component_names = list(a + b for a, b in itertools.product(load_dirs, deflections))\n        components = self.influence_matrix(component_names, grid_spacing, shape)\n\n        conv_func = plan_coupled_convolve(loads, components, None, periodic_axes)\n\n        return conv_func(loads)\n\n    def loads_from_surface_displacement(self,\n                                        displacements: dict,\n                                        grid_spacing: float,\n                                        other: typing.Optional[_MaterialABC] = None,\n                                        tol: float = 1e-8,\n                                        simple: bool = True,\n                                        max_it: int = None,\n                                        periodic_axes: typing.Sequence[bool] = (True, True)):\n\n        load_dirs = [key for key in displacements if key in \'xyz\']\n        load_dirs.sort()\n        shape = displacements[load_dirs[0]].shape\n        size = displacements[load_dirs[0]].size\n\n        if isinstance(grid_spacing, Sequence):\n            if len(grid_spacing) < 2:\n                grid_spacing = (grid_spacing, grid_spacing)\n            elif len(grid_spacing) > 2:\n                raise ValueError("Grid spacing should be a number or a two element sequence of numbers")\n        else:\n            grid_spacing = (grid_spacing, grid_spacing)\n\n        if simple:\n            component_names = [2 * d for d in load_dirs]\n        else:\n            component_names = list(a + b for a, b in itertools.product(load_dirs, load_dirs))\n\n        components = self.influence_matrix(component_names, grid_spacing, shape)\n\n        domain = slippy.xp.ones(displacements[load_dirs[0]].shape, dtype=bool)\n\n        if len(component_names) == 1:\n            load_dir = load_dirs[0]\n            conv_func = plan_convolve(displacements[load_dir], components[load_dir * 2], domain, periodic_axes)\n            b = displacements[load_dir].flatten()\n        else:\n            load_dir = None\n            conv_func = plan_coupled_convolve(displacements, components, domain, periodic_axes)\n            b = np.concatenate(tuple(displacements[d].flatten() for d in load_dirs))\n\n        loads, failed = bccg(conv_func, b, tol=tol, max_it=max_it, x0=np.zeros_like(b), min_pressure=-np.inf)\n        full_loads = dict()\n        for i in range(len(load_dirs)):\n            full_loads[load_dirs[i]] = slippy.xp.zeros(shape)\n            full_loads[load_dirs[i]][domain] = loads[i * size:(i + 1) * size]\n\n        return full_loads\n\n\nclass Rigid(_IMMaterial):\n    """ A rigid material\n\n    Parameters\n    ----------\n    name: str\n        The name of the material\n    """\n\n    material_type = \'Rigid\'\n\n    E = None\n    v = None\n    G = None\n    lam = None\n    K = None\n    M = None\n\n    def __init__(self, name: str):\n        super().__init__(name, True, np.inf, (1, 1), 0.0)\n\n    def _influence_matrix_spatial(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                  span: typing.Sequence[int]):\n        return {comp: np.zeros(span) for comp in components}\n\n    def _influence_matrix_frequency(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                    span: typing.Sequence[int]):\n        return {comp: np.zeros(span) for comp in components}\n\n    def displacement_from_surface_loads(self, loads, *args, **kwargs):\n        return [np.zeros_like(l) for l in loads]  # noqa: E741\n\n    def sss_influence_matrices_normal(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                      span: typing.Sequence[int], z: typing.Sequence[float] = None,\n                                      cuda: bool = False) -> dict:\n        raise NotImplementedError("Subsurface stresses are not implemented for rigid materials")\n\n    def sss_influence_matrices_tangential_x(self, components: typing.Sequence[str],\n                                            grid_spacing: typing.Sequence[float], span: typing.Sequence[int],\n                                            z: typing.Sequence[float] = None, cuda: bool = False) -> dict:\n        raise NotImplementedError("Subsurface stresses are not implemented for rigid materials")\n\n    def __repr__(self):\n        return "Rigid(" + self.name + ")"\n\n\nrigid = Rigid(\'rigid\')\n', 'is_package': False},
    'slippy.core.outputs': {'source': 'import warnings\nimport typing\nimport zipfile\nimport tinydb\nimport slippy\nimport os\nimport numpy as np\nfrom collections.abc import Sequence\nif slippy.CUDA:\n    import cupy as cp\n\n__all__ = [\'OutputRequest\', \'OutputSaver\', \'OutputReader\', \'read_output\']\n\n\nclass OutputSaver:\n    """\n    A context manager for saving model output\n\n    Parameters\n    ----------\n    model_name: str\n        The name of the model, to be used for the file names of the outputs\n\n    Notes\n    -----\n    This writes the outputs to a database file (*.sdb). The arrays cannot be stored in the database and are instead\n    stored in binary in a zip repository (*.sar). The entries in the data base are replaced with the file names in the\n    zip repository, the shape of the output and the data type.\n\n    See Also\n    --------\n    OutputReader - A class for reading output files back in\n    """\n    def __init__(self, model_name: str):\n        self.model_name = model_name\n        self.in_context = False\n        self.database_file = None\n        self.array_file = None\n        self.array_number = 0\n\n    def write(self, output: dict):\n        """Write outputs to file,\n\n        Parameters\n        ----------\n        output: dict\n            The outputs to be added to the database\n\n        """\n        if not self.in_context:\n            raise ValueError("Output saver is not in context cannot save")\n        clean_dict = dict()\n        for key, value in output.items():\n            if slippy.CUDA and isinstance(value, cp.ndarray):\n                value = cp.asnumpy(value)\n            if isinstance(value, np.ndarray) and value.size == 1:\n                try:\n                    value = float(value)\n                except TypeError:\n                    pass\n            if isinstance(value, np.ndarray):\n                name = \'a\' + str(self.array_number)\n                if value.flags.f_contiguous:\n                    value = np.ascontiguousarray(value)\n                self.array_file.writestr(name, value.tobytes())\n                value = \'**array**#\' + str(self.array_number) + \'#\' + str(value.shape) + \'#\' + str(value.dtype)\n                self.array_number += 1\n            clean_dict[key] = value\n        self.data_file.insert(clean_dict)\n\n    def __enter__(self):\n        db_filename = os.path.join(slippy.OUTPUT_DIR, self.model_name + \'.sdb\')\n        if os.path.exists(db_filename):\n            os.remove(db_filename)\n        self.data_file = tinydb.TinyDB(db_filename, \'w\')\n        self.array_file = zipfile.ZipFile(os.path.join(slippy.OUTPUT_DIR, self.model_name + \'.sar\'), \'w\')\n        self.in_context = True\n        return self\n\n    def __exit__(self, err_type, value, traceback):\n        self.data_file.close()\n        self.array_file.close()\n        self.in_context = False\n\n\nclass OutputRequest:\n    """An output request for a multi step contact model\n\n    Parameters\n    ----------\n    name: str\n        The name of the output request, used for debugging\n    parameters: list[str]\n        A list of parameters to be saved as part of the output, check step and sub-model descriptions for valid\n        names, alternatively [\'all\'] will save the entire model state\n    timing_mode: {\'interval\', \'time_interval\', \'n_outputs_per_step\', \'step_times\', \'global_times\'},\n    optional (\'interval\')\n        The timing mode used to control when this output is written to file, the value parameter controls how each\n        method is executed:\n\n        * \'interval\' the output is written every n time points during execution, using this with value set to 1\n           (as is the default behaviour) writes the output on every sub step / time point.\n        * \'time_interval\' the output is written every n units of time, for example if value is set to 0.25 a step\n          which is 1 unit of time long will output 4 times [t = 0.25, 0.5, 0.75, 1]. This is reset at the\n          beginning of each model step.\n        * \'n_outputs_per_step\' the output is written n times in each step it is active in regardless of the length\n          of each step, the time points are evenly spaced. value is the number of outputs to be recorded\n        * \'step times\' the output is written at specific times measured from the beginning of the steps which the\n          output is active in, this resets for every model step which uses this output. value should be a sorted\n          list of relative times\n        * \'global_times\' the output is written at specific times measured from the start of model execution, no\n          output will be written from steps where this output is not active. value should be a sorted list of\n          absolute times\n\n\n    value: Union[list, float], optional (1)\n        Either a float or list of floats, as defined above\n\n    Notes\n    -----\n    Outputs cannot be requested from the start of a step.\n\n    Outputs will only be written from steps which have the output added, this can be done through the individual\n    steps or the contact model.\n\n    See Also\n    --------\n    OutputReader - A class for easily reading output files\n\n    Examples\n    --------\n    An output request that will save everything at all time points:\n\n    >>> OutputRequest(\'output-0\', [\'all\'])\n\n    An output request that will save \'contact_nodes\' and normal load for every time step:\n\n    >>> OutputRequest(\'output-1\', [\'contact_nodes\', \'loads_z\'])\n    """\n    parameters: typing.Sequence[str]\n\n    def __init__(self, name: str, parameters: typing.Sequence[str], timing_mode: str = \'interval\',\n                 value: typing.Union[typing.Sequence, float] = 1):\n\n        self.name = name\n        valid_modes = (\'interval\', \'time_interval\', \'n_outputs_per_step\', \'step_times\', \'global_times\')\n        if timing_mode not in valid_modes:\n            raise ValueError(f"Unrecognised timing mode: {timing_mode}, should be one of {\', \'.join(valid_modes)}")\n\n        if not isinstance(parameters, Sequence) or isinstance(parameters, str):\n            raise ValueError("Parameters must be a sequence of strings")\n\n        self.timing = timing_mode\n        if timing_mode == \'interval\':\n            self.interval = value\n            self._interval_count = value\n        if timing_mode == \'time_interval\':\n            self.interval = value\n            self.next_time_point = 0\n        if timing_mode == \'n_outputs_per_step\':\n            self.interval = value\n        if timing_mode == \'step_times\':\n            self.interval = None\n            self.step_times = value\n        if timing_mode == \'global_times\':\n            self.interval = None\n            self.time_points = iter(value)\n            try:\n                self.next_time_point = next(self.time_points)\n            except StopIteration:\n                raise ValueError("Global times must have length of at least 1")\n\n        self.parameters = [str(p) for p in parameters]\n        self.start_time_this_step = 0\n        self.end_time_this_step = None\n\n    def new_step(self, current_time):\n        """\n        Called by the model when a new step is started\n        """\n        self.start_time_this_step = current_time\n        self.end_time_this_step = None\n        if self.timing == \'time_interval\':\n            self.next_time_point = current_time\n\n    def is_active(self, current_time: float, step_max_time: float):\n        """True if the output should be written on this time step\n        """\n        if self.timing == \'interval\':\n            if self._interval_count < self.interval:\n                self._interval_count += 1\n                return False\n            else:\n                self._interval_count = 1\n                return True\n\n        if self.timing == \'time_interval\':\n            if current_time >= self.next_time_point:\n                self.next_time_point += self.interval\n                return True\n            return False\n\n        if self.end_time_this_step is None:  # then new_step was just called\n            self.end_time_this_step = self.start_time_this_step + step_max_time\n            if self.timing == \'n_outputs_per_step\':\n                self.time_points = iter(np.linspace(self.start_time_this_step, self.end_time_this_step, self.interval))\n            if self.timing == \'step_times\':\n                self.time_points = iter([self.start_time_this_step + st for st in self.step_times])\n            try:\n                self.next_time_point = next(self.time_points)\n            except StopIteration:\n                self.next_time_point = None\n\n        if self.timing in [\'global_times\', \'n_outputs_per_step\', \'step_times\']:\n            if self.next_time_point is not None and current_time >= self.next_time_point:\n                try:\n                    self.next_time_point = next(self.time_points)\n                except StopIteration:\n                    self.next_time_point = None\n                return True\n            return False\n\n        warnings.warn(f"Output {self.name}, could not be written, output timing not recognised")\n        return False\n\n\nclass OutputReader:\n    """\n    A class for reading and querying output files (.sdb) and array files (.sar)\n\n    Parameters\n    ----------\n    file_name: str\n        The path to the .sdb file with or without the extension, there should be a corresponding .sar file with the\n        same name in the same directory\n\n    Attributes\n    ----------\n    fields: set\n        A set of all the fields which appear in the output database\n    time_points: list\n        A list of the all the time points in the output file\n\n    See Also\n    --------\n    OutputSaver\n    OutputRequest\n\n    Notes\n    -----\n    All arrays in the output will be lazily read from the array file. These will not be read until the data from the\n    array is requested. However, the lazy array objects are written so that numpy functions can use them as if they are\n    arrays and they can be indexed as if they are arrays. Indexing the array will read the entire array into memory.\n    For many uses this is good enough, however sometimes it is necessary to explicitly convert the lazy array into a\n    numpy array using numpy.asarray(lazy_array).\n\n    Examples\n    --------\n    Making an output file to test:\n\n    >>> import slippy.contact as c\n    >>> with c.OutputSaver(\'test\') as output_s:\n    >>>     output_s.write({\'time\':0,\'a\':5, \'b\':np.array([1,2,3,4]), \'c\':np.array([1,2,3,4])})\n    >>>     output_s.write({\'time\':1,\'a\':10, \'c\':np.array([1,2,3,4])})\n    >>>     output_s.write({\'time\':2,\'a\':15, \'b\':np.array([1,2,3,4]), })\n    >>>     output_s.write({\'time\':3,\'a\':20, \'b\':np.array([1,2,3,4]), \'c\':np.array([1,2,3,4])})\n\n    The file can then be read in using an output reader:\n\n    >>> output = c.OutputReader(\'test\')\n\n    We can find the time points and fields saved:\n\n    >>> output.time_points\n    [0, 1, 2, 3]\n    >>> output.fields\n    {\'a\', \'b\', \'c\', \'time\'}\n\n    The output reader can be indexed by a time point or a field:\n\n    >>> output[1]\n    {\'time\': 1, \'a\': 10, \'c\': array, shape:(4,), dtype:int32}\n    >>> output[\'a\']\n    {0: 5, 1: 10, 2: 15, 3: 20}\n\n    The result of this index is a dictionary of the results from a single time point or all the results from a field,\n    indexing again will give the result for a specific field at a specific time point.\n\n    >>> output[\'a\'][1] == output[1][\'a\']\n    True\n\n    For plotting etc. all of the values can be accessed:\n\n    >>> all_times = list(output[\'time\'].values())\n\n    You can also query the results data base directly using tinydb, note that this will not work with array items.\n\n    >>> from tinydb import Query\n    >>> result = Query()\n    >>> output.search(result.a == 10)\n    [{\'time\': 1, \'a\': 10, \'c\': array, shape:(4,), dtype:int32}]\n\n    The output reader can also be use to iterate through the results from each time point:\n\n    >>> for result_from_time_point in output:\n    >>>     print(result_from_time_point[\'time\'])\n    0\n    1\n    2\n    3\n    """\n    def __init__(self, file_name):\n        if not file_name.endswith(\'.sdb\'):\n            file_name += \'.sdb\'\n        self.file_name = file_name\n        with tinydb.TinyDB(file_name) as db:\n            self.all_entries = db.search(tinydb.Query().time >= 0)\n            self.fields = set()\n            self.time_points = []\n            for entry in self.all_entries:\n                self.fields.update(entry)\n                self.time_points.append(entry[\'time\'])\n\n    def __getitem__(self, time_point_or_field):\n        with tinydb.TinyDB(self.file_name) as db:\n            if time_point_or_field in self.time_points:\n                query = tinydb.Query()\n                raw_dict = db.search(query.time == time_point_or_field)[0]\n            elif time_point_or_field in self.fields:\n                f = time_point_or_field\n                raw_dict = {entry[\'time\']: (entry[f] if f in entry else None) for entry in self.all_entries}\n            else:\n                raise IndexError("Time point or field not recognised")\n        return _array_gen(raw_dict, self.file_name[:-4] + \'.sar\')\n\n    def search(self, query):\n        """Wraps TinyDB search method replacing array codes in database with lazy arrays\n\n        Parameters\n        ----------\n        query: tinydb.Query\n            A valid tinydb Query\n\n        Returns\n        -------\n        list of results that match the query\n\n        Notes\n        -----\n        Queries cannot match against arrays as these are not stored directly in the database\n\n        Examples\n        --------\n        >>> with OutputSaver(\'test\') as output:\n        >>>     output.write({\'time\':0,\'a\':5, \'b\':np.array([1,2,3,4]), \'c\':np.array([1,2,3,4])})\n        >>>     output.write({\'time\':1,\'a\':10, \'c\':np.array([1,2,3,4])})\n        >>>     output.write({\'time\':2,\'a\':15, \'b\':np.array([1,2,3,4]), })\n        >>>     output.write({\'time\':3,\'a\':20, \'b\':np.array([1,2,3,4]), \'c\':np.array([1,2,3,4])})\n        >>> output = OutputReader(\'test\')\n        >>> from tinydb import Query\n        >>> result = Query()\n        >>> output.search(result.a == 10)\n        [{\'time\': 1, \'a\': 10, \'c\': array, shape:(4,), dtype:int32}]\n        """\n        with tinydb.TinyDB(self.file_name) as db:\n            results_list = db.search(query)\n        filled_results = []\n        for result_dict in results_list:\n            filled_results.append(_array_gen(result_dict, self.file_name[:-4] + \'.sar\'))\n        return filled_results\n\n    def __iter__(self):\n        current = 0\n        while current < len(self.time_points):\n            yield self[self.time_points[current]]\n            current += 1\n\n    def __repr__(self):\n        return (f"OutputReader \\n"\n                f"fields: {\', \'.join(self.fields)} \\n"\n                f"time points {\', \'.join([str(tp) for tp in self.time_points])}")\n\n\ndef _array_gen(output_dict, array_file_name):\n    """\n    Helper function to replace string codes for _ArrayReader objects in the output of a query\n\n    Parameters\n    ----------\n    output_dict: dict\n        A dict, normally the result of a query on the database\n    array_file_name: str\n        The file name of the array file which goes with the output database\n\n    Returns\n    -------\n    output_dict: dict\n        The input dict modified by changing any array code values to _ArrayReader objects (lazily read arrays)\n    """\n    for key, value in output_dict.items():\n        if isinstance(value, str) and value.startswith(\'**array**\'):\n            output_dict[key] = _ArrayReader(array_file_name, value)\n    return output_dict\n\n\nclass _ArrayReader:\n    """\n    Helper class for reading arrays from zip file, should act like an array but\n    lazily loads from the zipfile.\n\n    Parameters\n    ----------\n    file_name: str\n        The full path to the array file (.sar)\n    entry_string: str\n        The string from the corresponding entry in the output database\n\n    Examples\n    --------\n    >>> with OutputSaver(\'test\') as output_files:\n    >>>     output_files.write({\'my_array\':np.array([1,2,3,4])})\n    >>> lazy_array = _ArrayReader(\'test.sar\', \'**array**#0#(4,)#int32\')\n    >>> #                                                ^ file name in zip repo\n    >>> #                                                   ^ shape of array\n    >>> #                                                       ^ dtype of array\n    >>> np.max(lazy_array)\n    4\n    >>> lazy_array[0]\n    1\n    """\n    def __init__(self, file_name: str, entry_string: str):\n        self.file_name = file_name\n        hashes = [n for n, v in enumerate(entry_string) if v == \'#\']\n        self.file_num = entry_string[hashes[0] + 1:hashes[1]]\n        shape = entry_string[hashes[1] + 1:hashes[2]]\n        if any([s not in \'1234567890 ,()\' for s in shape]):\n            raise ValueError("Data in this file has been modified, unable to read")\n        self.shape = eval(shape)\n        self.dtype_name = entry_string[hashes[2] + 1:]\n        # noinspection PyUnresolvedReferences\n        self.dtype = np.__getattribute__(self.dtype_name)\n        self._array = None\n\n    @property\n    def array(self):\n        if self._array is None:\n            self._fill_array()\n        return self._array\n\n    def _fill_array(self):\n        with zipfile.ZipFile(self.file_name, \'r\') as file:\n            self._array = np.frombuffer(file.read(\'a\' + self.file_num), dtype=self.dtype).reshape(self.shape)\n\n    def __array__(self):\n        return self.array\n\n    def __getitem__(self, *items):\n        return self.array.__getitem__(*items)\n\n    def __repr__(self):\n        return f"array, shape:{self.shape}, dtype:{self.dtype_name}"\n\n\ndef read_output(file_name: str) -> OutputReader:\n    """Read a pair of output files\n\n    Parameters\n    ----------\n    file_name: str\n        The file name or full path to the database file (.sdb)\n\n    Returns\n    -------\n    OutputReader object\n\n    Notes\n    -----\n    The returned OutputReader object has attributes time_points and fields, these are all the time points for which\n    an output was recorded (for single step static analysis there will be one time point at t=1)\n\n    Indexing the OutputReader object with a time point will return all of the results from that time point as a\n    dictionary\n\n    Indexing the OutputReader with a field will give a dict of the results from that field for every time point.\n    With the keys being the time values for each measurement, missing values will be replaced by None\n\n    The result is that indexing with a time point then a field or a field then a time point gives the result for that\n    field at the specific time.\n\n    Any arrays in the results will be lazily read when they are first accessed, these can be converted to numpy arrays\n    by array = np.array(lazy_array). However they should work with numpy functions and indexing without conversion.\n\n    Examples\n    --------\n    >>> with OutputSaver(\'test\') as output:\n    >>>     output.write({\'time\':0,\'a\':5, \'b\':np.array([1,2,3,4]), \'c\':np.array([1,2,3,4])})\n    >>>     output.write({\'time\':1,\'a\':10, \'c\':np.array([1,2,3,4])})\n    >>>     output.write({\'time\':2,\'a\':15, \'b\':np.array([1,2,3,4]), })\n    >>>     output.write({\'time\':3,\'a\':20, \'b\':np.array([1,2,3,4]), \'c\':np.array([1,2,3,4])})\n    >>> output = read_output(\'test\')\n    >>> output.time_points\n    [0,1,2,3]\n    >>> output[1]\n    {\'time\': 1, \'a\': 10, \'c\': array, shape:(4,), dtype:int32} # dict of results at a specific time\n    >>> output.fields\n    {\'a\', \'b\', \'c\', \'time\'}\n    >>> output[\'a\']\n    {0: 5, 1: 10, 2: 15, 3: 20} # dict with keys of time points and values of \'a\' at each time point\n    >>> output[\'a\'][1] == output[1][\'a\']\n    True\n    """\n    return OutputReader(file_name)\n', 'is_package': False},
    'slippy.core.surface_tensed_material': {'source': 'import typing\nfrom .materials import _IMMaterial\n\n\nclass SurfaceTensedMaterial(_IMMaterial):\n\n    def __init__(self, name, modulus, p_ratio, tau_0, max_load, im_intergration_error=1e-8):\n        super().__init__(name, max_load)\n        self.e_star = modulus / (1 - p_ratio ** 2)\n        self.s = 2 * tau_0 / self.e_star\n        self.int_tol = im_intergration_error\n\n    def _influence_matrix_spatial(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                  span: typing.Sequence[int]):\n        if len(components) > 1 or \'zz\' not in components:\n            raise ValueError("Only normal loading is implemented for surface tensed materials")\n\n    def sss_influence_matrices_normal(self, components: typing.Sequence[str], grid_spacing: typing.Sequence[float],\n                                      span: typing.Sequence[int], z: typing.Sequence[float] = None,\n                                      cuda: bool = False) -> dict:\n\n        raise NotImplementedError("Sub surface stresses are not implemented for this material")\n\n    def sss_influence_matrices_tangential_x(self, components: typing.Sequence[str],\n                                            grid_spacing: typing.Sequence[float], span: typing.Sequence[int],\n                                            z: typing.Sequence[float] = None, cuda: bool = False) -> dict:\n\n        raise NotImplementedError("Sub surface stresses are not implemented for this material")\n', 'is_package': False},
    'slippy.core.tests.test_convolove_basic_fftw': {'source': 'import numpy as np\nimport numpy.testing as npt\n\nimport slippy\nimport slippy.core as c\nfrom scipy.signal import fftconvolve\n\ne_im = c.elastic_influence_matrix_spatial\n\nloads_shapes = [(128, 128),\n                (127, 128), (129, 128), (128, 127), (128, 129),\n                (128, 128), (129, 128), (128, 128), (128, 128),\n                (129, 129), (127, 127), (127, 129), (129, 127)]\n\nshapes_circ = [(127, 127), (128, 128), (129, 129),\n               (129, 127), (127, 129),\n               (128, 129), (128, 127)]\n\n\n# Test if our non circular convolution lines up with scipy\'s fft convolve\ndef test_non_circ_convolve_vs_scipy():\n    with slippy.OverRideCuda():\n        for l_s in loads_shapes:\n            # generate an influence matrix, pick a component which is not symmetric!\n            im_s = tuple(s * 2 for s in l_s)\n            im = e_im(\'zx\', im_s, (0.01, 0.01), 200e9, 0.3)\n            loads = 1000*np.random.rand(*l_s)\n            scipy_result = fftconvolve(loads, im, mode=\'same\')\n            conv_func = c.plan_convolve(loads, im, fft_im=False)\n            slippy_result = conv_func(loads)\n            err_msg = f\'Non circular convolution did not match scipy output for loads shape: {l_s} and IM shape: {im_s}\'\n            npt.assert_allclose(slippy_result, scipy_result, err_msg=err_msg)\n\n\n# Test if our circular convolve gives a maximum in the right place\ndef test_circ_convolve_location():\n    with slippy.OverRideCuda():\n        for im_s, l_s in zip(shapes_circ, shapes_circ):\n            # generate an influence matrix, pick a component which is not symmetric!\n            im = e_im(\'zz\', im_s, (0.01, 0.01), 200e9, 0.3)\n            loads = np.zeros(l_s)\n            loads[64, 64] = 1000\n            conv_func = c.plan_convolve(loads, im, circular=True)\n            slippy_result = conv_func(loads)\n            loc_load = np.argmax(loads)\n            loc_result = np.argmax(slippy_result)\n            err_msg = f\'Circular convolution, location of load dosn\\\'t match displacement\' \\\n                      f\'for loads shape: {l_s} and IM shape: {im_s} \\n \' \\\n                      f\'expected: {np.unravel_index(loc_load,l_s)}, found: {np.unravel_index(loc_result,l_s)}\'\n            assert loc_load == loc_result, err_msg\n\n\n# Test if our non circular convolution gives a maximum in the right place\ndef test_non_circ_convolve_location():\n    with slippy.OverRideCuda():\n        for l_s in loads_shapes:\n            # generate an influence matrix, pick a component which is not symmetric!\n            im_s = tuple(s * 2 for s in l_s)\n            im = e_im(\'zz\', im_s, (0.01, 0.01), 200e9, 0.3)\n            loads = np.zeros(l_s)\n            loads[64, 64] = 1000\n            conv_func = c.plan_convolve(loads, im)\n            slippy_result = conv_func(loads)\n            loc_load = np.argmax(loads)\n            loc_result = np.argmax(slippy_result)\n            err_msg = f\'Non circular convolution, location of load dosn\\\'t match displacement\' \\\n                      f\'for loads shape: {l_s} and IM shape: {im_s} \\n \' \\\n                      f\'expected: {np.unravel_index(loc_load,l_s)}, found: {np.unravel_index(loc_result,l_s)}\'\n            assert loc_load == loc_result, err_msg\n\n\ndef test_mixed_convolve():\n    with slippy.OverRideCuda():\n        for circ in [[True, False], [False, True]]:\n            loads = np.zeros([128, 128])\n            im_s = tuple((2 - p) * s for p, s in zip(circ, loads.shape))\n            im = e_im(\'zz\', im_s, (0.01, 0.01), 200e9, 0.3)\n            loads[64, 64] = 1000\n            conv_func = c.plan_convolve(loads, im, circular=circ)\n            slippy_result = conv_func(loads)\n            loc_load = np.argmax(loads)\n            loc_result = np.argmax(slippy_result)\n            err_msg = f\'Mixed circular convolution, location of load dosn\\\'t match displacement\' \\\n                      f\'for circular: {circ} \\n \' \\\n                      f\'expected: {np.unravel_index(loc_load, loads.shape)}, \' \\\n                      f\'found: {np.unravel_index(loc_result, loads.shape)}\'\n            assert loc_load == loc_result, err_msg\n\n\n# Test that the fft cannot be planned to be circular and different shape inputs\ndef test_raises_uequal_shapes_circ():\n    with slippy.OverRideCuda():\n        im = e_im(\'zz\', (128, 128), (0.01, 0.01), 200e9, 0.3)\n        load_shapes = [(128, 129), (128, 129), (129, 128), (129, 128)]\n        circulars = [True, (False, True), True, (True, False)]\n        for l_s, circ in zip(load_shapes, circulars):\n            with npt.assert_raises(AssertionError):\n                loads = np.zeros(l_s)\n                _ = c.plan_convolve(loads, im, circular=circ)\n\n\n# Test that the convolution functions don\'t raise errors when the shapes are equal\ndef test_dont_raise_equal_shapes_circ():\n    with slippy.OverRideCuda():\n        im = e_im(\'zz\', (128, 128), (0.01, 0.01), 200e9, 0.3)\n        load_shapes = [(128, 128), (128, 64), (64, 64), (64, 128)]\n        circulars = [True, (True, False), False, (False, True)]\n        for l_s, circ in zip(load_shapes, circulars):\n            loads = np.zeros(l_s)\n            try:\n                _ = c.plan_convolve(loads, im, circular=circ)\n            except:  # noqa: E722\n                raise AssertionError(f"Plan convolve raised wrong error for mixed "\n                                     f"convolution load shape: {l_s}, circ: {circ}")\n\n\ndef test_inverse_conv():\n    np.random.seed(0)\n    with slippy.OverRideCuda():\n        loads = np.random.rand(128, 128)\n        im = e_im(\'zz\', loads.shape, (1e-6, 1e-6), 200e9, 0.3)\n        conv_func = c.plan_convolve(loads, im, circular=True, fft_im=False)\n        recovered = conv_func.inverse_conv(conv_func(loads), True)\n        npt.assert_allclose(loads, recovered)\n', 'is_package': False},
    'slippy.core.tests.test_convolve_basic_cuda': {'source': 'import numpy as np\nimport numpy.testing as npt\n\nimport slippy\nimport slippy.core as c\n\nfrom scipy.signal import fftconvolve\n\ntry:\n    import cupy as cp\n    slippy.CUDA = True\nexcept ImportError:\n    cp = None\n    slippy.CUDA = False\n\ne_im = c.elastic_influence_matrix_spatial\n\nloads_shapes = [(128, 128),\n                (127, 128), (129, 128), (128, 127), (128, 129),\n                (128, 128), (129, 128), (128, 128), (128, 128),\n                (129, 129), (127, 127), (127, 129), (129, 127)]\n\nshapes_circ = [(127, 127), (128, 128), (129, 129),\n               (129, 127), (127, 129),\n               (128, 129), (128, 127)]\n\n\n# Test if our non circular convolution lines up with scipy\'s fft convolve\n\ndef test_non_circ_convolve_vs_scipy():\n    try:\n        import cupy as cp\n        slippy.CUDA = True\n    except ImportError:\n        return\n    for l_s in loads_shapes:\n        # generate an influence matrix, pick a component which is not symmetric!\n        im_s = tuple(s*2 for s in l_s)\n        im = e_im(\'zx\', im_s, (0.01, 0.01), 200e9, 0.3)\n        loads = 1000*np.random.rand(*l_s)\n        scipy_result = fftconvolve(loads, im, mode=\'same\')\n        conv_func = c.plan_convolve(loads, im, fft_im=False)\n        slippy_result = cp.asnumpy(conv_func(loads))\n        err_msg = f\'Non circular convolution did not match scipy output for loads shape: {l_s} and IM shape: {im_s}\'\n        npt.assert_allclose(slippy_result, scipy_result, err_msg=err_msg)\n\n\n# Test if our circular convolve gives a maximum in the right place\ndef test_circ_convolve_location():\n    try:\n        import cupy as cp\n        slippy.CUDA = True\n    except ImportError:\n        return\n    for im_s, l_s in zip(shapes_circ, shapes_circ):\n        # generate an influence matrix, pick a component which is not symmetric!\n        im = e_im(\'zz\', im_s, (0.01, 0.01), 200e9, 0.3)\n        loads = np.zeros(l_s)\n        loads[64, 64] = 1000\n        conv_func = c.plan_convolve(loads, im, circular=True)\n        slippy_result = cp.asnumpy(conv_func(loads))\n        loc_load = np.argmax(loads)\n        loc_result = np.argmax(slippy_result)\n        err_msg = f\'Circular convolution, location of load dosn\\\'t match displacement\' \\\n                  f\'for loads shape: {l_s} and IM shape: {im_s} \\n \' \\\n                  f\'expected: {np.unravel_index(loc_load,l_s)}, found: {np.unravel_index(loc_result,l_s)}\'\n        assert loc_load == loc_result, err_msg\n\n\n# Test if our non circular convolution gives a maximum in the right place\ndef test_non_circ_convolve_location():\n    try:\n        import cupy as cp\n        slippy.CUDA = True\n    except ImportError:\n        return\n    for l_s in loads_shapes:\n        # generate an influence matrix, pick a component which is not symmetric!\n        im_s = tuple(s * 2 for s in l_s)\n        im = e_im(\'zz\', im_s, (0.01, 0.01), 200e9, 0.3)\n        loads = np.zeros(l_s)\n        loads[64, 64] = 1000\n        conv_func = c.plan_convolve(loads, im)\n        slippy_result = cp.asnumpy(conv_func(loads))\n        loc_load = np.argmax(loads)\n        loc_result = np.argmax(slippy_result)\n        err_msg = f\'Non circular convolution, location of load dosn\\\'t match displacement\' \\\n                  f\'for loads shape: {l_s} and IM shape: {im_s} \\n \' \\\n                  f\'expected: {np.unravel_index(loc_load,l_s)}, found: {np.unravel_index(loc_result,l_s)}\'\n        assert loc_load == loc_result, err_msg\n\n\ndef test_mixed_convolve():\n    try:\n        import cupy as cp\n        slippy.CUDA = True\n    except ImportError:\n        return\n    for circ in [[True, False], [False, True]]:\n        loads = np.zeros([128, 128])\n        im_s = tuple((2-p)*s for p, s in zip(circ, loads.shape))\n        im = e_im(\'zz\', im_s, (0.01, 0.01), 200e9, 0.3)\n        loads[64, 64] = 1000\n        conv_func = c.plan_convolve(loads, im, circular=circ)\n        slippy_result = cp.asnumpy(conv_func(loads))\n        loc_load = np.argmax(loads)\n        loc_result = np.argmax(slippy_result)\n        err_msg = f\'Mixed circular convolution, location of load dosn\\\'t match displacement\' \\\n                  f\'for circular: {circ} \\n \' \\\n                  f\'expected: {np.unravel_index(loc_load, loads.shape)}, \' \\\n                  f\'found: {np.unravel_index(loc_result, loads.shape)}\'\n        assert loc_load == loc_result, err_msg\n\n\n# Test that the fft cannot be planned to be circular and different shape inputs\ndef test_raises_uequal_shapes_circ():\n    try:\n        import cupy  # noqa: F401\n        slippy.CUDA = True\n    except ImportError:\n        return\n    im = e_im(\'zz\', (128, 128), (0.01, 0.01), 200e9, 0.3)\n    load_shapes = [(128, 129), (128, 129), (129, 128), (129, 128)]\n    circulars = [True, (False, True), True, (True, False)]\n    for l_s, circ in zip(load_shapes, circulars):\n        with npt.assert_raises(AssertionError):\n            loads = np.zeros(l_s)\n            _ = c.plan_convolve(loads, im, circular=circ)\n\n\n# Test that the convolution functions don\'t raise errors when the shapes are equal\ndef test_dont_raise_equal_shapes_circ():\n    try:\n        import cupy  # noqa: F401\n        slippy.CUDA = True\n    except ImportError:\n        return\n    im = e_im(\'zz\', (128, 128), (0.01, 0.01), 200e9, 0.3)\n    load_shapes = [(128, 128), (128, 64), (64, 64), (64, 128)]\n    circulars = [True, (True, False), False, (False, True)]\n    for l_s, circ in zip(load_shapes, circulars):\n        loads = np.zeros(l_s)\n        try:\n            _ = c.plan_convolve(loads, im, circular=circ)\n        except:  # noqa: E722\n            raise AssertionError(f"Plan convolve raised wrong error for mixed "\n                                 f"convolution load shape: {l_s}, circ: {circ}")\n\n\ndef test_inverse_conv():\n    np.random.seed(0)\n    try:\n        import cupy  # noqa: F401\n        slippy.CUDA = True\n    except ImportError:\n        return\n    loads = np.random.rand(128, 128)\n    im = e_im(\'zz\', loads.shape, (1e-6, 1e-6), 200e9, 0.3)\n    conv_func = c.plan_convolve(loads, im, circular=True, fft_im=False)\n    recovered = conv_func.inverse_conv(conv_func(loads), True)\n    npt.assert_allclose(loads, cp.asnumpy(recovered))\n', 'is_package': False},
    'slippy.core.tests.test_convolve_basic_fft_ims_fftw': {'source': "# want to test that the result you get from fft'd ims is always the same as the one you get from non fft'd ims\n\n# test the values with different shapes\n\n# test multi\n\n#\n", 'is_package': False},
    'slippy.core.tests.test_gmres': {'source': 'import numpy.testing as npt\nimport numpy as np\nimport slippy\nfrom slippy.core import gmres\n\n\ndef test_gmres():\n    all_x = []\n    msgs = []\n    try:\n        import cupy as cp\n        slippy.CUDA = True\n        n = 6\n        a = cp.tril(cp.ones((n, n)))\n        b = cp.ones(n)\n        x0 = b * 0\n        x, failed = gmres(lambda y: cp.dot(a, y), x0, b, 4, n, 1e-6, override_cuda=False)\n        assert not failed, "GPU gmres iterations failed to converge"\n        all_x.append(cp.asnumpy(x))\n        msgs.append("GPU gmres iterations converged to incorrect result")\n    except ImportError:\n        pass\n\n    n = 6\n    a = np.tril(np.ones((n, n)))\n    b = np.ones(n)\n    x0 = b * 0\n    x, failed = gmres(lambda y: np.dot(a, y), x0, b, 4, n, 1e-6, override_cuda=True)\n    assert not failed, "CPU gmres iterations failed to converge"\n    all_x.append(x)\n    msgs.append("CPU gmres iterations converged to incorrect result")\n\n    x_true = x0*0\n    x_true[0] = 1\n    for x, msg in zip(all_x, msgs):\n        npt.assert_allclose(x, x_true, atol=3e-6, err_msg=msg)\n', 'is_package': False},
    'slippy.core.tests.test_materials': {'source': 'import numpy as np\nimport numpy.testing as npt\nimport slippy\nimport slippy.core as core\n\n"""\nIf you add a material you need to add the properties that it will be tested with to the material_parameters dict,\nthe key should be the name of the class (what ever it is declared as after the class key word).\nThe value should be a tuple of dicts:\nThe first dict in the tuple will be unpacked to instantiate the class,\nThe second will be used with the displacement from loads method\nThe third will be used with the loads from displacement method to ensure that the methods are inverses of each other\n\nIf there is a limit the applicability of the displacements from loads method (such as for a perfectly plastic material\nthe _max_load key word should be set in the second dict.\n\nFor more complex behaviour please also implement your own tests\n"""\n\nmaterial_parameters = {\n    \'Elastic\': ({\'name\': \'steel_5\', \'properties\': {\'E\': 200e9, \'v\': 0.3}},\n                {\'grid_spacing\': 0.01, \'simple\': True},\n                {\'grid_spacing\': 0.01, \'simple\': True, \'tol\': 1e-9}),\n    \'Rigid\': ({}, {}, {})\n}\n\nexceptions = [core.Rigid]\n\n\ndef test_materials_basic():\n    # check that one of influence matrix or displacement from loading is given\n    for material in core.materials._IMMaterial._subclass_registry:\n        if material in exceptions:\n            continue\n        try:\n            mat_params = material_parameters[material.material_type]\n        except KeyError:\n            raise AssertionError(f"Material test parameters are not specified, for material {material.material_type}")\n        mat_instance = material(**mat_params[0])\n        max_load = mat_params[1].pop(\'_max_load\', 1)\n\n        np.random.seed(0)\n\n        loads = np.random.rand(16, 16) * max_load\n\n        # check that the loads and displacement functions are inverse of each other\n        for direction in {\'x\', \'y\', \'z\'}:\n            load_in_direction = {direction: loads}\n            displacement = mat_instance.displacement_from_surface_loads(load_in_direction, **mat_params[1])\n\n            set_disp = displacement[direction]\n\n            loads_calc = mat_instance.loads_from_surface_displacement(displacements={direction: set_disp},\n                                                                      **mat_params[2])\n\n            npt.assert_allclose(loads, slippy.asnumpy(loads_calc[direction]), atol=max_load * 0.02)\n\n\ndef test_elastic_coupled():\n    mat = core.Elastic(\'steel_6\', {\'E\': 200e9, \'v\': 0.3})\n    np.random.seed(0)\n\n    loads1 = np.random.rand(16, 16)\n    loads2 = np.random.rand(16, 16)\n\n    directions = \'xyzx\'\n\n    for i in range(3):\n        dir_1 = directions[i]\n        dir_2 = directions[i+1]\n        loads_in_direction = {dir_1: loads1, dir_2: loads2}\n        displacement = mat.displacement_from_surface_loads(loads_in_direction, grid_spacing=0.01, simple=True)\n        loads_calc = mat.loads_from_surface_displacement(displacements=displacement,\n                                                         grid_spacing=0.01, simple=True)\n        for direction in [dir_1, dir_2]:\n            npt.assert_allclose(loads_in_direction[direction], slippy.asnumpy(loads_calc[direction]), atol=0.02)\n\n        displacement = mat.displacement_from_surface_loads(loads_in_direction, grid_spacing=0.01, simple=False)\n        loads_calc = mat.loads_from_surface_displacement(displacements=displacement,\n                                                         grid_spacing=0.01, simple=False)\n        for direction in [dir_1, dir_2]:\n            npt.assert_allclose(loads_in_direction[direction], slippy.asnumpy(loads_calc[direction]), atol=0.02)\n', 'is_package': False},
    'slippy.core.tests.test_multi_convolve_cuda': {'source': "import slippy\nimport slippy.core as core\nimport numpy as np\nimport numpy.testing as npt\nimport itertools\n\n\ndef test_basic_multi_convolve_cuda():\n    try:\n        import cupy as cp\n        slippy.CUDA = True\n    except ImportError:\n        return\n    comps = [a + b for a, b in itertools.product('xyz', 'xyz')]\n    ims = np.array([core.elastic_influence_matrix_spatial(comp, (64, 64), [1e-6] * 2, 200e9, 0.3) for comp in comps])\n    loads = np.zeros_like(ims[0])\n    loads[31, 31] = 1\n    out = core.plan_multi_convolve(loads, ims, circular=True, fft_ims=False)(loads)\n    for expt, got in zip(ims, out):\n        npt.assert_allclose(cp.asnumpy(got), cp.asnumpy(expt), atol=1e-30)\n\n\ndef test_vs_sequential():\n    try:\n        import cupy as cp\n        slippy.CUDA = True\n    except ImportError:\n        return\n    periodics = [(False, False), (True, False), (False, True), (True, True)]\n    domains = (None, 0.5 > np.random.rand(16, 16))\n    comps = ['xz', 'zz']\n    loads = np.random.rand(16, 16)\n    for p, d in itertools.product(periodics, domains):\n        im_shape = tuple((2-p)*s for p, s in zip(p, loads.shape))\n        ims = np.array([core.elastic_influence_matrix_spatial(comp, im_shape, [1e-6] * 2, 200e9, 0.3) for comp in comps])\n        multi_func = core.plan_multi_convolve(loads, ims, d, p, fft_ims=False)\n        if d is None:\n            multi_result = multi_func(loads)\n        else:\n            multi_result = multi_func(loads[d])\n        single_results = np.zeros_like(multi_result)\n        single_funcs = []\n        for i in range(2):\n            single_func = core.plan_convolve(loads, ims[i], d, p, fft_im=False)\n            if d is None:\n                single_results[i] = single_func(loads)\n            else:\n                single_results[i] = single_func(loads[d])\n            single_funcs.append(single_func)\n\n        npt.assert_allclose(cp.asnumpy(multi_result), cp.asnumpy(single_results), atol=1e-30)\n\n        if d is not None:\n            multi_result = multi_func(loads[d], ignore_domain=True)\n            single_results = np.zeros_like(multi_result)\n            for i in range(2):\n                single_results[i] = single_funcs[i](loads[d], ignore_domain=True)\n\n            npt.assert_allclose(cp.asnumpy(multi_result), cp.asnumpy(single_results), atol=1e-30)\n", 'is_package': False},
    'slippy.core.tests.test_multi_convolve_fftw': {'source': "import slippy\nimport slippy.core as core\nimport numpy as np\nimport numpy.testing as npt\nimport itertools\n\n\ndef test_basic_multi_convolve_fftw():\n    slippy.CUDA = False\n    comps = [a + b for a, b in itertools.product('xyz', 'xyz')]\n    ims = np.array([core.elastic_influence_matrix_spatial(comp, (64, 64), [1e-6] * 2, 200e9, 0.3) for comp in comps])\n    loads = np.zeros_like(ims[0])\n    loads[31, 31] = 1\n    out = core.plan_multi_convolve(loads, ims, circular=True, fft_ims=False)(loads)\n    for expt, got in zip(ims, out):\n        npt.assert_allclose(got, expt, atol=1e-30)\n\n\ndef test_multi_convolve_vs_sequential_fftw():\n    slippy.CUDA = False\n    periodics = [(False, False), (True, False), (False, True), (True, True)]\n    domains = (None, 0.5 > np.random.rand(16, 16))\n    comps = ['xz', 'zz']\n    loads = np.random.rand(16, 16)\n    for p, d in itertools.product(periodics, domains):\n        im_shape = tuple((2 - p) * s for p, s in zip(p, loads.shape))\n        ims = np.array([core.elastic_influence_matrix_spatial(comp, im_shape, [1e-6] * 2, 200e9, 0.3) for comp in comps])\n        multi_func = core.plan_multi_convolve(loads, ims, d, p, fft_ims=False)\n        if d is None:\n            multi_result = multi_func(loads)\n        else:\n            multi_result = multi_func(loads[d])\n        single_results = np.zeros_like(multi_result)\n        single_funcs = []\n        for i in range(2):\n            single_func = core.plan_convolve(loads, ims[i], d, p, fft_im=False)\n            if d is None:\n                single_results[i] = single_func(loads)\n            else:\n                single_results[i] = single_func(loads[d])\n            single_funcs.append(single_func)\n\n        npt.assert_allclose(multi_result, single_results, atol=1e-30)\n\n        if d is not None:\n            multi_result = multi_func(loads[d], ignore_domain=True)\n            single_results = np.zeros_like(multi_result)\n            for i in range(2):\n                single_results[i] = single_funcs[i](loads[d], ignore_domain=True)\n\n            npt.assert_allclose(multi_result, single_results, atol=1e-30)\n", 'is_package': False},
    'slippy.core.tests.test_output': {'source': 'import slippy.core as core\nimport numpy as np\nfrom tinydb import Query\n\n\ndef test_read_write_output():\n    with core.OutputSaver(\'test\') as output_w:\n        output_w.write({\'time\': 0, \'a\': 5, \'b\': np.array([1, 2, 3, 4]), \'c\': np.array([1, 2, 3, 4], dtype=float)})\n        output_w.write({\'time\': 1, \'a\': 10, \'c\': np.array([1, 2, 3, 4], dtype=float)})\n        output_w.write({\'time\': 2, \'a\': 15, \'b\': np.array([1, 2, 3, 4]), })\n        output_w.write({\'time\': 3, \'a\': 20, \'b\': np.array([1, 2, 3, 4]), \'c\': np.array([1, 2, 3, 4], dtype=float)})\n    output = core.OutputReader(\'test\')\n    assert output.time_points == [0, 1, 2, 3], str(output.time_points)\n    assert output.fields == {\'a\', \'b\', \'c\', \'time\'}, str(output.fields)\n    assert output[1][\'time\'] == 1\n    assert output[\'a\'] == {0: 5, 1: 10, 2: 15, 3: 20}\n    assert output[\'a\'][1] == output[1][\'a\']\n    result = Query()\n    assert output.search(result.a == 10)\n    times = []\n    for out in output:\n        times.append(out[\'time\'])\n    assert times == [0, 1, 2, 3]\n\n\ndef test_array_reading():\n    dtypes = [int, np.int64, float, np.complex64, np.complex128]\n    shapes = [(1,), (5,), (5, 6), (5, 6, 7)]\n    sizes = [1, 5, 30, 210]\n    i = 0\n    strings = []\n    with core.OutputSaver(\'test\') as output_w:\n        for dtype in dtypes:\n            for size, shape in zip(sizes, shapes):\n                for order in [\'C\', \'F\']:\n                    array = np.reshape(np.arange(size, dtype=dtype), newshape=shape)\n                    if order == \'F\':\n                        array = np.asfortranarray(array)\n                    output_w.write({\'time\': i, \'array\': array})\n                    i += 1\n                    strings.append(f\'dtype:{str(dtype)}, shape:{str(shape)}, order={order}\')\n\n    output = core.OutputReader(\'test\')\n    i = 0\n    for output_line in output:\n        array = np.array(output_line[\'array\']).flatten()\n        assert np.all(np.diff(array) == 1), "array not sorted " + strings[i]\n        assert np.all((np.round(array)-array) == 0), "array incorrect data " + strings[i]\n        i += 1\n\n\ndef test_lazy_array():\n    with core.OutputSaver(\'test\') as output_files:\n        output_files.write({\'my_array\': np.array([1, 2, 3, 4], dtype=np.int32)})\n    lazy_array = core.outputs._ArrayReader(\'test.sar\', \'**array**#0#(4,)#int32\')\n    assert np.max(lazy_array) == 4\n    lazy_array = core.outputs._ArrayReader(\'test.sar\', \'**array**#0#(4,)#int32\')\n    assert lazy_array[0] == 1\n', 'is_package': False},
    'slippy.core.tests.test_principal_stresses': {'source': 'from slippy.core import solve_cubic, get_derived_stresses\n\nfrom scipy.spatial.transform import Rotation as R\nimport numpy as np\nimport numpy.testing as npt\n\n# note these must be in order for comparison at end to work\ntest_matrix = [[300,   200,  100],\n               [200,   0,    0],\n               [-100, -200, -300],\n               [300,   0,   -300],\n               [200,  -100, -100],\n               [0,     0,    0],\n               [100,   100,  0],\n               [0,    -100, -100]]\n\n\ndef test_derived_stresses():\n    np.random.seed(0)\n    for stresses in test_matrix:\n        s1, s2, s3 = stresses\n        # make cauchy stress tensor\n        tensor = np.array([[s1, 0, 0],\n                           [0, s2, 0],\n                           [0, 0, s3]])\n        # rotate tensor\n        rotation = R.from_rotvec(2 * np.pi * np.random.rand(3))\n        rm = rotation.as_matrix()\n        rm_dash = rm.transpose()\n        rt = np.dot(rm, np.dot(tensor, rm_dash))\n        # make tensor (have to expand dims to ensure each element is an array\n        named_tensor = {\'xx\': np.expand_dims(rt[0, 0], 0), \'yy\': np.expand_dims(rt[1, 1], 0),\n                        \'zz\': np.expand_dims(rt[2, 2], 0), \'xy\': np.expand_dims(rt[0, 1], 0),\n                        \'xz\': np.expand_dims(rt[0, 2], 0), \'yz\': np.expand_dims(rt[1, 2], 0)}\n        # find principal stresses\n        found = get_derived_stresses(named_tensor, [\'1\', \'2\', \'3\'])\n        npt.assert_allclose(np.stack([found[\'1\'], found[\'2\'], found[\'3\']]).flatten(),\n                            np.array(stresses), atol=1e-6)\n\n\ndef test_solve_cubic_numba():\n    dtypes = [\'float64\', \'float32\']\n    for dtype in dtypes:\n        # designed to test all branches of the algo\n        b = np.array([3, 2, 3, 3, 4, 4, 4, 0], dtype=dtype)\n        c = np.array([1, 4 / 3, 1, 4, 7 / 3, 7, 0, 0], dtype=dtype)\n        d = np.array([0, 1, -1, 2, 2 - 1.6296296296296293, 2, -6, 0], dtype=dtype)\n        found_roots = np.transpose(np.stack(solve_cubic(b, c, d)))\n        all_coeffs = np.transpose(np.stack([np.ones_like(b), b, c, d]))\n        for coeffs, roots in zip(all_coeffs, found_roots):\n            np_roots = np.roots(coeffs)\n            np_roots = np.sort(np.real(np_roots[(np.abs(np_roots) - np.abs(np.real(np_roots))) < 1e-7]))\n            if len(roots) == len(np_roots):\n                npt.assert_allclose(roots, np_roots, atol=1e-7)\n            elif len(np_roots) == 1:\n                npt.assert_allclose(roots, [np_roots[0]] * 3, atol=1e-7)\n            else:\n                raise ValueError("This should never happen")\n\n\ndef test_solve_cubic_cuda():\n    try:\n        import cupy as cp\n    except ImportError:\n        return\n    dtypes = [\'float64\', \'float32\']\n    for dtype in dtypes:\n        # designed to test all branches of the algo\n        b = cp.array([3, 2, 3, 3, 4, 4, 4, 0], dtype=dtype)\n        c = cp.array([1, 4 / 3, 1, 4, 7 / 3, 7, 0, 0], dtype=dtype)\n        d = cp.array([0, 1, -1, 2, 2 - 1.6296296296296293, 2, -6, 0], dtype=dtype)\n        found_roots = cp.transpose(cp.stack(solve_cubic(b, c, d)))\n        all_coeffs = cp.transpose(cp.stack([cp.ones_like(b), b, c, d]))\n        for coeffs, roots in zip(all_coeffs, found_roots):\n            np_roots = np.roots(cp.asnumpy(coeffs))\n            np_roots = np.sort(np.real(np_roots[(np.abs(np_roots) - np.abs(np.real(np_roots))) < 1e-7]))\n            if len(roots) == len(np_roots):\n                npt.assert_allclose(cp.asnumpy(roots), np_roots, atol=1e-7)\n            elif len(np_roots) == 1:\n                npt.assert_allclose(cp.asnumpy(roots), [np_roots[0]] * 3, atol=1e-7)\n            else:\n                raise ValueError("This should never happen")\n', 'is_package': False},
    'slippy.data': {'source': '', 'is_package': True},
    'slippy.surface': {'source': '"""\n===========================================================\nSurface generation and manipulation (:mod:`slippy.surface`)\n===========================================================\n\n.. currentmodule:: slippy.surface\n\nThis package contains functions and classes for reading surfaces from file,\nmanipulating, generating and analysing surfaces.\n\nThe Surface class for experimental surfaces\n===========================================\n\nThe Surface class contains methods for reading surfaces from files including .mat, .txt, .csv and .al3d files. It also\ncontains methods for analysing surface roughness and other parameters.\n\n.. autosummary::\n   :toctree: generated/\n\n   Surface\n\n\nAnalytical Surfaces\n===================\n\nSurfaces which can be described by a mathematical function, these can be combined, rotated or shifted with no loss in\nresolution.\n\n.. autosummary::\n   :toctree: generated/\n\n   FlatSurface         -- Flat or sloping surface.\n   RoundSurface        -- Round surfaces\n   PyramidSurface      -- Square based pyramid surfaces\n   DiscFreqSurface     -- Surfaces containing specific frequency components\n   HurstFractalSurface -- A Hurst Fractal Surface\n\nRandom Surfaces\n===============\n\nSurfaces based on transformations of random surfaces or probabilistic descriptions of the FFT.\n\n.. autosummary::\n   :toctree: generated/\n\n   RandomPerezSurface     -- Surfaces with set height distribution and PSD found by the Perez method\n   RandomFilterSurface    --Surfaces from transformations of random sequences\n   ProbFreqSurface        -- Surfaces based on a probabilistic description of the FFT\n\nFunctions\n=========\n\nFunctional interfaces for common tasks, these are all aliased by class methods in the surface class, apart from\nsurface_like.\n\n.. autosummary::\n   :toctree: generated/\n\n   assurface              -- Make a surface object\n   read_surface           -- Read a surface object from file\n   alicona_read           -- Read alicona data files\n   read_tst_file          -- Read a bruker umt tst file\n   roughness              -- Find 2d roughness parameters\n   get_height_of_mat_vr   -- Find the height of a specified material or void volume ratio\n   get_mat_vr             -- Find the material or void volume ratio at a particular height\n   subtract_polynomial    -- Fit and subtract an n degree polynomial from a surface profile\n"""\n\n\nfrom .ACF_class import ACF\nfrom .Surface_class import Surface, assurface, read_surface, _AnalyticalSurface, RollingSurface\nfrom .Geometric import FlatSurface, RoundSurface, PyramidSurface\nfrom .Random import RandomFilterSurface, RandomPerezSurface\nfrom .FFTBased import ProbFreqSurface, DiscFreqSurface, HurstFractalSurface\nfrom .alicona import alicona_read\nfrom .roughness_funcs import roughness, subtract_polynomial, get_mat_vr, get_height_of_mat_vr\nfrom .read_tst_file import read_tst_file\n\n__all__ = [\'Surface\', \'assurface\', \'read_surface\', \'ACF\', \'FlatSurface\', \'RoundSurface\', \'PyramidSurface\',\n           \'RandomFilterSurface\', \'RandomPerezSurface\', \'ProbFreqSurface\', \'DiscFreqSurface\', \'HurstFractalSurface\',\n           \'alicona_read\', \'roughness\', \'subtract_polynomial\', \'get_mat_vr\', \'get_height_of_mat_vr\',\n           \'read_tst_file\', \'_AnalyticalSurface\', \'RollingSurface\']\n', 'is_package': True},
    'slippy.surface.ACF_class': {'source': 'import numpy as np\nimport types\nimport scipy.signal\nimport scipy.interpolate\nfrom slippy.core import _SurfaceABC\n\n__all__ = [\'ACF\']\n\n\nclass ACF(object):\n    """ A helper class for auto correlation functions\n\n    Produces ACFs that are independent ot the original grid spacing, these can\n    be used to generate random surfaces with any grid spacing.\n\n    Parameters\n    ----------\n    source : Surface object, array, function or str\n        The source for the ACF see notes\n    grid_spacing : float optional (None)\n        The distance between grid points in the surface profile, only needed\n        if source is an array\n\n    Other Parameters\n    ----------------\n    args : float optional (None)\n        If the source is a string, indicating the acf follows an equation, arg\n        are the constants in the equation\n\n    Attributes\n    ----------\n\n    method\n    original\n    acf_type\n\n    Methods\n    -------\n\n    call\n\n    Notes\n    -----\n\n    Valid options for the source are:\n\n        - A surface object\n        - An array, the grid_spacing parameter must also be set\n        - A function\n        - \'exp\' other args must be passed\n\n    If the source is \'exp\' three additional arguments must be passed. The\n    centre value of the acf (sigma) and the decay length in the x and y\n    directions (beta_x and beta_y). The acf is then calculated as:\n\n    sigma**2*np.exp(-2.3*np.sqrt((X/beta_x)**2+(Y/beta_y)**2))\n\n    If a function is given as the input it must take as arguments arrays of X\n    and Y coordinates and return an array of Z coordinates for example:\n\n    X,Y=np.meshgrid(range(10),range(10))\n\n    Z=input_function(X,Y)\n\n    Examples\n    --------\n\n    >>> # Generate an ACF with an exponential shape:\n    >>> ACF(\'exp\', 2, 0.1, 0.2)\n\n    >>> # Generate an ACF from a surface object:\n    >>> ACF(my_surface)\n\n    >>> # Generate an ACF from an array:\n    >>> my_acf=ACF(array, grid_spacing=1)\n    >>> # Get the original acf points:\n    >>> np.array(my_acf)\n\n    """\n\n    method = None\n    """The method which is called to generate points"""\n    original = None\n    """If the source is an array or a Surface object, the original acf array"""\n    acf_type = \'\'\n    """A description of the acf source"""\n\n    def __init__(self, source, *args, grid_spacing=1):\n        if type(source) is str:\n            self._input_check_string(source, args)\n            self.acf_type = "string"\n        elif isinstance(source, _SurfaceABC):\n            self._input_check_array(source.profile, grid_spacing=source.grid_spacing)\n            self.acf_type = "surface"\n        elif isinstance(source, types.FunctionType):\n            self._input_check_method(source)\n            self.acf_type = "function"\n        else:\n            if grid_spacing is None:\n                msg = "grid spacing positional argument must be supplied if ACF source is an array"\n                raise ValueError(msg)\n            self._input_check_array(source, grid_spacing)\n            # args should contain the grid_spacing of the array\n            self.acf_type = "array"\n\n    def _input_check_string(self, source, args):\n        supported_functions = [\'exp\', \'polynomial\']\n        if not (source in supported_functions):\n            msg = ("Function type not supported, supported types are:\\n" +\n                   "\\n".join(supported_functions) + "\\nfor custom functions pass "\n                                                    "the function object to this constructor")\n            raise NotImplementedError(msg)\n        if source == \'exp\':\n            sigma = args[0]\n            beta_x = args[1]\n            beta_y = args[2]\n            self.method = _exp_acf(sigma, beta_x, beta_y)\n        elif source == \'polynomial\':\n            pass\n            raise NotImplementedError("polynomial functions are not implemented")\n\n    def _input_check_array(self, source, grid_spacing, origin=\'centre\'):\n        try:\n            profile = np.asarray(source)\n        except ValueError:\n            msg = ("invalid input, input should be either a surface, function "\n                   "handle, function name as a string with relevant params or "\n                   "array-like")\n            raise ValueError(msg)\n        x = profile.shape[0]\n        y = profile.shape[1]\n        self.o_grid_spacing = grid_spacing\n        self.original = (scipy.signal.correlate(profile, profile, \'same\') / (x * y))\n\n        x = np.arange(x) * grid_spacing\n        y = np.arange(y) * grid_spacing\n\n        if type(origin) is str:\n            origin = origin.lower()\n            if origin == \'centre\':\n                origin = [np.mean(x), np.mean(y)]\n            else:\n                description = origin\n                origin = [0, 0]\n                if description[1] == \'r\' or description[1] == \'e\':\n                    origin[0] = max(x)\n                if description[0] == \'t\' or description[0] == \'n\':\n                    origin[1] = max(y)\n        x = x - origin[0]\n        y = y - origin[1]\n\n        self.method = scipy.interpolate.RectBivariateSpline(x, y, self.original)\n\n    def _input_check_method(self, source):\n        self.method = source\n\n    def __call__(self, x, y):\n        """\n        Evaluate the ACF at specified grid points\n\n        Parameters\n        ----------\n        x,y : 1D np.array\n            The x and y coordinates of the grid points to be evaluated, see notes for usage\n\n        Returns\n        -------\n        np.array\n            The \'height\' of the acf at the grip points requested\n\n        Notes\n        -----\n        The x and y parameters are turned into a grid before evaluating the ACF function\n\n        Examples\n        --------\n        >>> my_acf = ACF(\'exp\', None, 1, 1) # Make an ACF object with an exponential ACf\n        >>> # evaluate the acf a the points x=[-10,-8....,10], y==[-10,-8....,10]\n        >>> discrete_acf = my_acf(np.arange(-10, 11, 2), np.arange(-10, 11, 2))\n        >>> # The results is evaluated over the grid, not just at the specified points\n        >>> discrete_acf.shape\n        (11,11)\n        """\n        # feed to self.method\n        if self.acf_type in [\'array\', \'surface\']:\n            return self.method(x, y)\n        else:\n            mesh_x, mesh_y = np.meshgrid(x, y)\n            return self.method(mesh_x, mesh_y)\n\n    def __array__(self):\n        if self.original is not None:\n            return self.original\n        else:\n            raise ValueError("Could not return ACF as array, ACF must be made from"\n                             " an array or surface for this to work in stead use "\n                             "array(this(x_pts,y_pts)), see documentation for __call__ for more information")\n\n\ndef _exp_acf(sigma, beta_x, beta_y):\n    def inner(x_mesh, y_mesh):\n        raw = sigma ** 2 * np.exp(-2.3 * np.sqrt((x_mesh / beta_x) ** 2 + (y_mesh / beta_y) ** 2))\n        return raw\n    return inner\n', 'is_package': False},
    'slippy.surface.FFTBased': {'source': '"""\nClasses for generating pseudo-random surfaces based on description of FFT:\n    ===========================================================================\n    ===========================================================================\n    Each class inherits functionality from the Surface but changes the\n    __init__ and discretise functions\n    ===========================================================================\n    ===========================================================================\n    DiscFreqSurface:\n        Generate a surface containing only specific frequency components\n    ProbFreqSurface:\n        Generate a surface containing normally distributed amplitudes with a\n        specified function for the variance of the distribution based on the\n        frequency\n    DiscFreqSurface:\n        Generate a surface containing frequency components with amplitude\n        specified by a function of the frequency\n\n    ===========================================================================\n    ===========================================================================\n\n"""\n\nimport typing\nfrom numbers import Number\n\nimport numpy as np\n\nfrom .Surface_class import _AnalyticalSurface, Surface\n\n__all__ = ["DiscFreqSurface", "ProbFreqSurface", "HurstFractalSurface"]\n\n\nclass DiscFreqSurface(_AnalyticalSurface):\n    r""" Surfaces with discrete frequency components\n\n    This surface produces a profile with frequency components which are constant in th y direction,\n    these can be rotated and combined by addition or subtraction to give any combination of frequencies.\n\n    Parameters\n    ----------\n    frequencies: Sequence[float]\n        The frequencies present in the surface\n    amplitudes: Sequence[float], optional ((1, ))\n        The amplitude of each frequency, must be same length as frequencies\n    phases: typing.Sequence[float] = (0,)\n        The phases of each of the frequencies, must be the same length as frequencies\n    rotation: Number = 0\n        If set the surface is rotated by the set amount, in radians\n    shift: tuple, optional (None)\n        If set the origin of the surface is shifted by the set amount in the x and y directions, should be a two element\n        tuple of float. By default, the surface is shifted so that the origin becomes the centre of the surface. To stop\n        this behaviour specify a shift of (0, 0)\n    generate: bool, optional (False)\n        If True the surface profile is generated on instantiation, else it can be generated by the discretise method.\n        If True two of the: grid_spacing, extent or shape must also be set\n    grid_spacing: float, optional (None)\n        The grid spacing of the surface profile\n    extent: tuple, optional (None)\n        The overall dimensions of the surface in the same units as the grid spacing, should be a two element tuple of\n        float\n    shape: tuple = None\n        The number of points in each direction of the surface array, should be a two element tuple of integers\n\n    See Also\n    --------\n    ProbFreqSurface\n    HurstFractalSurface\n\n    Notes\n    -----\n    Roughness functions are aliased from the functions provided in the surface\n    module\n\n    Examples\n    --------\n    >>> mySurf=DiscFreqSurface(10, 0.1)\n    >>> mySurf.extent=[0.5,0.5]\n    >>> mySurf.discretise(0.001)\n\n    """\n    is_discrete = False\n    surface_type = \'discreteFreq\'\n\n    def __init__(self, frequencies: typing.Sequence[float], amplitudes: typing.Sequence[float] = (1,),\n                 phases: typing.Sequence[float] = (0,), rotation: Number = 0,\n                 shift: typing.Optional[tuple] = None,\n                 generate: bool = False, grid_spacing: float = None,\n                 extent: tuple = None, shape: tuple = None):\n\n        if type(frequencies) is list or type(frequencies) is np.ndarray:\n            self.frequencies = frequencies\n        else:\n            raise ValueError(\'Frequencies, amplitudes and phases must be equal\'\n                             \'length lists or np.arrays\')\n        is_complex = [type(amp) is complex for amp in amplitudes]\n        if any(is_complex):\n            if not len(frequencies) == len(amplitudes):\n                raise ValueError(\'Frequencies, amplitudes and phases must be\'\n                                 \' equal length lists or np.arrays\')\n            else:\n                self.amplitudes = amplitudes\n        else:\n            if not len(frequencies) == len(amplitudes) == len(phases):\n                raise ValueError(\'Frequencies, amplitudes and phases must be\'\n                                 \' equal length lists or np.arrays\')\n            else:\n                cplx_amps = []\n                for idx in range(len(amplitudes)):\n                    cplx_amps.append(amplitudes[idx] *\n                                     np.exp(1j * phases[idx]))\n                self.amplitudes = cplx_amps\n\n        super().__init__(generate=generate, rotation=rotation, shift=shift,\n                         grid_spacing=grid_spacing, extent=extent, shape=shape)\n\n    def _height(self, x_mesh, y_mesh):\n        profile = np.zeros_like(x_mesh)\n        for idx in range(len(self.frequencies)):\n            profile += np.real(self.amplitudes[idx] *\n                               np.exp(-1j * self.frequencies[idx] * x_mesh * 2 * np.pi))\n        return profile\n\n    def __repr__(self):\n        string = self._repr_helper()\n        return f\'DiscFreqSurface({self.frequencies}, {self.amplitudes}{string})\'\n\n\nclass ProbFreqSurface(_AnalyticalSurface):\n    """\n    ProbFreqSurface(H, qr, qs)\n\n    Generates a surface with all possible frequencies in the fft represented\n    with amplitudes described by the probability distribution given as input.\n    Defaults to the parameters used in the contact mechanics challenge\n\n    This class only works for square 2D domains\n\n    For more information the definitions of the input parameters refer to\n    XXXXXX contact mechanics challenge paper\n\n    """\n\n    is_discrete = False\n    surface_type = \'Random\'\n\n    def __init__(self, h=2, qr=0.05, qs=10,\n                 generate: bool = False, grid_spacing: float = None,\n                 extent: tuple = None, shape: tuple = None):\n        self.h = h\n        self.qs = qs\n        self.qr = qr\n        super().__init__(grid_spacing=grid_spacing, extent=extent, shape=shape, generate=generate)\n\n    def rotate(self, radians: Number):\n        raise NotImplementedError("Probabilistic frequency surface cannot be rotated")\n\n    def shift(self, shift: tuple = None):\n        if shift is None:\n            return\n        raise NotImplementedError("Probabilistic frequency surface cannot be shifted")\n\n    def _height(self, x_mesh, y_mesh):\n        grid_spacing, extent, shape = check_coords_are_simple(x_mesh, y_mesh)\n\n        qny = np.pi / grid_spacing\n\n        u = np.linspace(0, qny, shape[0])\n        u_mesh, v_mesh = np.meshgrid(u, u)\n        freqs = np.abs(u_mesh + v_mesh)\n        varience = np.zeros(freqs.shape)\n        varience[np.logical_and((1 / freqs) > (1 / self.qr), (2 * np.pi / freqs) <= (extent[0]))] = 1\n        varience[np.logical_and((1 / freqs) >= (1 / self.qs), (1 / freqs) < (1 / self.qr))] = \\\n            (freqs[np.logical_and(1 / freqs >= 1 / self.qs, 1 / freqs < 1 / self.qr)] / self.qr) ** (-2 * (1 + self.h))\n\n        fou_trans = np.reshape(np.array([np.random.normal() * var ** 0.5 for var in varience.flatten()]), freqs.shape)\n        return np.real(np.fft.ifft2(fou_trans))\n\n    def __repr__(self):\n        string = self._repr_helper()\n        return f\'ProbFreqSurface(h={self.h}, qr={self.qr}, qs={self.qs}{string})\'\n\n\nclass HurstFractalSurface(Surface):\n    r"""Hurst fractal surfaces\n\n    Parameters\n    ----------\n    sigma: float\n        The RSM roughness of the surface\n    hurst_exponent: float\n        The hurst exponent, must be between 0 and 1, related to the fractal dimension by D = 3-H\n    roll_off_frequency: float, optional (0.0)\n    generate: bool, optional (False)\n        If true the surface profile is generated on instantiation, two of: grid_spacing, extent or shape must be set\n    grid_spacing: float, optional (None)\n        The grid spacing of the surface profile\n    extent: tuple, optional (None)\n        The overall surface dimensions in the x and y directions\n    shape: tuple, optional (None)\n        The number of grid points in the x and y directions, computation is faster for powers of 2\n\n    See Also\n    --------\n\n    ProbFreqSurface\n    RandomSurface\n    surface_like\n\n    Notes\n    -----\n\n    generates a hurst fractal surface with frequency components from q0 to\n    cut off frequency in even steps of q0.\n\n    amplitudes are given by:\n\n    q0 amplitude\\*\\*2 \\*((h\\*\\*2+k\\*\\*2)/2)\\*\\*(1-Hurst parameter)\n\n    where h,k = \\-N...N\n    where N=cut off frequency/ q0\n    phases are randomly generated on construction of the surface object,\n    repeated calls to the discretise function will discretise on the same surface\n    but repeated calls to this class will generate different realisations\n\n    References\n    ----------\n\n    A new efficient numerical method for contact mechanics of rough surfaces\n    C.Putignano L.Afferrante G.Carbone G.Demelio\n\n    Examples\n    --------\n\n    >>> #create the surface object with the specified fractal parameters\n    >>> my_surface=HurstFractalSurface(1,0.2,1000, shape=(128, 128), grid_spacing=0.01)\n    >>> #descrtise the surface over a grid 1 unit by 1 unit with a grid_spacing of 0.01\n    >>> my_surface.discretise()\n    >>> my_surface.show()\n\n    """\n    is_discrete = False\n    surface_type = "hurstFractal"\n\n    def __init__(self, sigma: float, hurst_exponent: float, roll_off_frequency: float = 0, generate: bool = False,\n                 grid_spacing: float = None, extent: tuple = None, shape: tuple = None):\n        self.input_params = (sigma, hurst_exponent, roll_off_frequency)\n\n        if hurst_exponent > 1 or hurst_exponent < 0:\n            raise ValueError(\'Hurst exponent must be between 0 and 1\')\n\n        self._hurst_exponent = hurst_exponent\n        self._sigma = sigma\n        self._roll_off_frequency = roll_off_frequency\n\n        super().__init__(grid_spacing=grid_spacing, extent=extent, shape=shape)\n\n        if generate:\n            self.discretise()\n\n    def discretise(self, return_new: bool = False):\n        """Generate a new profile realisation, return a new surface if needed\n\n        Parameters\n        ----------\n        return_new: bool\n            If True a new surface instance is returned, else the profile property of the current surface is set\n\n        Returns\n        -------\n        out: Surface\n            A new surface object with the profile set, will have the same shape and grid spacing as the current object\n            only returned if return_new is True\n\n        Notes\n        -----\n        As a side effect this will set the FFT and PSD properties of the discretised surface.\n\n        Copyright (c) 2016, Mona Mahboob Kanafi\n        All rights reserved.\n\n        Redistribution and use in source and binary forms, with or without\n        modification, are permitted provided that the following conditions are met:\n\n        * Redistributions of source code must retain the above copyright notice, this\n          list of conditions and the following disclaimer.\n\n        * Redistributions in binary form must reproduce the above copyright notice,\n          this list of conditions and the following disclaimer in the documentation\n          and/or other materials provided with the distribution\n        * Neither the name of Aalto University nor the names of its\n          contributors may be used to endorse or promote products derived from this\n          software without specific prior written permission.\n        THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"\n        AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n        IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n        DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\n        FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n        DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n        SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n        CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n        OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n        OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n        References\n        ----------\n        Code ported from the matlab version:\n        https://uk.mathworks.com/matlabcentral/fileexchange/60817-surface-generator-artificial-randomly-rough-surfaces?s_tid=mwa_osa_a\n        """\n        if self.profile is not None and not return_new:\n            raise ValueError(\'Profile is already set, set the return_new argument to true to return a new surface \'\n                             \'instance with the same fractal properties\')\n\n        if self.shape is None or self.grid_spacing is None:\n            raise ValueError(\'Grid spacing and shape of the surface must be set before a hurst fractal can be \'\n                             \'generated\')\n\n        m, n = [s + s % 2 for s in self.shape]\n        grid_spacing = self.grid_spacing\n        hurst_exponent = self._hurst_exponent\n        sigma = self._sigma\n        qr = self._roll_off_frequency\n\n        lx, ly = [n_pts * grid_spacing for n_pts in [m, n]]\n        # make the wave vectors\n        qx = np.array([2 * np.pi / m * k for k in range(m)])\n        qx = np.unwrap((np.fft.fftshift(qx)) - 2 * np.pi) / grid_spacing\n\n        qy = np.array([2 * np.pi / n * k for k in range(n)])\n        qy = np.unwrap((np.fft.fftshift(qy)) - 2 * np.pi) / grid_spacing\n\n        # find absolute frequencies\n        qx_mesh, qy_mesh = np.meshgrid(qx, qy)\n        rho = (qy_mesh ** 2 + qx_mesh ** 2) ** 0.5\n\n        # make the PSD matrix\n        psd = rho ** (-2 * (hurst_exponent + 1))\n        psd[rho < qr] = qr ** (-2 * (hurst_exponent + 1)) if qr > 0 else np.inf\n        psd[n // 2, m // 2] = 0.0\n\n        # Scale surface to sigma (apply rms)\n        rms_f2d = np.sqrt(sum(psd.flatten()) * (2 * np.pi) ** 2 / lx / ly)\n        alpha = sigma / rms_f2d\n        psd *= alpha ** 2\n        self.psd = np.fft.ifftshift(psd)\n\n        # converting the PSD to the fft\n        magnitudes = np.sqrt(psd / (grid_spacing ** 2 / (n * m * (2 * np.pi) ** 2)))\n        magnitudes = _conj_sym(magnitudes)\n        phases = -np.pi + (2 * np.pi) * np.random.rand(n, m)\n        phases = _conj_sym(phases, neg=True)\n\n        u, v = _pol2cart(magnitudes, phases)\n        fou_trans = np.empty(u.shape, dtype=complex)\n        fou_trans.real = u\n        fou_trans.imag = v\n\n        fou_trans = np.fft.ifftshift(fou_trans)\n\n        profile = np.fft.ifft2(fou_trans)\n\n        profile = profile.real\n\n        if return_new:\n            out = Surface(profile=profile, grid_spacing=grid_spacing)\n            out.psd = psd\n            out.fft = fou_trans\n            return out\n\n        self.profile = profile\n        self.fft = fou_trans\n\n    def __repr__(self):\n        string = super().__repr__()[:-1]\n        input_param_string = \', \'.join([str(p) for p in self.input_params])\n        return f\'HurstFractal{string}, {input_param_string[:-1]})\'\n\n    def rotate(self, radians: Number):\n        raise NotImplementedError("Hurst fractal surface cannot be rotated")\n\n    def shift(self, shift: tuple = None):\n        if shift is None:\n            return\n        raise NotImplementedError("Hurst fractal surface cannot be shifted")\n\n\ndef check_coords_are_simple(x_mesh, y_mesh):\n    """\n    Checks that the coordinates are of the type np.meshgrid(np.arrange(0, end, step), np.arrange(0, end, step))\n\n    Parameters\n    ----------\n    x_mesh: np.ndarray\n    y_mesh: np.ndarray\n\n    Returns\n    -------\n    grid_spacing, extent, shape\n    """\n    x_mesh_check, y_mesh_check = np.meshgrid(x_mesh[0, :], x_mesh[0, :])\n\n    difference = np.diff(x_mesh[0, :])\n    if not np.allclose(difference, difference[0]):\n        raise ValueError(\'x and y points must be evenly spaced and sorted\')\n\n    if not x_mesh[0, 0] == 0:\n        raise ValueError(\'x and y points must start at 0\')\n\n    if not x_mesh_check == x_mesh and y_mesh_check == y_mesh:\n        raise ValueError("For discretising a Probabilistic frequency surface the x and y coordinates should form"\n                         " an evenly spaced grid aligned with the axes")\n\n    extent = (x_mesh[0, -1], x_mesh[0, -1])\n    grid_spacing = difference[0]\n    shape = [ex / grid_spacing + 1 for ex in extent]\n    return grid_spacing, extent, shape\n\n\ndef _conj_sym(matrix: np.ndarray, in_place=True, neg=False):\n    """ apply conjugate symmetry to a matrix\n    """\n    try:\n        n, m = matrix.shape\n    except AttributeError:\n        raise ValueError(f\'Input matrix must be a 2d numpy array, got {type(matrix)}\')\n\n    mult = -1 if neg else 1\n\n    if not in_place:\n        matrix = matrix.copy()\n    matrix[0, 0] = 0.0\n    matrix[0, m // 2] = 0.0\n    matrix[n // 2, 0] = 0.0\n    matrix[n // 2, m // 2] = 0.0\n\n    matrix[1:, 1:m // 2] = mult * np.rot90(matrix[1:, m // 2 + 1:], 2)\n    matrix[0, 1:m // 2] = mult * np.flip(matrix[0, m // 2 + 1:])  # just needs to flip it\n    matrix[n // 2 + 1:, 0] = mult * np.flip(matrix[1:n // 2, 0])  # also just needs to flip it\n    matrix[n // 2 + 1:, m // 2] = mult * np.flip(matrix[1:n // 2, m // 2])\n\n    return matrix\n\n\ndef _pol2cart(rho, phi):\n    x = rho * np.cos(phi)\n    y = rho * np.sin(phi)\n    return x, y\n', 'is_package': False},
    'slippy.surface.Geometric': {'source': '"""\nClasses for generating geometric surfaces:\n    ===========================================================================\n    ===========================================================================\n    Each class inherits functionality from the _AnalyticalSurface class but changes the\n    __init__, _height and __repr__ functions\n    ===========================================================================\n    ===========================================================================\n\n    FlatSurface:\n        For generating flat surfaces, slopes are allowed in both directions\n    PyramidSurface:\n        For generating square pyramid surfaces like indenters\n    RoundSurface:\n        For generating ball type surfaces different radii allowed in each\n        direction\n\n    ===========================================================================\n    ===========================================================================\n\n"""\n\n__all__ = [\'FlatSurface\', \'RoundSurface\', \'PyramidSurface\']\n\nimport collections.abc\nimport typing\nimport warnings\nfrom numbers import Number\n\nimport numpy as np\n\nfrom .Surface_class import _AnalyticalSurface\n\n\nclass FlatSurface(_AnalyticalSurface):\n    """ Flat surface can be angled in any direction by changing slope\n\n    Parameters\n    ----------\n    slope : {tuple, float}, optional (0,0)\n        The gradient of the surface in the x and y directions\n    rotation: float, optional (None)\n        If set the surface will be rotated by this number of radians\n    shift: tuple, optional (None)\n        If set the surface will be shifted by this distance in the and y directions, tuple should be length 2, if not\n        set the default is to shift by half the extent, meaning that the origin becomes the centre.\n    generate: bool, optional (False)\n        If True the surface profile is discretised on instantiation.\n    grid_spacing: float, optional (None)\n        The distance between grid points on the surface profile\n    extent: tuple, optional (None)\n        The overall size of the surface\n    shape: tuple, optional (None)\n        The number of grid points in each direction on the surface\n\n\n    Attributes\n    ----------\n\n    See Also\n    --------\n    Surface\n\n    Notes\n    -----\n    This is a subclass of Surface all functionality and attributes are available\n    within this class.\n\n    All keyword arguments allowed for Surface are also\n    allowed on instantiation of this class apart from the profile key word.\n\n    If the extent is findable on instantiation the surface will be shifted so the natural origin is in the centre\n    of the extent. If the extent is not findable the natural origin will be at (0,0)\n\n    Examples\n    --------\n\n    Make an analytically defined flat surface with no slope:\n\n    >>> import slippy.surface as s\n    >>> my_surface = s.FlatSurface()\n\n    Make a discretely defined flat surface with no slope:\n\n    >>> my_surface = s.FlatSurface(grid_spacing = 1e-6, shape = (256, 256), generate=True)\n\n    Alternatively, any two of: shape, extent and grid_spacing can be set, eg:\n\n    >>> my_surface = s.FlatSurface(extent = (1e-5, 1e-5), shape = (256, 256), generate=True)\n\n    """\n    surface_type = \'flat\'\n    analytic = True\n\n    def __init__(self, slope: typing.Union[tuple, float] = (0, 0), rotation: float = None,\n                 shift: typing.Optional[tuple] = None,\n                 generate: bool = False, grid_spacing: float = None,\n                 extent: tuple = None, shape: tuple = None):\n        if isinstance(slope, collections.abc.Sequence):\n            self._slope = slope\n        elif isinstance(slope, Number):\n            # noinspection PyTypeChecker\n            slope = float(slope)\n            self._slope = [slope, 0]\n            if self.dimensions == 2:\n                warnings.warn("Assumed 0 slope in Y direction for"\n                              " analytical flat surface")\n        super().__init__(generate=generate, rotation=rotation, shift=shift,\n                         grid_spacing=grid_spacing, extent=extent, shape=shape)\n\n    def _height(self, x_mesh, y_mesh):\n        """Analytically determined height of the surface at specified points\n\n        Parameters\n        ----------\n        x_mesh, y_mesh : array-like\n            Arrays of X and Y points, must be the same shape\n\n        Returns\n        -------\n        Array of surface heights, with the same shape as the input arrays\n\n        Notes\n        -----\n        This is an alternative to discretise which may be more\n        appropriate for some applications\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> my_surface=FlatSurface(slope=(1,1))\n        >>> x, y = np.arange(10), np.arange(10)\n        >>> X, Y = np.meshgrid(x,y)\n        >>> Z=my_surface.height(X, Y)\n        """\n        return x_mesh * self._slope[0] + y_mesh * self._slope[1]\n\n    def __repr__(self):\n        string = self._repr_helper()\n        return \'FlatSurface(slope=\' + repr(self._slope) + string + \')\'\n\n\nclass RoundSurface(_AnalyticalSurface):\n    """ Round surfaces with any radii\n\n    Parameters\n    ----------\n    radius : Sequence\n        The radius of the surface in the X Y and Z directions, or in all\n        directions if a float is given\n    rotation: float, optional (None)\n        If set the surface will be rotated by this number of radians\n    shift: tuple, optional (None)\n        If set the surface will be shifted by this distance in the and y directions, tuple should be length 2, if not\n        set the default is to shift by half the extent, meaning that the origin becomes the centre.\n    generate: bool, optional (False)\n        If True the surface profile is discretised on instantiation.\n    grid_spacing: float, optional (None)\n        The distance between grid points on the surface profile\n    extent: tuple, optional (None)\n        The overall size of the surface\n    shape: tuple, optional (None)\n        The number of grid points in each direction on the surface\n\n\n    See Also\n    --------\n    Surface\n\n    Notes\n    -----\n    This is a subclass of Surface all functionality and attributes are available\n    within this class.\n\n    All keyword arguments allowed for Surface are also\n    allowed on instantiation of this class apart from the profile key word.\n\n    If the extent is findable on instantiation the surface will be shifted so the natural origin is in the centre\n    of the extent. If the extent is not findable the natural origin will be at (0,0).\n    For a round surface the natural origin is the centre of the ball.\n\n    Examples\n    --------\n    Making an analytically defined spherical surface with radius 1:\n\n    >>> import slippy.surface as s\n    >>> my_surface = s.RoundSurface((1,1,1), extent=(0.5,0.5))\n\n    Making a discretely defined cylindrical surface:\n\n    >>> my_surface = s.RoundSurface((1,float(\'inf\'),1), extent=(0.5,0.5), grid_spacing=0.001, generate = True)\n\n    Making a discretely defined cylindrical surface which is rotated 45 degrees:\n\n    >>> my_surface = s.RoundSurface((1,float(\'inf\'),1), extent=(0.5, 0.5), shape=(512, 512), generate = True,\n    >>>                             rotation=3.14/4)\n\n    """\n    radius: tuple\n\n    def __init__(self, radius: typing.Sequence, rotation: float = None,\n                 shift: typing.Optional[tuple] = None,\n                 generate: bool = False, grid_spacing: float = None,\n                 extent: tuple = None, shape: tuple = None):\n\n        if isinstance(radius, Number):\n            radius = (radius,)*3\n        radius = [r if r else np.inf for r in radius]\n        if np.isinf(radius[-1]):\n            raise ValueError(\'Radius in the z direction must be set\')\n        if isinstance(radius, collections.abc.Sequence) and len(radius) == 3:\n            self._radius = radius\n        else:\n            msg = (\'Radius must be either scalar or list of radii equal in \'\n                   \'length to number of dimensions of the surface +1\')\n            raise ValueError(msg)\n        super().__init__(generate=generate, rotation=rotation, shift=shift,\n                         grid_spacing=grid_spacing, extent=extent, shape=shape)\n\n    def _height(self, x_mesh, y_mesh):\n        """Analytically determined height of the surface at specified points\n\n        Parameters\n        ----------\n        x_mesh, y_mesh : array-like\n            Arrays of x and y points, must be the same shape\n\n        Returns\n        -------\n        Array of surface heights, with the same shape as the input arrays\n\n        Notes\n        -----\n        This is an alternative to discretise the surface which may be more\n        appropriate for some applications\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> my_surface=RoundSurface(radius=(1,1,1))\n        >>> x, y = np.arange(10), np.arange(10)\n        >>> x_mesh, y_mesh = np.meshgrid(x,y)\n        >>> Z=my_surface.height(x_mesh, y_mesh)\n        """\n        # noinspection PyTypeChecker\n        z = ((1 - (x_mesh / self._radius[0]) ** 2 - (y_mesh / self._radius[1]) ** 2) *\n             self._radius[-1]**2)**0.5 - self._radius[-1]\n        return np.nan_to_num(z, False)\n\n    def __repr__(self):\n        string = self._repr_helper()\n        return \'RoundSurface(radius=\' + repr(self._radius) + string + \')\'\n\n\nclass PyramidSurface(_AnalyticalSurface):\n    """ Pyramid surface with any slopes\n\n    Parameters\n    ----------\n    lengths : {Sequence, float}\n        The characteristic lengths of the pyramid in each direction, if a scalar is given the results is a square based\n        pyramid with 45 degree sides\n    rotation: float, optional (None)\n        If set the surface will be rotated by this number of radians\n    shift: tuple, optional (None)\n        If set the surface will be shifted by this distance in the and y directions, tuple should be length 2, if not\n        set the default is to shift by half the extent, meaning that the origin becomes the centre.\n    generate: bool, optional (False)\n        If True the surface profile is discretised on instantiation.\n    grid_spacing: float, optional (None)\n        The distance between grid points on the surface profile\n    extent: tuple, optional (None)\n        The overall size of the surface\n    shape: tuple, optional (None)\n        The number of grid points in each direction on the surface\n\n    See Also\n    --------\n    Surface\n\n    Notes\n    -----\n    This is a subclass of Surface all functionality and attributes are available\n    within this class.\n\n    All keyword arguments allowed for Surface are also\n    allowed on instantiation of this class apart from the profile key word.\n\n    If the extent is findable on instantiation the surface will be shifted so the natural origin is in the centre\n    of the extent. If the extent is not findable the natural origin will be at (0,0).\n    For a round surface the natural origin is the centre of the ball.\n\n    Examples\n    --------\n    Making an analytically defined square based pyramid:\n\n    >>> import slippy.surface as s\n    >>> my_surface = s.PyramidSurface((1,1,1), extent=(0.5,0.5))\n\n    Making a discretely defined square based pyramid:\n\n    >>> my_surface = s.PyramidSurface((1, 1, 3), extent=(0.5,0.5), grid_spacing=0.001, generate = True)\n    """\n    surface_type = \'pyramid\'\n\n    def __init__(self, lengths: typing.Union[typing.Sequence], rotation: float = None,\n                 shift: typing.Optional[tuple] = None,\n                 generate: bool = False, grid_spacing: float = None,\n                 extent: tuple = None, shape: tuple = None):\n        if isinstance(lengths, Number):\n            lengths = (lengths, ) * 3\n\n        if type(lengths) is tuple:\n            if len(lengths) == (self.dimensions + 1):\n                self._lengths = lengths\n            else:\n                msg = (\'Lengths must be either scalar or list of Lengths equal\'\n                       \' in length to number of dimensions of the surface +1\')\n                raise ValueError(msg)\n        super().__init__(generate=generate, rotation=rotation, shift=shift,\n                         grid_spacing=grid_spacing, extent=extent, shape=shape)\n\n    def _height(self, x_mesh, y_mesh):\n        """Analytically determined height of the surface at specified points\n\n        Parameters\n        ----------\n        x_mesh, y_mesh : array-like\n            Arrays of X and Y points, must be the same shape\n\n        Returns\n        -------\n        Array of surface heights, with the same shape as the input arrays\n\n        Notes\n        -----\n        This is an alternative to discretise the surface which may be more\n        appropriate for some applications\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> my_surface=PyramidSurface(lengths=[20,20,20])\n        >>> x, y = np.arange(10), np.arange(10)\n        >>> X, Y = np.meshgrid(x,y)\n        >>> Z=my_surface.height(X, Y)\n        """\n        return (0 - np.abs(x_mesh) / self._lengths[0] - np.abs(y_mesh) / self._lengths[1]) * self._lengths[-1]\n\n    def __repr__(self):\n        string = self._repr_helper()\n        return \'PyramidSurface(lengths=\' + repr(self._lengths) + string + \')\'\n', 'is_package': False},
    'slippy.surface.Random': {'source': '# change random iteration methods to work with scipy optimize way more methods avalible\n"""\n#TODO:\n        Sort out documentation for each method\n\n"""\n\nimport typing\nimport warnings\nfrom collections import defaultdict\n\nimport numpy as np\nimport scipy.stats\nfrom scipy.optimize import minimize\nfrom scipy.signal import fftconvolve\nfrom numba import njit\n\nfrom .ACF_class import ACF\nfrom .Surface_class import Surface, _Surface\nfrom ._johnson_utils import _fit_johnson_by_moments, _fit_johnson_by_quantiles\n\n__all__ = [\'RandomFilterSurface\', \'RandomPerezSurface\']\n\n\nclass RandomPerezSurface(_Surface):\n    """ Surfaces with set height distribution and PSD found by the Perez method\n\n    Parameters\n    ----------\n    target_psd: np.ndarray\n        The PSD which the surface will approximate, the shape of the surface will be the same as the psd array\n        (the same number of points in each direction)\n    height_distribution: {scipy.stats.rv_continuous, sequence}\n        Either a scipy.stats distribution or a sequence of the same size as the required output\n    accuracy: float, optional (1e-3)\n        The accuracy required for the solution to be considered converged, see the notes of the discretise method for\n        more information\n    max_it: int, optional (100)\n        The maximum number of iterations used to discretise a realisation\n    min_speed: float, optional (1e-10)\n        The minimum speed of the iterations, if the iterations are converging slower than this they are deemed not to\n        converge\n    generate: bool, optional (False)\n        If True the surface profile is found on instantiation\n    grid_spacing: float, optional (None)\n        The distance between grid points on the surface\n    exact: {\'psd\', \'heights\', \'best\'}, optional (\'best\')\n\n\n    Notes\n    -----\n    This method iterates between a surface with the exact right height distribution and one with the exact right PSD\n    this method is not guaranteed to converge for all surfaces, for more details see the reference.\n\n    Examples\n    --------\n    Making a surface with a normal height distribution and a given power spectra.\n\n    >>> import numpy as np\n    >>> import scipy.stats as stats\n    >>> import slippy.surface as s\n    >>> # making a surface with an exponential ACF as described in the original paper:\n    >>> beta = 10 # the drop off length of the acf\n    >>> sigma = 1 # the roughness of the surface\n    >>> qx = np.arange(-128,128)\n    >>> qy = np.arange(-128,128)\n    >>> Qx, Qy = np.meshgrid(qx,qy)\n    >>> Cq = sigma**2*beta/(2*np.pi*(beta**2+Qx**2+Qy**2)**0.5) # the PSD of the surface\n    >>> Cq = np.fft.fftshift(Cq)\n    >>> height_distribution = stats.norm()\n    >>> my_surface = s.RandomPerezSurface(target_psd = Cq, height_distribution=height_distribution,\n    >>>                                   grid_spacing=1,\n    >>>                                   generate=True)\n    >>> my_surface.show()\n\n    References\n    ----------\n    Based on the method and code given in:\n\n    Francesc Pérez-Ràfols, Andreas Almqvist,\n    Generating randomly rough surfaces with given height probability distribution and power spectrum,\n    Tribology International,\n    Volume 131,\n    2019,\n    Pages 591-604,\n    ISSN 0301-679X,\n    https://doi.org/10.1016/j.triboint.2018.11.020.\n    (http://www.sciencedirect.com/science/article/pii/S0301679X18305607)\n\n    """\n\n    dist: scipy.stats.rv_continuous = None\n    _rvs: np.ndarray = None\n\n    def __init__(self, target_psd: np.ndarray,\n                 height_distribution: typing.Union[scipy.stats.rv_continuous, typing.Sequence] = None,\n                 accuracy: float = 1e-3, max_it: int = 100, min_speed: float = 1e-10,\n                 generate: bool = False, grid_spacing: float = None, exact: str = \'best\'):\n\n        super().__init__(grid_spacing, None, None)\n        self._target_psd = target_psd\n        if height_distribution is None:\n            height_distribution = scipy.stats.norm()\n        try:\n            if hasattr(height_distribution, \'rvs\'):\n                self.dist = height_distribution\n            elif len(height_distribution) == target_psd.size or height_distribution.size == target_psd.size:\n                self._rvs = np.array(height_distribution).flatten()\n        except AttributeError:\n            raise ValueError(\'Unrecognised type for height distribution\')\n        self._accuracy = accuracy\n        self._max_it = max_it\n        self._min_speed = min_speed\n        if exact not in {\'psd\', \'heights\', \'best\'}:\n            raise ValueError("exact not recognised should be one of {\'psd\', \'heights\', \'best\'}")\n        self._exact = exact\n        if generate:\n            self.discretise()\n\n    def __repr__(self):\n        pass\n\n    def discretise(self, return_new: bool = False, accuracy: float = None, max_it: int = None, min_speed: float = None,\n                   suppress_errors: bool = False, return_original: bool = False):\n        """Discretise the surface with a realisation\n\n        Parameters\n        ----------\n        return_new: bool, optional (False)\n            If True a new surface is returned else Nothing is returned and the profile property of the surface is set\n        accuracy: float, optional (None)\n            The tolerance used to detect convergence of the psd and height distribution, if not set defaults to the\n            value set on initialisation\n        max_it: int, optional (None)\n            The maximum number of iterations used to fit the PSD and height spectra, if not set defaults to the value\n            set on initialisation\n        min_speed: float, optional (None)\n            The minimum speed which the iterations can be converging before they are stopped (assumed to be not\n            converging), if not set defaults to the value set on initialisation\n        suppress_errors: bool, optional (False)\n            If True convergence errors are suppressed and the profile realisation is made even if the solution has not\n            converged, warnings are produced\n        return_original: bool, optional (False)\n            If True the variables returned by the original code given in the paper are returned, these are: the\n            estimated surface with the correct height distribution, the estimated surface with the correct PSD and a\n            dict of errors with each element being a list of error values with one value for each iteration.\n\n        Returns\n        -------\n        Will return a new surface object if the return_new argument is True, otherwise sets the profile property of the\n        parent surface\n        Will return two surface estimates and a dict of errors  if return_original is True\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import scipy.stats as stats\n        >>> import slippy.surface as s\n        >>> # making a surface with an exponential ACF as described in the original paper:\n        >>> beta = 10 # the drop off length of the acf\n        >>> sigma = 1 # the roughness of the surface\n        >>> qx = np.arange(-128,128)\n        >>> qy = np.arange(-128,128)\n        >>> Qx, Qy = np.meshgrid(qx,qy)\n        >>> Cq = sigma**2*beta/(2*np.pi*(beta**2+Qx**2+Qy**2)**0.5) # the PSD of the surface\n        >>> height_distribution = stats.norm()\n        >>> my_surface = s.RandomPerezSurface(target_psd = Cq, height_distribution=height_distribution, grid_spacing=1)\n        >>> my_surface.discretise()\n        >>> my_surface.show()\n        Zh, Zs, error = fractal_surf_generator(np.fft.ifftshift(Cq),\n                                               np.random.randn(256,256),\n                                               min_speed = 1e-10,max_error=0.01)\n\n        Notes\n        -----\n        During iteration of this solution two surfaces are maintained, one which has the correct PSD and one which has\n        the correct height distribution, the one returned is the one which was first deemed to have converged. To over\n        ride this behaviour set return original to True\n\n        References\n        ----------\n\n        Francesc Pérez-Ràfols, Andreas Almqvist,\n        Generating randomly rough surfaces with given height probability distribution and power spectrum,\n        Tribology International,\n        Volume 131,\n        2019,\n        Pages 591-604,\n        ISSN 0301-679X,\n        https://doi.org/10.1016/j.triboint.2018.11.020.\n        (http://www.sciencedirect.com/science/article/pii/S0301679X18305607)\n        """\n        if return_original and return_new:\n            raise ValueError("Only one of return_new and return_original can be set to True")\n\n        accuracy = self._accuracy if accuracy is None else accuracy\n        max_it = self._max_it if max_it is None else max_it\n        min_speed = self._min_speed if min_speed is None else min_speed\n\n        # scale and centre the PSD\n        power_spectrum = self._target_psd\n        m, n = power_spectrum.shape\n        power_spectrum[0, 0] = 0\n        power_spectrum = power_spectrum / np.sqrt(np.sum(power_spectrum.flatten() ** 2)) * m * n\n\n        # generate random values for the surface\n        if self.dist is not None:\n            height_distribution = self.dist.rvs(power_spectrum.shape).flatten()\n        elif self._rvs is not None:\n            height_distribution = self._rvs\n        else:\n            raise ValueError("Height distribution not set, cannot descretise")\n\n        # scale and centre the height probability distribution\n        mean_height = np.mean(height_distribution.flatten())\n        height_guess = height_distribution - mean_height\n        sq_roughness = np.sqrt(np.mean(height_guess.flatten() ** 2))\n        height_guess = height_guess / sq_roughness\n\n        # sort height dist\n        index_0 = np.argsort(height_guess.flatten())\n        sorted_target_heights = height_guess.flatten()[index_0]\n\n        # find bins for height distribution error\n        bin_width = 3.5 * sorted_target_heights.size ** (-1 / 3)  # Scott bin method *note that the\n        # values are normalised to have unit standard deviation\n        n_bins = int(np.ceil((sorted_target_heights[-1] - sorted_target_heights[0]) / bin_width))\n        bin_edges = np.linspace(sorted_target_heights[0], sorted_target_heights[-1], n_bins + 1)\n        n0, bin_edges = np.histogram(sorted_target_heights, bins=bin_edges, density=True)\n        error = defaultdict(list)\n\n        height_guess = height_guess.reshape(power_spectrum.shape)\n        fft_height_guess = np.fft.fft2(height_guess)\n\n        best = \'psd\'\n\n        while True:\n            # Step 1: fix power spectrum by FFT filter\n            # Zs = np.fft.ifft2(zh*power_spectrum/Ch)\n            phase = np.angle(fft_height_guess)\n            # phase = _conj_sym(phase, neg=True)\n            psd_guess = np.fft.ifft2(power_spectrum * np.exp(1j * phase)).real\n\n            # find error in height distribution\n            n_hist, _ = np.histogram(psd_guess.flatten(), bin_edges, density=True)\n            error[\'H\'].append(np.sum(np.abs(n_hist - n0) * (bin_edges[1:] - bin_edges[:-1])))\n\n            # Step 2: Fix the height distribution rank ordering\n            height_guess = psd_guess.flatten()\n            index = np.argsort(height_guess)\n            height_guess[index] = sorted_target_heights\n            height_guess = height_guess.reshape((m, n))\n            fft_height_guess = np.fft.fft2(height_guess)\n            # find error in the power spectrum\n            fft_hg_abs = np.abs(fft_height_guess)\n            # Ch = np.abs(zh**2)#*grid_spacing**2/(n*m*(2*np.pi)**2)\n            error[\'PS\'].append(np.sqrt(np.mean((1 - fft_hg_abs[power_spectrum > 0] /\n                                                power_spectrum[power_spectrum > 0]) ** 2)))\n            error[\'PS0\'].append(np.sqrt(np.mean(fft_hg_abs[power_spectrum == 0] ** 2)) /\n                                np.mean(power_spectrum[power_spectrum > 0]))\n\n            if len(error[\'H\']) >= max_it:\n                msg = \'Iterations for fractal surface failed to converge in the set number of iterations\'\n                break\n            if len(error[\'H\']) > 2 and abs(error[\'H\'][-1] - error[\'H\'][-2]) / error[\'H\'][-1] < min_speed:\n                msg = (\'Solution for fractal surface convering is converging \'\n                       \'slower than the minimum speed, solution failed to converge\')\n                break\n            if len(error[\'H\']) > 2 and (error[\'H\'][-2] - error[\'H\'][-1]) < 0:\n                msg = \'Solution is diverging, solution failed to converge\'\n                break\n            if error[\'H\'][-1] < accuracy:\n                msg = \'\'\n                best = \'heights\'\n                break\n            if error[\'PS\'][-1] < accuracy and error[\'PS0\'][-1] < accuracy:\n                msg = \'\'\n                best = \'psd\'\n                break  # solution converged\n\n        if msg:\n            if suppress_errors:\n                warnings.warn(msg)\n            else:\n                raise StopIteration(msg)\n\n        exact = self._exact if self._exact != \'best\' else best\n\n        if exact == \'psd\':\n            profile = psd_guess * sq_roughness + mean_height\n        else:\n            profile = height_guess * sq_roughness + mean_height\n\n        if return_new:\n            return Surface(profile=profile, grid_spacing=self.grid_spacing)\n\n        if return_original:\n            return height_guess, psd_guess, error\n\n        self.profile = profile\n\n\nclass RandomFilterSurface(_Surface):\n    r""" Surfaces based on transformations of random sequences by a filter\n\n    Filter coefficients can be found by fourier analysis or solving the least squares problem given by Patir.\n\n    Parameters\n    ----------\n    target_acf: slippy.surface.ACF\n        An ACF object describing the trage autocorrelation function of the surface\n    grid_spacing: float, optional (None)\n        The distance between surface points, must be set before the filter coefficients can be found\n    extent: 2 element sequence of floats, optional (None)\n        The total size of the surface in the same units as the grid spacing\n    shape: 2 element sequence of ints, optional (None)\n        The number of points in each direction on the surface\n\n    Attributes\n    ----------\n    dist : scipy.stats.rv_continuous\n        The statistical distribution which the random sequence is drawn from\n\n    Methods\n    -------\n    linear_transforms: find filter coefficients by Patir\'s method (with extentions)\n    fir_filter: find filter coefficients by Hu and Tonder\'s method\n    set_moments\n    set_quantiles\n    discretise\n\n    See Also\n    --------\n    surface_like\n\n    Notes\n    -----\n    This is a subclass of Surface and inherits all methods. All key words that\n    can be passed to Surface on instantiation can also be passed to this class\n    apart from \'profile\'\n\n    Examples\n    --------\n    In the following example we will generate a randomly rough surface with an exponential ACF and a non gaussian height\n    distribution.\n\n    >>> import slippy.surface as s  # surface generation and manipulation\n    >>> import numpy as np          # numerical functions\n    >>> np.random.seed(0)\n    >>> target_acf = s.ACF(\'exp\', 2, 0.1, 0.2)  # make an example ACF\n    >>> # Finding the filter coefficients\n    >>> lin_trans_surface = s.RandomFilterSurface(target_acf=target_acf, grid_spacing=0.01)\n    >>> lin_trans_surface.linear_transform(filter_shape=(40,20), gtol=1e-5, symmetric=True)\n    >>> # Setting the skew and kurtosis of the output surface\n    >>> lin_trans_surface.set_moments(skew = -0.5, kurtosis=5)\n    >>> # generating and showing a realisation of the surface\n    >>> my_realisation = lin_trans_surface.discretise([512,512], periodic=False, create_new=True)\n    >>> fig, axes = my_realisation.show([\'profile\', \'acf\', \'histogram\'], [\'image\', \'image\'], figsize=(15,5))\n\n    References\n    ----------\n\n    Hu, Y. Z., & Tonder, K. (1992). Simulation of 3-D random rough surface by 2-D digital filter and Fourier analysis.\n    International Journal of Machine Tools, 32(1–2), 83–90.\n    doi.org/10.1016/0890-6955(92)90064-N\n\n    Patir, N. (1978). A numerical procedure for random generation of rough surfaces. Wear, 47(2), 263–277.\n    doi.org/10.1016/0043-1648(78)90157-6\n\n    Watson, M., Lewis, R., & Slatter, T. (2020). Improvements to the linear transform technique for generating randomly\n    rough surfaces with symmetrical autocorrelation functions. Tribology International, 151(April), 106487.\n    doi.org/10.1016/j.triboint.2020.106487\n    """\n\n    surface_type = \'Random\'\n    dist = scipy.stats.norm(loc=0, scale=1)\n    _filter_coefficients: np.ndarray = None\n    target_acf: ACF = None\n    is_discrete: bool = False\n    _moments = None\n    _method_keywords = None\n    target_acf_array = None\n    "An array of acf values used as the target for the fitting procedure"\n\n    def __init__(self,\n                 target_acf: ACF = None,\n                 grid_spacing: typing.Optional[float] = None,\n                 extent: typing.Optional[typing.Sequence] = None,\n                 shape: typing.Optional[typing.Sequence] = None):\n\n        super().__init__(grid_spacing=grid_spacing, extent=extent, shape=shape)\n\n        if target_acf is not None:\n            self.target_acf = target_acf\n\n    def __repr__(self):\n        string = \'RandomFilterSurface(\'\n        if self.target_acf is not None:\n            string += f\'target_acf={repr(self.target_acf)}, \'\n            string += f\'grid_spacing={self.grid_spacing}, \'\n        if self._moments is not None:\n            string += f\'moments = {self._moments}, \'\n        if self.shape is not None:\n            string += f\'shape = {self.shape}, \'\n        string = string[:-2]\n        return string + \')\'\n\n    def linear_transform(self, filter_shape: typing.Sequence = (14, 14), symmetric: bool = True, max_it: int = None,\n                         gtol: float = 1e-5, method=\'BFGS\', **minimize_kwargs):\n        r"""\n        Generates a linear transform matrix\n\n        Solves the non linear optimisation problem to generate a\n        moving average filter that when convolved with a set of normally\n        distributed random numbers will generate a surface profile with the\n        specified ACF\n\n        Parameters\n        ----------\n\n        filter_shape: Sequence, optional (14, 14)\n            The dimensions of the filter coefficient matrix to be generated the default is (35, 35), must be exactly 2\n            elements both elements must be ints\n        symmetric: bool, optional (True)\n            If true a symmetric filter will be fitted to the target ACF, this typically produces more realistic surfaces\n            for the same filter shape but takes longer to fit the filter\n        max_it: int, optional (100)\n            The maximum number of iterations used\n        gtol: float, optional (1e-11)\n            The accuracy of the iterated solution\n        method: str, optional (\'BFGS\')\n            Type of solver. In most situations this should be one of the following:\n            - Nelder-Mead\n            - Powell\n            - CG\n            - BFGS\n            - Newton-CG\n            However other options exist, see the notes for more details\n        minimize_kwargs\n            Extra key word arguments which are passed to scipy.optimise.minimize function, valid arguments will depend\n            on the choice of method\n\n        Returns\n        -------\n\n        None\n            Sets the filter_coefficients property of the instance\n\n\n        See Also\n        --------\n\n        RandomFilterSurface.set_moments\n        RandomFilterSurface.FIRfilter\n\n        Notes\n        -----\n\n        This problem has a unique solution for each grid spacing. This should\n        be set before running this method, else it is assumed to be 1.\n\n        For more information on each of the methods available the documentation of scipy.optimize.minimize should be\n        consulted. Practically, for this problem only unconstrained, unbound solvers are appropriate, these are:\n\n        - Nelder-Mead\n        - Powell\n        - CG\n        - BFGS\n        - Newton-CG\n        - dogleg\n        - trust-ncg\n        - trust-krylov\n        - trust-exact\n\n        However, the dogleg, trust-ncg, trust-krylov, trust-exact additionally require the user to specify the hessian\n        matrix for the problem which is currently unsupported.\n\n        References\n        ----------\n\n        ..[1] N. Patir, "A numerical procedure for random generation of\n        rough surfaces (1978)"\n        Wear, 47(2), 263–277.\n        \'<https://doi.org/10.1016/0043-1648(78)90157-6>\'_\n\n        Examples\n        --------\n\n        In the following example we will generate a randomly rough surface with an exponential ACF and a non gaussian\n        height distribution.\n\n        >>> import slippy.surface as s  # surface generation and manipulation\n        >>> import numpy as np          # numerical functions\n        >>> np.random.seed(0)\n        >>> target_acf = s.ACF(\'exp\', 2, 0.1, 0.2)  # make an example ACF\n        >>> # Finding the filter coefficients\n        >>> lin_trans_surface = s.RandomFilterSurface(target_acf=target_acf, grid_spacing=0.01)\n        >>> lin_trans_surface.linear_transform(filter_shape=(40,20), gtol=1e-5, symmetric=True)\n        >>> # Setting the skew and kurtosis of the output surface\n        >>> lin_trans_surface.set_moments(skew = -0.5, kurtosis=5)\n        >>> # generating and showing a realisation of the surface\n        >>> my_realisation = lin_trans_surface.discretise([512,512], periodic=False, create_new=True)\n        >>> fig, axes = my_realisation.show([\'profile\', \'acf\', \'histogram\'], [\'image\', \'image\'], figsize=(15,5))\n        """\n        self._method_keywords = {**locals()}\n        del (self._method_keywords[\'self\'])\n\n        self.surface_type = \'linear_transform\'\n\n        if self.target_acf is None:\n            raise ValueError("No target ACF given, a target ACF must be given before the filter coefficients can be "\n                             "found")\n\n        # n by m ACF\n        n = filter_shape[0]\n        m = filter_shape[1]\n\n        if max_it is None:\n            max_it = n * m * 100\n\n        if self.grid_spacing is None:\n            msg = ("Grid spacing is not set assuming grid grid_spacing is 1, the solution is unique for each grid "\n                   "spacing")\n            warnings.warn(msg)\n            self.grid_spacing = 1\n\n        # generate the acf array form the ACF object\n        el = self.grid_spacing * np.arange(n)\n        k = self.grid_spacing * np.arange(m)\n        acf_array = self.target_acf(k, el)\n        self.target_acf_array = acf_array\n        # initial guess (n by m guess of filter coefficients)\n        x0 = _initial_guess(acf_array)\n\n        if symmetric:\n            result = minimize(_min_fun_symmetric, x0/2, args=(acf_array,), method=method,\n                              jac=_get_grad_min_fun_symmetric, tol=gtol,\n                              **minimize_kwargs)\n        else:\n            result = minimize(_min_fun, x0, args=(acf_array,), method=method, jac=_get_grad_min_fun, tol=gtol,\n                              **minimize_kwargs)\n\n        if not result.success:\n            warnings.warn(result.message)\n\n        alpha = np.reshape(result.x, filter_shape)\n\n        if symmetric:\n            filter_coefficients_half = alpha\n            n1, m1 = filter_coefficients_half.shape\n            filter_coefficients = np.zeros((n1 * 2 - 1, m1))\n            filter_coefficients[:n1, :m1] = np.flip(filter_coefficients_half, 0)\n            filter_coefficients[n1 - 1:, :m1] = filter_coefficients_half\n            alpha = filter_coefficients\n\n        # un comment the next two lines for the root finding method\n        # from scipy.optimise import fsolve\n        # alpha, *optional_out = fsolve(_root_func, x0, args=(acf_array,),\n        #                              xtol=gtol, maxfev=max_it, full_output=True)\n\n        self._filter_coefficients = alpha\n\n    def set_moments(self, skew=0, kurtosis=0):\n        r"""\n        Sets the skew and kurtosis of the output surface\n\n        If a filter coefficients matrix is present, this method changes the dist\n        property of this instance to a distribution that produces a series of\n        johnson or normally distributed random numbers that will have the\n        set skew and kurtosis when convolved with the filter coefficients matrix.\n\n        Parameters\n        ----------\n\n        skew, kurtosis : float\n            The desired moments of the surface profile\n\n        Returns\n        -------\n        None\n            Sets the dist parameter of the instance\n\n        See Also\n        --------\n        RandomFilterSurface.linear_transform\n\n        Notes\n        -----\n\n        The skew of the input sequence:\n        :math:`Sk_\\eta`\n        can be related to the skew of the final surface:\n        :math:`Sk_z`\n        by the following:\n\n        :math:`Sk_z=Sk_\\eta \\frac{\\sum_{i=0}^{q} \\alpha_{i}^{3}}{(\\sum_{i=0}^{q}\\alpha_i^2)^\\frac{3}{2}}`\n\n        The kurtosis of the input sequence can be related to the final surface\n        by [1]:\n\n        :math:`K_z= \\frac{K_\\eta \\sum_{i=0}^q \\alpha_i^2 + 6 \\sum_{i=0}^{q-1}\\sum_{j=i+1}^q\\alpha_i^2 \\alpha_j^2}{(\\sum_{i=0}^q \\alpha_i^2)^2}`\n\n        References\n        ----------\n\n        [1] Manesh, K. K., Ramamoorthy, B., & Singaperumal, M. (2010). Numerical generation of anisotropic 3D\n        non-Gaussian engineering surfaces with specified 3D surface roughness parameters. Wear, 268(11–12),\n        1371–1379. https://doi.org/10.1016/j.wear.2010.02.005\n\n        Examples\n        --------\n        In the following example we will generate a randomly rough surface with an exponential ACF and a non gaussian\n        height distribution.\n\n        >>> import slippy.surface as s  # surface generation and manipulation\n        >>> import numpy as np          # numerical functions\n        >>> np.random.seed(0)\n        >>> target_acf = s.ACF(\'exp\', 2, 0.1, 0.2)  # make an example ACF\n        >>> # Finding the filter coefficients\n        >>> lin_trans_surface = s.RandomFilterSurface(target_acf=target_acf, grid_spacing=0.01)\n        >>> lin_trans_surface.linear_transform(filter_shape=(40,20), gtol=1e-5, symmetric=True)\n        >>> # Setting the skew and kurtosis of the output surface\n        >>> lin_trans_surface.set_moments(skew = -0.5, kurtosis=5)\n        >>> # generating and showing a realisation of the surface\n        >>> my_realisation = lin_trans_surface.discretise([512,512], periodic=False, create_new=True)\n        >>> fig, axes = my_realisation.show([\'profile\', \'acf\', \'histogram\'], [\'image\', \'image\'], figsize=(15,5))\n        """  # noqa\n        self._moments = (skew, kurtosis)\n\n        if self._filter_coefficients is None:\n            msg = ("Filter coefficients matrix not found, this must be found by"\n                   " the linear_transforms or FIR_filter methods before this "\n                   "method can be used")\n            raise AttributeError(msg)\n\n        alpha = self._filter_coefficients\n\n        alpha = alpha.flatten()\n        alpha2 = alpha ** 2  # alpha squared\n        sal2 = np.sum(alpha2)  # sum alpha squared\n\n        seq_skew = skew * (sal2 ** (3 / 2)) / np.sum(alpha2 * alpha)\n\n        # making the mixed term\n        quad_term = 0.0\n        q = len(alpha)\n        for i in range(0, q - 1):\n            for j in range(i, q):\n                quad_term += alpha2[i] * alpha2[j]\n\n        seq_kurt = (kurtosis * sal2 ** 2 - 6 * quad_term) / np.sum(alpha2**2) + 3\n\n        self.dist = _fit_johnson_by_moments(0, 1, seq_skew, seq_kurt, True)\n\n    def set_quantiles(self, quantiles: typing.Sequence):\n        """ Fit a johnson distribution to give a resulting surface with the supplied quantiles\n\n        Parameters\n        ----------\n        quantiles: Sequence\n            Quantile values, quantiles relate to normal quantiles of -1.5, -0.5, 0.5, 1.5\n            roughly: 0.067, 0.309, 0.691, 0.933\n\n        Notes\n        -----\n        The quantiles supplied should relate to the quantiles in the final surface not the distribution that will be\n        filtered.\n\n        See Also\n        --------\n        set_moments\n\n        """\n        dist = _fit_johnson_by_quantiles(quantiles)\n\n        moments = np.array(dist.stats(\'sk\'))\n\n        self.set_moments(moments[0], moments[1])\n\n        return\n\n    def fir_filter(self, target_acf: ACF = None, filter_span: typing.Sequence = None):\n        """\n        Create a 2D FIR filter to produce a surface with the given ACF\n\n        Parameters\n        ----------\n\n        target_acf: ACF\n            The target ACF of the final surface.\n        filter_span: Sequence, optional (None)\n            The span of the filter which will be found, larger filters give better long range representation of the ACF\n            but take longer to find and longer to apply\n\n\n        See Also\n        --------\n\n        slippy.surface.ACF\n        RandomFilterSurface.linear_transform\n        RandomFilterSurface.discretise\n\n        Notes\n        -----\n\n        1 For this function to work the grid_spacing of the final surface\n            must be set.\n        2 After running this method surface realisations can be generated by the\n            discretise method\n        3 Uses the method defined here:\n            Hu, Y. Z., & Tonder, K. (1992). Simulation of 3-D random rough\n            surface by 2-D digital filter and Fourier analysis.\n            International Journal of Machine Tools and …, 32(1–2), 83–90.\n            https://doi.org/10.1016/0890-6955(92)90064-N\n\n        Examples\n        --------\n\n        #TODO\n        """\n        if target_acf is None:\n            target_acf = self.target_acf\n\n        if target_acf is None:\n            raise ValueError(\'No ACF set\')\n\n        self._method_keywords = {**locals()}\n        del (self._method_keywords[\'target_acf\'])\n        del (self._method_keywords[\'self\'])\n\n        self.surface_type = \'fir_filter\'\n\n        # initialise sizes\n        if self.grid_spacing is None:\n            warnings.warn("Grid grid_spacing is not set assuming grid"\n                          " grid_spacing is 1")\n            self.grid_spacing = 1\n\n        if filter_span is None:\n            if self.shape is None:\n                raise ValueError(\'Either the shape and grid_spacing of the surface or the filter span and the \'\n                                 \'grid_spacing must be set before the filter coefficients can be found by this method\')\n            filter_span = self.shape\n\n        # generate ACF object if input is not ACF object\n        if type(target_acf) is ACF:\n            self.target_acf = target_acf\n        if self.target_acf is None:\n            raise ValueError("Target ACF must be set before the filter coefficients can be found")\n\n        # Generate array of ACF\n        el = self.grid_spacing * np.arange(filter_span[0])\n        k = self.grid_spacing * np.arange(filter_span[1])\n        acf_array = self.target_acf(k, el)\n\n        # Find FIR filter coefficients\n        self._filter_coefficients = np.sqrt(np.fft.fft2(acf_array))\n\n    def discretise(self, output_shape: typing.Sequence = None, periodic: bool = False,\n                   create_new: bool = False):\n        """\n        Create a random surface realisation based on preset parameters\n\n        Parameters\n        ----------\n\n        output_shape : 2 element list of ints\n            The size of the output in points, the grid_spacing of these points\n            is set when the filter coefficients matrix is generated, see\n            linear_transform for more information\n        periodic : bool, (False)\n            If true the resulting surface will be periodic in geometry, for\n            this to work the filter coefficients matrix must have odd order in\n            both directions\n        create_new : bool, optional (False)\n            If set to true the method will return a new surface object with the\n            generated profile and the correct sizes/ grid_spacing otherwise the\n            parent surface will given the generated profile\n\n        Returns\n        -------\n\n        A new surface object if the create_new parameter is set to true else\n        nothing, but sets profile property of surface\n\n        See Also\n        --------\n\n        RandomFilterSurface.linear_transform\n        RandomFilterSurface.fir_filter\n\n        Notes\n        -----\n\n        Uses the method outlined in the below with fft based convolution:\n        Liao, D., Shao, W., Tang, J., & Li, J. (2018). An improved rough\n        surface modeling method based on linear transformation technique.\n        Tribology International, 119(August 2017), 786–794.\n        https://doi.org/10.1016/j.triboint.2017.12.008\n\n        """\n\n        if self._filter_coefficients is None:\n            raise AttributeError(\'The filter coefficients matrix must be found by either the linear_transform or \'\n                                 \'fir_filter method before surface realisations can be generated\')\n\n        filter_coefficients = self._filter_coefficients\n\n        n, m = filter_coefficients.shape\n\n        if output_shape is None:\n            output_shape = self.shape\n\n        if output_shape is None:\n            raise ValueError("Output shape is not set")\n\n        output_n, output_m = output_shape\n\n        if periodic:\n            eta = np.pad(self.dist.rvs(size=[output_n, output_m]), ((0, n-1), (0, m-1)), \'wrap\')\n        else:\n            eta = self.dist.rvs(size=[output_n + n - 1, output_m + m - 1])\n\n        profile = fftconvolve(eta, filter_coefficients, \'valid\')\n\n        if create_new:\n            return Surface(grid_spacing=self.grid_spacing, profile=profile)\n        else:\n            self.profile = profile\n            self.is_discrete = True\n        return\n\n\ndef _initial_guess(target_acf):\n    """Find the initial guess for the filter coefficient matrix in the linear transforms method\n\n    Parameters\n    ----------\n    target_acf: np.ndarray\n\n    Returns\n    -------\n    np.ndarray, initial guess of filter coefficients\n    """\n    n, m = target_acf.shape\n    c = np.zeros_like(target_acf)\n    for i in range(n):\n        for j in range(m):\n            c[i, j] = target_acf[i, j] / ((n - i) * (m - j))\n    s_sq = target_acf[0, 0] / np.sum((c ** 2).flatten())\n    return (c * s_sq ** 0.5).flatten()\n\n\ndef _root_func(alpha: np.ndarray, target_acf: np.ndarray):\n    """Optimisation function for linear transforms method if using with a vector root finding algorithm\n\n    Parameters\n    ----------\n    alpha: np.ndarray\n        The current filter coefficient matrix\n    target_acf: np.ndarray\n        The target acf array (same shape as alpha)\n\n    Returns\n    -------\n    np.ndarray of residuals\n    """\n    alpha = alpha.reshape(target_acf.shape)\n    acf_estimate = _get_acf_estimate_fft(alpha)\n    return (acf_estimate - target_acf).flatten()\n\n\ndef _min_fun(alpha: np.ndarray, target_acf: np.ndarray):\n    """Optimisation function for linear transforms method if using with a minimisation function\n\n    Parameters\n    ----------\n    alpha: np.ndarray\n        The current filter coefficient matrix\n    target_acf: np.ndarray\n        The target acf array (same shape as alpha)\n\n    Returns\n    -------\n    np.ndarray of residuals\n    """\n    alpha = alpha.reshape(target_acf.shape)\n    acf_estimate = _get_acf_estimate_fft(alpha)\n    return np.sum(((target_acf - acf_estimate).flatten()) ** 2)\n\n\ndef _min_fun_symmetric(alpha: np.ndarray, target_acf: np.ndarray):\n    """Optimisation function for linear transforms method if using with a minimisation function\n\n    Parameters\n    ----------\n    alpha: np.ndarray\n        The current filter coefficient matrix\n    target_acf: np.ndarray\n        The target acf array (same shape as alpha)\n\n    Returns\n    -------\n    np.ndarray of residuals\n    """\n    alpha = alpha.reshape(target_acf.shape)\n    n1, m1 = alpha.shape\n    alpha_2 = np.zeros((n1 * 2 - 1, m1))\n    alpha_2[:n1, :m1] = np.flip(alpha, 0)\n    alpha_2[n1 - 1:, :m1] = alpha\n    acf_estimate = _get_acf_estimate_fft(alpha_2)\n    return np.sum(((target_acf - acf_estimate[:n1, :m1]).flatten()) ** 2)\n\n\n@njit\ndef _get_acf_estimate(alpha):\n    n, m = alpha.shape\n    acf_estimate = np.zeros_like(alpha)\n    for p in range(n):\n        for q in range(m):\n            a_est = 0.0\n            for k in range(n - p):\n                for el in range(m - q):\n                    a_est += alpha[k, el] * alpha[k + p, el + q]\n            acf_estimate[p, q] = a_est\n    return acf_estimate\n\n\ndef _get_acf_estimate_fft(alpha):\n    """Gives the same results as the manual convolution method above but much faster for large filters"""\n    n, m = alpha.shape\n    alpha_pad = np.pad(np.flip(alpha, (0, 1)), ((0, n - 1), (0, m - 1)), mode=\'constant\')\n    return fftconvolve(alpha, alpha_pad, \'same\')\n\n\ndef _get_grad_min_fun(alpha, target_acf):\n    alpha = alpha.reshape(target_acf.shape)\n    acf_estimate = _get_acf_estimate_fft(alpha)\n    return _grad_min_fun(alpha, target_acf, acf_estimate).flatten()\n\n\ndef _get_grad_min_fun_symmetric(alpha, target_acf):\n    alpha = alpha.reshape(target_acf.shape)\n    n1, m1 = alpha.shape\n    alpha_2 = np.zeros((n1 * 2 - 1, m1))\n    alpha_2[:n1, :] = np.flip(alpha, 0)\n    alpha_2[n1 - 1:, :m1] = alpha\n    acf_estimate = _get_acf_estimate_fft(alpha_2)[:n1, :m1]\n    grads_2 = _grad_min_fun(alpha_2, target_acf, acf_estimate)\n    grads = grads_2[n1 - 1:, :m1]\n    grads[1:, :] += np.flip(grads_2[:n1 - 1, :], 0)\n    return grads.flatten()\n\n\n@njit\ndef _grad_min_fun(alpha: np.ndarray, target_acf: np.ndarray, acf_estimate):\n    """Gradient of the above optimisation function for minimisation methods\n\n    Parameters\n    ----------\n    alpha: np.ndarray\n        The filter coefficients\n    target_acf: np.ndarray\n        The the target acf\n\n    Returns\n    -------\n    np.ndarray\n        The gradient of the objective value wrt each of the filter coefficients\n    """\n    n, m = alpha.shape\n    grads = np.zeros_like(alpha)\n    n1, m1 = target_acf.shape\n    difference = target_acf - acf_estimate\n    for i in range(1, n + 1):\n        for j in range(1, m + 1):\n            grad = 0.0\n            for p in range(min(n - i + 1, n1)):\n                for q in range(m - j + 1):\n                    grad += (difference[p, q]) * (-alpha[i + p - 1, j + q - 1])\n            for p in range(min(i, n1)):\n                for q in range(j):\n                    grad += (difference[p, q]) * (-alpha[i - p - 1, j - q - 1])\n            grads[i - 1, j - 1] = 2.0 * grad\n\n    return grads\n', 'is_package': False},
    'slippy.surface.Surface_class': {'source': 'import abc\nimport copy\nimport csv\nimport os\nimport typing\nimport warnings\nfrom numbers import Number\nfrom collections import defaultdict\nfrom collections.abc import Sequence\n\nimport numpy as np\nimport scipy.interpolate\nimport scipy.signal\n\nfrom slippy.core import _MaterialABC, _SurfaceABC\nfrom .ACF_class import ACF\nfrom .roughness_funcs import get_height_of_mat_vr, low_pass_filter\nfrom .roughness_funcs import get_mat_vr, get_summit_curvatures\nfrom .roughness_funcs import roughness, subtract_polynomial, find_summits\n\n__all__ = [\'Surface\', \'assurface\', \'read_surface\', \'_Surface\', \'_AnalyticalSurface\', \'RollingSurface\']\n\n\ndef assurface(profile, grid_spacing=None):\n    """ make a surface from a profile\n\n    Parameters\n    ----------\n    profile : array-like\n        The surface profile\n    grid_spacing : float optional (None)\n        The spacing between grid points on the surface\n\n    Returns\n    -------\n    surface : Surface object\n        A surface object with the specified profile and grid size\n\n    See Also\n    --------\n    Surface\n    read_surface\n\n    Notes\n    -----\n\n\n    Examples\n    --------\n\n    >>> profile=np.random.normal(size=[10,10])\n    >>> my_surface=assurface(profile, 0.1)\n    >>> my_surface.extent\n    [1,1]\n\n    """\n    return Surface(profile=profile, grid_spacing=grid_spacing)\n\n\ndef read_surface(file_name, **kwargs):\n    """ Read a surface from a file\n\n    Parameters\n    ----------\n    file_name : str\n        The full path to the data file\n\n    Other Parameters\n    ----------------\n\n    delim : str optional (\',\')\n        The delimiter used in the data file, only needed for csv or txt files\n    p_name : str optional (\'profile\')\n        The name of the variable containing the profile data, needed if a .mat\n        file is given\n    gs_name : str optional (\'grid_spacing\')\n        The name of the variable containing the grid_spacing, needed if a .mat\n        file is given\n\n    Returns\n    -------\n    A surface object generated from the file\n\n    See Also\n    --------\n    Surface\n    alicona_read\n    scipy.io.loadmat\n\n    Notes\n    -----\n    This function directly invokes the surface class, any other keywords that\n    can be passed to that class can be passed to this function\n\n    Examples\n    --------\n\n    >>> # Read a csv file with tab delimiters\n    >>> my_surface=read_surface(\'data.csv\', delim=\'\\t\')\n\n    >>> # Read a .al3d file\n    >>> my_surface=read_surface(\'data.al3d\')\n\n    >>> # Read a .mat file with variables called prof and gs\n    >>> my_surface=read_surface(\'data.mat\', p_name=\'prof\', gs_name=\'gs\')\n\n    """\n    return Surface(file_name=file_name, **kwargs)\n\n\nclass _Surface(_SurfaceABC):\n    """\n    An abstract base class for surface types, this class should be extended to given new types of surface. To create an\n    analytical surface please subclass _AnalyticalSurface\n    """\n\n    # The surface class for discrete surfaces (typically experimental)\n    is_discrete: bool = False\n    """ A bool flag, True if there is a profile present """\n    acf: typing.Optional[ACF] = None\n    """ The auto correlation function of the surface profile """\n    psd: typing.Optional[np.ndarray] = None\n    """ The power spectral density of the surface """\n    fft: typing.Optional[np.ndarray] = None\n    """ The fast fourier transform of the surface """\n    surface_type: str = "Generic"\n    """ A description of the surface type """\n    dimensions: typing.Optional[int] = 2\n    """ The number of spatial dimensions that """\n    is_analytic: bool = False\n\n    _material: typing.Optional[_MaterialABC] = None\n    unworn_profile: typing.Optional[np.ndarray] = None\n    _profile: typing.Optional[np.ndarray] = None\n    _grid_spacing: typing.Optional[float] = None\n    _shape: typing.Optional[tuple] = None\n    _extent: typing.Optional[tuple] = None\n    _inter_func = None\n    _allowed_keys = {}\n    _mask: typing.Optional[np.ndarray] = None\n    _size: typing.Optional[int] = None\n    _subclass_registry = []\n    _original_extent = None\n    wear_volumes: typing.Optional[defaultdict] = None\n\n    def __init__(self, grid_spacing: typing.Optional[float] = None, extent: typing.Optional[tuple] = None,\n                 shape: typing.Optional[tuple] = None, is_discrete: bool = False):\n        if grid_spacing is not None and extent is not None and shape is not None:\n            raise ValueError("Up to two of grid_spacing, extent and size should be set, all three were set")\n\n        self.is_discrete = is_discrete\n\n        if grid_spacing is not None:\n            self.grid_spacing = grid_spacing\n        if extent is not None:\n            self.extent = extent\n        if shape is not None:\n            self.shape = shape\n\n    @classmethod\n    def __init_subclass__(cls, is_abstract=False, **kwargs):\n        super().__init_subclass__(**kwargs)\n        if not is_abstract:\n            _Surface._subclass_registry.append(cls)\n\n    @property\n    def size(self):\n        """The total number of points in the surface"""\n        return self._size\n\n    @property\n    def mask(self):\n        """A mask used to exclude some values from analysis, a single float or an array of bool the same size as profile\n        Either a boolean array of size self.size or a float of the value to be excluded\n        """\n        return self._mask\n\n    @mask.setter\n    def mask(self, value: typing.Union[float, np.ndarray]):\n\n        if type(value) is float:\n            if np.isnan(value):\n                mask = np.isnan(self.profile)\n            else:\n                mask = self.profile == value\n        elif isinstance(value, np.ndarray):\n            mask = np.asarray(value, dtype=bool)\n            if not mask.shape == self.shape:\n                msg = ("profile and mask shapes do not match: profile is"\n                       "{profile.shape}, mask is {mask.shape}".format(**locals()))\n                raise TypeError(msg)\n        elif isinstance(value, str):\n            raise TypeError(\'Mask cannot be a string\')\n        elif isinstance(value, Sequence):\n            mask = np.zeros_like(self.profile, dtype=bool)\n            for item in value:\n                self.mask = item\n                mask = np.logical_and(self._mask, mask)\n        else:\n            raise TypeError("Mask type is not recognised")\n        self._mask = mask\n\n    @mask.deleter\n    def mask(self):\n        self._mask = None\n\n    @property\n    def extent(self):\n        """ The overall dimensions of the surface in the same units as grid spacing\n        """\n        return self._extent\n\n    @extent.setter\n    def extent(self, value: typing.Sequence[float]):\n        if not isinstance(value, Sequence):\n            msg = "Extent must be a Sequence, got {}".format(type(value))\n            raise TypeError(msg)\n        if len(value) > 2:\n            raise ValueError("Too many elements in extent, must be a maximum of two dimensions")\n\n        if self.profile is not None:\n            p_aspect = (self.shape[0]) / (self.shape[1])\n            e_aspect = value[0] / value[1]\n            if abs(e_aspect - p_aspect) > 0.0001:\n                msg = "Extent aspect ratio doesn\'t match profile aspect ratio"\n                raise ValueError(msg)\n            else:\n                self._extent = tuple(value)\n                self._grid_spacing = value[0] / (self.shape[0])\n        else:\n            self._extent = tuple(value)\n            self.dimensions = len(value)\n            if self.grid_spacing is not None:\n                self._shape = tuple([int(v / self.grid_spacing) for v in value])\n                self._size = np.product(self._shape)\n            if self._shape is not None:\n                self._grid_spacing = self._extent[0] / self._shape[0]\n                self._extent = tuple([sz * self._grid_spacing for sz in self._shape])\n        return\n\n    @extent.deleter\n    def extent(self):\n        self._extent = None\n        self._grid_spacing = None\n        if self.profile is None:\n            self._shape = None\n            self._size = None\n\n    @property\n    def shape(self):\n        """The shape of the surface profile array, the number of points in each direction\n        """\n        return self._shape\n\n    @shape.setter\n    def shape(self, value: typing.Sequence[int]):\n        if not isinstance(value, Sequence):\n            raise ValueError(f"Shape should be a Sequence type, got: {type(value)}")\n\n        if self._profile is not None:\n            raise ValueError("Cannot set shape when profile is present")\n\n        self._shape = tuple([int(x) for x in value])\n        self._size = np.product(self._shape)\n        if self.grid_spacing is not None:\n            self._extent = tuple([v * self.grid_spacing for v in value])\n        elif self.extent is not None:\n            self._grid_spacing = self._extent[0] / self._shape[0]\n            self._extent = tuple([sz * self.grid_spacing for sz in self.shape])\n\n    @shape.deleter\n    def shape(self):\n        if self.profile is None:\n            self._shape = None\n            self._size = None\n            self._extent = None\n            self._grid_spacing = None\n        else:\n            msg = "Cannot delete shape with a surface profile set"\n            raise ValueError(msg)\n\n    @property\n    def profile(self):\n        """The height data for the surface profile\n        """\n        return self._profile\n\n    @profile.setter\n    def profile(self, value: np.ndarray):\n        """Sets the profile property\n        """\n        if value is None:\n            return\n\n        try:\n            self.unworn_profile = np.asarray(value, dtype=float).copy()\n            # this has to be before _profile is set (rewritten for rolling surface)\n            self.wear_volumes = defaultdict(lambda: np.zeros_like(self.unworn_profile))\n            self._profile = np.asarray(value, dtype=float).copy()\n        except ValueError:\n            msg = "Could not convert profile to array of floats, profile contains invalid values"\n            raise ValueError(msg)\n\n        self._shape = self._profile.shape\n        self._size = self._profile.size\n        self.dimensions = len(self._profile.shape)\n\n        if self.grid_spacing is not None:\n            self._extent = tuple([self.grid_spacing * p for p in self.shape])\n        elif self.extent is not None:\n            if self.dimensions == 1:\n                self._grid_spacing = (self.extent[0] / self.shape[0])\n            if self.dimensions == 2:\n                e_aspect = self.extent[0] / self.extent[1]\n                p_aspect = self.shape[0] / self.shape[1]\n\n                if abs(e_aspect - p_aspect) < 0.0001:\n                    self._grid_spacing = (self.extent[0] / self.shape[0])\n                else:\n                    warnings.warn("Global size does not match profile size,"\n                                  " global size has been deleted")\n                    self._extent = None\n\n    @profile.deleter\n    def profile(self):\n        self.unworn_profile = None\n        self._profile = None\n        del self.shape\n        del self.extent\n        del self.mask\n        self.wear_volumes = None\n        self.is_discrete = False\n\n    @property\n    def grid_spacing(self):\n        """The distance between grid points in the x and y directions\n        """\n        return self._grid_spacing\n\n    @grid_spacing.setter\n    def grid_spacing(self, grid_spacing: float):\n        if grid_spacing is None:\n            return\n\n        if not isinstance(grid_spacing, float):\n            try:\n                # noinspection PyTypeChecker\n                grid_spacing = float(grid_spacing)\n            except ValueError:\n                msg = ("Invalid type, grid spacing of type {} could not be "\n                       "converted into float".format(type(grid_spacing)))\n                raise ValueError(msg)\n\n        if np.isinf(grid_spacing):\n            msg = "Grid spacing must be finite"\n            raise ValueError(msg)\n\n        self._grid_spacing = grid_spacing\n\n        if self.profile is None:\n            if self.extent is not None:\n                self._shape = tuple([int(sz / grid_spacing) for sz in self.extent])\n                self._size = np.product(self._shape)\n                self._extent = tuple([sz * grid_spacing for sz in self._shape])\n            elif self.shape is not None:\n                self._extent = tuple([grid_spacing * pt for pt in self.shape])\n        else:\n            self._extent = tuple([s * grid_spacing for s in self.shape])\n\n    @grid_spacing.deleter\n    def grid_spacing(self):\n        self._extent = None\n        self._grid_spacing = None\n        if self.profile is None:\n            del self.shape\n\n    @property\n    def material(self):\n        """ A material object describing the properties of the surface """\n        return self._material\n\n    @material.setter\n    def material(self, value):\n        if isinstance(value, _MaterialABC):\n            self._material = value\n        else:\n            raise ValueError("Unable to set material, expected material object"\n                             " received %s" % str(type(value)))\n\n    @material.deleter\n    def material(self):\n        self._material = None\n\n    def wear(self, name: str, x_pts: np.ndarray, y_pts: np.ndarray, depth: np.ndarray):\n        """\n        Add wear / geometry changes to the surface profile\n\n        Parameters\n        ----------\n        name: str\n            Name of the source of wear\n        x_pts: np.ndarray\n            The x locations of the worn points in length units\n        y_pts: np.ndarray\n            The y locations of the worn points in length units\n        depth: np.ndarray\n            The depth to wear each point, negative values will add height\n\n        """\n        if not x_pts.size == y_pts.size == depth.size:\n            raise ValueError(f"X, Y locations and wear depths are not the same size for wear \'{name}\':\\n"\n                             f"x:{x_pts.size}\\n"\n                             f"y:{y_pts.size}\\n"\n                             f"depth:{depth.size}")\n\n        if np.any(np.isnan(depth)):\n            raise ValueError(f"Some wear depth values are nan for wear {name}")\n\n        # equivalent to rounding and applying wear to nearest node\n        x_ind = np.array(x_pts / self.grid_spacing + self.grid_spacing/2, dtype=np.uint16)\n        y_ind = np.array(y_pts / self.grid_spacing + self.grid_spacing/2, dtype=np.uint16)\n\n        self.wear_volumes[name][y_ind, x_ind] += depth\n        self._profile[y_ind, x_ind] -= depth\n        self._inter_func = None  # force remaking the interpolator if the surface has been worn\n\n    def get_fft(self, profile_in=None):\n        """ Find the fourier transform of the surface\n\n        Finds the fft of the surface and stores it in your_instance.fft\n\n        Parameters\n        ----------\n        profile_in : array-like optional (None)\n            If set the fft of profile_in will be found and returned otherwise\n            instances profile attribute is used\n\n        Returns\n        -------\n        transform : array\n            The fft of the instance\'s profile or the profile_in if one is\n            supplied\n\n        See Also\n        --------\n        get_psd\n        get_acf\n        show\n\n        Notes\n        -----\n        Uses numpy fft.fft or fft.fft2 depending on the shape of the profile\n\n\n        Examples\n        --------\n        >>># Set the fft property of the surface\n        >>> import slippy.surface as s\n        >>> my_surface  = s.assurface([[1,2],[3,4]], grid_spacing=1)\n        >>>my_surface.get_fft()\n\n        >>># Return the fft of a provided profile\n        >>>fft_of_profile_2=my_surface.get_fft(np.array([[1,2],[3,4]]))\n\n        """\n        if profile_in is None:\n            profile = self.profile\n        else:\n            profile = profile_in\n        try:\n            if len(profile.shape) == 1:\n                transform = np.fft.fft(profile)\n                if type(profile_in) is bool:\n                    self.fft = transform\n            else:\n                transform = np.fft.fft2(profile)\n                if type(profile_in) is bool:\n                    self.fft = transform\n        except AttributeError:\n            raise AttributeError(\'Surface must have a defined profile for fft\'\n                                 \' to be used\')\n        if profile_in is None:\n            self.fft = transform\n        else:\n            return transform\n\n    def get_acf(self, profile_in=None):\n        """ Find the auto correlation function of the surface\n\n        Finds the ACF of the surface and stores it in your_instance.acf\n\n        Parameters\n        ----------\n        profile_in : array-like optional (None)\n\n        Returns\n        -------\n        output : ACF object\n            An acf object with the acf data stored, the values can be extracted\n            by numpy.array(output)\n\n        See Also\n        --------\n        get_psd\n        get_fft\n        show\n        slippy.surface.ACF\n\n        Notes\n        -----\n        ACF data is kept in ACF objects, these can then be interpolated or\n        evaluated at specific points with a call:\n\n\n        Examples\n        --------\n        >>> import slippy.surface as s\n        >>> my_surface  = s.assurface([[1,2],[3,4]], grid_spacing=1)\n        >>> # Sets the acf property of the surface with an ACF object\n        >>> my_surface.get_acf()\n        >>> # The acf values are then given by the following\n        >>> np.array(my_surface.acf)\n        >>> # The acf can be shown using the show function:\n        >>> my_surface.show(\'acf\', \'image\')\n\n        >>> # Finding the ACF of a provided profile:\n        >>> ACF_object_for_profile_2=my_surface.get_acf(np.array([[4, 3], [2, 1]]))\n        >>> # equivalent to ACF(profile_2)\n\n        """\n\n        if profile_in is None:\n            # noinspection PyTypeChecker\n            self.acf = ACF(self)\n        else:\n            profile = np.asarray(profile_in)\n            # noinspection PyTypeChecker\n            output = np.array(ACF(profile))\n            return output\n\n    def get_psd(self):\n        """ Find the power spectral density of the surface\n\n        Finds the PSD of the surface and stores it in your_instance.psd\n\n        Parameters\n        ----------\n\n        (None)\n\n        Returns\n        -------\n\n        (None), sets the psd attribute of the instance\n\n        See Also\n        --------\n        get_fft\n        get_acf\n        show\n\n        Notes\n        -----\n        Finds the psd by fourier transforming the ACF, in doing so looks for\n        the instance\'s acf property. If this is not found the acf is calculated\n        and set.\n\n        Examples\n        --------\n\n        >>> # sets the psd attribute of my_surface\n        >>> import slippy.surface as s\n        >>> my_surface  = s.assurface([[1,2],[3,4]], grid_spacing=1)\n        >>> my_surface.get_psd()\n\n        """\n        # PSD is the fft of the ACF (https://en.wikipedia.org/wiki/Spectral_density#Power_spectral_density)\n        if self.acf is None:\n            self.get_acf()\n        # noinspection PyTypeChecker\n        self.psd = self.get_fft(np.asarray(self.acf))\n\n    def subtract_polynomial(self, order, mask=None):\n        """ Flatten the surface by subtracting a polynomial\n\n        Alias for :func:`~slippy.surface.subtract_polynomial` function\n\n\n        """\n        if mask is None:\n            mask = self.mask\n\n        new_profile, coefs = subtract_polynomial(self.profile, order, mask)\n        self.profile = new_profile\n\n        return coefs\n\n    def roughness(self, parameter_name, mask=None, curved_surface=False,\n                  no_flattening=False, filter_cut_off=None,\n                  four_nearest=False):\n        """ Find areal roughness parameters\n\n        Alias for :func:`~slippy.surface.roughness` function\n\n        """\n        if mask is None:\n            mask = self.mask\n\n        out = roughness(self, parameter_name, mask=mask,\n                        curved_surface=curved_surface,\n                        no_flattening=no_flattening,\n                        filter_cut_off=filter_cut_off,\n                        four_nearest=four_nearest)\n        return out\n\n    def get_mat_vr(self, height, void=False, mask=None, ratio=True):\n        """ Find the material or void volume ratio for a given height\n\n        Alias for :func:`~slippy.surface.get_mat_vr` function\n\n        """\n        if mask is None:\n            mask = self.mask\n\n        return get_mat_vr(height, profile=self.profile, void=void, mask=mask,\n                          ratio=ratio)\n\n    def get_height_of_mat_vr(self, ratio, void=False, mask=None,\n                             accuracy=0.001):\n        """ Find the height of a given material or void volume ratio\n\n        Alias for :func:`~slippy.surface.get_height_of_mat_vr` function\n\n        """\n        if mask is None:\n            mask = self.mask\n\n        return get_height_of_mat_vr(ratio, self.profile, void=void, mask=mask,\n                                    accuracy=accuracy)\n\n    def get_summit_curvature(self, summits=None, mask=None,\n                             filter_cut_off=None, four_nearest=False):\n        """ Get summit curvatures\n\n        Alias for :func:`~slippy.surface.get_summit_curvature` function\n\n        """\n        if mask is None:\n            mask = self.mask\n\n        return get_summit_curvatures(self.profile, summits=summits, mask=mask,\n                                     filter_cut_off=filter_cut_off,\n                                     four_nearest=four_nearest, grid_spacing=self.grid_spacing)\n\n    def find_summits(self, mask=None, four_nearest=False, filter_cut_off=None,\n                     invert=False):\n        """ Find summits after low pass filtering\n\n        Alias for :func:`~slippy.surface.find_summits` function\n\n        """\n        if mask is None:\n            mask = self.mask\n\n        if invert:\n            return find_summits(self.profile * -1,\n                                grid_spacing=self.grid_spacing, mask=mask,\n                                four_nearest=four_nearest,\n                                filter_cut_off=filter_cut_off)\n        else:\n            return find_summits(self, mask=mask, four_nearest=four_nearest,\n                                filter_cut_off=filter_cut_off)\n\n    def low_pass_filter(self, cut_off_freq, return_copy=False):\n        """ Low pass FIR filter the surface profile\n\n        Alias for :func:`~slippy.surface.low_pass_filter` function\n\n        """\n        if return_copy:\n            return low_pass_filter(self, cut_off_freq)\n        else:\n            self.profile = low_pass_filter(self, cut_off_freq)\n\n    def resample(self, new_grid_spacing=None, return_profile=False, remake_interpolator=False):\n        """ Resample or crop the profile by interpolation\n\n        Parameters\n        ----------\n\n        new_grid_spacing : float, optional (None)\n            The grid spacing on the new surface, if the grid_spacing is not set on the current surface it is assumed to\n            be 1\n        return_profile : bool, optional (False)\n            If true the interpolated profile is returned otherwise it is set as the profile of the instance\n        remake_interpolator : bool, optional (False)\n            If true any memoized interpolator will be deleted and remade based on the current profile before\n            interpolation, see notes.\n\n        Returns\n        -------\n\n        new_profile : array\n            If return_profile is True the interpolated profile is returned\n\n        See Also\n        --------\n        rotate\n        fill_holes\n        surface_like\n\n        Notes\n        -----\n        On the first call this function will make an interpolator object which\n        is used to interpolate, on subsequent calls this object is found and\n        used resulting in no loss of quality. If the remake_interpolator key\n        word is set to true this interpolator is remade. This will result in a\n        loss of quality for subsequent calls but is necessary if the profile\n        property has changed.\n\n        This method does not support masking.\n\n        The profile should have nan or inf values removed by the fill_holes\n        method before running this\n\n        Examples\n        --------\n\n        >>> import numpy as np\n        >>> import slippy.surface as s\n        >>> profile=np.random.normal(size=(101,101))\n        >>> my_surface=s.assurface(profile, grid_spacing=1)\n        >>> # interpolate on a coarse grid:\n        >>> my_surface.resample(10)\n        >>> # check shape:\n        >>> my_surface.shape\n        (11,11)\n        >>> # restore original profile:\n        >>> my_surface.resample(1)\n        >>> my_surface.shape\n        (101,101)\n        """\n        gs_changed = False\n        if self.grid_spacing is None:\n            gs_changed = True\n            self.grid_spacing = 1\n\n        if remake_interpolator or self._inter_func is None:\n            self._original_extent = self.extent\n            x0 = np.arange(0, self.extent[0], self.grid_spacing)\n            y0 = np.arange(0, self.extent[1], self.grid_spacing)\n            self._inter_func = scipy.interpolate.RectBivariateSpline(x0, y0, self.profile)\n        x1 = np.arange(0, self._original_extent[0], new_grid_spacing)\n        y1 = np.arange(0, self._original_extent[1], new_grid_spacing)\n        new_profile = self._inter_func(x1, y1)\n\n        if gs_changed:\n            del self.grid_spacing\n\n        if return_profile:\n            return new_profile\n        else:\n            self.profile = new_profile\n            if not gs_changed:\n                self.grid_spacing = new_grid_spacing\n\n    def __add__(self, other):\n        if not isinstance(other, _Surface):\n            return Surface(profile=self.profile + other, grid_spacing=self.grid_spacing)\n\n        if self.grid_spacing is not None and other.grid_spacing is not None and self.grid_spacing != other.grid_spacing:\n            if self.grid_spacing < other.grid_spacing:\n                prof_2 = other.resample(self.grid_spacing, return_profile=True)\n                prof_1 = self.profile\n                new_gs = self.grid_spacing\n            else:\n                prof_1 = self.resample(other.grid_spacing, return_profile=True)\n                prof_2 = other.profile\n                new_gs = other.grid_spacing\n        else:\n            prof_1 = self.profile\n            prof_2 = other.profile\n            if self.grid_spacing is not None:\n                new_gs = self.grid_spacing\n            else:\n                new_gs = other.grid_spacing\n\n        new_shape = [min(p1s, p2s) for p1s, p2s in zip(prof_1.shape, prof_2.shape)]\n        new_profile = prof_1[0:new_shape[0], 0:new_shape[1]] + prof_2[0:new_shape[0], 0:new_shape[1]]\n        return Surface(profile=new_profile, grid_spacing=new_gs)\n\n    def __mul__(self, other):\n        if isinstance(other, Number):\n            return Surface(profile=self.profile*other, grid_spacing=self.grid_spacing)\n        else:\n            raise NotImplementedError("Multiplication not implement for Surfaces unless other parameter is number")\n\n    def __div__(self, other):\n        if isinstance(other, Number):\n            return Surface(profile=self.profile/other, grid_spacing=self.grid_spacing)\n        else:\n            raise NotImplementedError("Division not implement for Surfaces unless other parameter is number")\n\n    def __sub__(self, other):\n        if not isinstance(other, _Surface):\n            return Surface(profile=self.profile - other, grid_spacing=self.grid_spacing)\n\n        if self.grid_spacing is not None and other.grid_spacing is not None and self.grid_spacing != other.grid_spacing:\n            if self.grid_spacing < other.grid_spacing:\n                prof_2 = other.resample(self.grid_spacing, return_profile=True)\n                prof_1 = self.profile\n                new_gs = self.grid_spacing\n            else:\n                prof_1 = self.resample(other.grid_spacing, return_profile=True)\n                prof_2 = other.profile\n                new_gs = other.grid_spacing\n        else:\n            prof_1 = self.profile\n            prof_2 = other.profile\n            if self.grid_spacing is not None:\n                new_gs = self.grid_spacing\n            else:\n                new_gs = other.grid_spacing\n\n        new_shape = [min(p1s, p2s) for p1s, p2s in zip(prof_1.shape, prof_2.shape)]\n        new_profile = prof_1[0:new_shape[0], 0:new_shape[1]] - prof_2[0:new_shape[0], 0:new_shape[1]]\n        return Surface(profile=new_profile, grid_spacing=new_gs)\n\n    def __eq__(self, other):\n        if not isinstance(other, _Surface) or self.is_discrete != other.is_discrete:\n            return False\n        if self.is_discrete:\n            return np.array_equal(self.profile, other.profile) and self.grid_spacing == other.grid_spacing\n        else:\n            return repr(self) == repr(other)\n\n    def show(self, property_to_plot: typing.Union[str, typing.Sequence[str]] = \'profile\',\n             plot_type: typing.Union[str, typing.Sequence[str]] = \'default\', ax=False, *, dist=None, stride=None,\n             **figure_kwargs):\n        """ Plot surface properties\n\n        Parameters\n        ----------\n        property_to_plot : str or list of str length N optional (\'profile\')\n            The property to be plotted see notes for supported names\n        plot_type : str or list of str length N optional (\'default\')\n            The type of plot to be produced, see notes for supported types\n        ax : matplotlib axes or False optional (False)\n            If supplied the plot will be added to the axis\n        dist : a scipy probability distribution, optional (None)\n            Only used if probplot is requested, the probability distribution\n            to plot against\n        stride : float, optional (None)\n            Only used if a wire frame plot is requested, the stride between\n            wires\n        figure_kwargs : optional (None)\n            Keyword arguments sent to the figure function in matplotlib\n\n        Returns\n        -------\n        ax : matplotlib axes or list of matplotlib axes length N\n            The axis with the plot\n\n        See Also\n        --------\n        get_fft\n        get_psd\n        get_acf\n        ACF\n\n        Notes\n        -----\n        If fft, psd or acf are requested the field of the surface is filled\n        by the relevant get_ method before plotting.\n\n        The grid spacing attribute should be set before plotting\n\n        2D and 1D plots can be produced. 2D properties are:\n\n            - profile         - surface profile\n            - unworn_profile  - the surface profile with no wear applied\n            - fft2d           - fft of the surface profile\n            - psd             - power spectral density of the surface profile\n            - acf             - auto correlation function of the surface\n            - apsd            - angular power spectral density of the profile\n\n        Plot types allowed for 2D plots are:\n\n            - surface (default)\n            - image\n            - mesh\n\n        If a mesh plot is requested the distance between lines in the mesh can\n        be specified with the stride keyword\n\n        1D properties are:\n\n            - histogram - histogram of the profile heights\n            - fft1d     - 1 dimentional fft of the surface\n            - qq        - quartile quartile plot of the surface heights\n\n        If qq or dist hist are requested the distribution to be plotted against\n        the height values can be specified by the dist keyword\n\n        Each of the 1D properties can only be plotted on it\'s default plot type\n\n        Examples\n        --------\n        >>> # show the surface profile as an image:\n        >>> import slippy.surface as s\n        >>> import numpy as np\n        >>> my_surface=s.assurface(np.random.rand(10,10))\n        >>> my_surface.show(\'profile\', \'image\')\n\n        >>> # show the 2D fft of the surface profile with a range of plot types\n        >>> my_surface.show([\'fft2D\',\'fft2D\',\'fft2D\'], [\'mesh\', \'image\', \'default\'])\n\n        """\n        import matplotlib.pyplot as plt\n        # noinspection PyUnresolvedReferences\n        from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n        from scipy.stats import probplot\n\n        if self.profile is None:\n            raise AttributeError(\'The profile of the surface must be set before it can be shown\')\n        if self.grid_spacing is None:\n            raise AttributeError("The grid spacing of the surface must be set before it can be shown")\n\n        types2d = [\'profile\', \'fft2d\', \'psd\', \'acf\', \'apsd\', \'unworn_profile\']\n        types1d = [\'histogram\', \'fft1d\', \'qq\', \'hist\']\n\n        # using a recursive call to deal with multiple plots on the same fig\n        if isinstance(property_to_plot, Sequence) and not isinstance(property_to_plot, str):\n            number_of_subplots = len(property_to_plot)\n            if not type(ax) is bool:\n                msg = ("Can\'t plot multiple plots on single axis, "\n                       \'making new figure\')\n                warnings.warn(msg)\n            if isinstance(plot_type, Sequence) and not isinstance(plot_type, str):\n                plot_type = list(plot_type)\n                if len(plot_type) < number_of_subplots:\n                    plot_type.extend([\'default\'] * (number_of_subplots - len(plot_type)))\n            else:\n                plot_type = [plot_type, ] * number_of_subplots\n            # 11, 12, 13, 22, then filling up rows of 3 (unlikely to be used)\n            # fig = plt.figure()\n            # ax = fig.add_subplot(111, projection=\'3d\')\n            if len(property_to_plot) < 5:\n                n_cols = [1, 2, 3, 2][number_of_subplots - 1]\n            else:\n                n_cols = 3\n            n_rows = int(np.ceil(number_of_subplots / 3))\n            fig = plt.figure(**figure_kwargs)\n            ax = []\n            sub_plot_number = 100 * n_rows + 10 * n_cols + 1\n            for i in range(number_of_subplots):\n                if property_to_plot[i].lower() in types2d and not plot_type[i] in (\'image\', \'default\'):\n                    ax.append(fig.add_subplot(sub_plot_number + i, projection=\'3d\'))\n                else:\n                    ax.append(fig.add_subplot(sub_plot_number + i))\n                self.show(property_to_plot[i], plot_type[i], ax[i])\n            return fig, ax\n        #######################################################################\n        # main method\n        #######################################################################\n        # 2D plots\n        try:\n            property_to_plot = property_to_plot.lower()\n        except AttributeError:\n            msg = "Property to plot must be a string or a list of strings"\n            raise ValueError(msg)\n\n        if not (property_to_plot in types2d or property_to_plot in types1d):\n            msg = (\'Unsupported property to plot see documentation for details\'\n                   \', type given: \\n\' + str(property_to_plot) + \' \\nsupported ty\'\n                                                                \'pes: \\n\' + \' \'.join(types2d + types1d))\n            raise ValueError(msg)\n\n        if not ax:\n            fig = plt.figure(**figure_kwargs)\n\n        if property_to_plot in types2d:\n            if not ax and (plot_type == \'image\' or plot_type == \'default\'):\n                # noinspection PyUnboundLocalVariable\n                ax = fig.add_subplot(111)\n            elif not ax:\n                # noinspection PyUnboundLocalVariable\n                ax = fig.add_subplot(111, projection=\'3d\')\n\n            if property_to_plot == \'profile\':\n                labels = [\'Surface profile\', \'x\', \'y\', \'Height\']\n                x = self.grid_spacing * np.arange(self.shape[0])\n                y = self.grid_spacing * np.arange(self.shape[1])\n                z = self.profile\n\n            elif property_to_plot == \'unworn_profile\':\n                labels = [\'Surface profile (unworn)\', \'x\', \'y\', \'Height\']\n                x = self.grid_spacing * np.arange(self.shape[0])\n                y = self.grid_spacing * np.arange(self.shape[1])\n                z = self.unworn_profile\n\n            elif property_to_plot == \'fft2d\':\n                labels = [\'Fourier transform of surface\', \'u\', \'v\', \'|F(x)|\']\n                if self.fft is None:\n                    self.get_fft()\n                z = np.abs(np.fft.fftshift(self.fft))\n                x = np.fft.fftfreq(self.shape[0], self.grid_spacing)\n                y = np.fft.fftfreq(self.shape[1], self.grid_spacing)\n\n            elif property_to_plot == \'psd\':\n                labels = [\'Power spectral density\', \'u\', \'v\', \'Power/ frequency\']\n                if self.psd is None:\n                    self.get_psd()\n                # noinspection PyTypeChecker\n                z = np.log(np.abs(np.fft.fftshift(self.psd)))\n                x = np.fft.fftfreq(self.shape[0], self.grid_spacing)\n                y = np.fft.fftfreq(self.shape[1], self.grid_spacing)\n\n            elif property_to_plot == \'acf\':\n                labels = [\'Auto correlation function\', \'x\', \'y\',\n                          \'Surface auto correlation\']\n                if self.acf is None:\n                    self.get_acf()\n                # noinspection PyTypeChecker\n                z = np.abs(np.asarray(self.acf))\n                x = self.grid_spacing * np.arange(self.shape[0])\n                y = self.grid_spacing * np.arange(self.shape[1])\n                x = x - max(x) / 2\n                y = y - max(y) / 2\n\n            elif property_to_plot == \'apsd\':\n                labels = [\'Angular power spectral density\', \'x\', \'y\']\n                if self.fft is None:\n                    self.get_fft()\n                p_area = (self.shape[0] - 1) * (self.shape[1] - 1) * self.grid_spacing ** 2\n                z = self.fft * np.conj(self.fft) / p_area\n                x = self.grid_spacing * np.arange(self.shape[0])\n                y = self.grid_spacing * np.arange(self.shape[1])\n                x = x - max(x) / 2\n                y = y - max(y) / 2\n            else:\n                raise ValueError("Property not recognised")\n\n            mesh_x, mesh_y = np.meshgrid(x, y)\n\n            if plot_type == \'surface\':\n                ax.plot_surface(mesh_x, mesh_y, np.transpose(z))\n                # plt.axis(\'equal\')\n                ax.set_zlabel(labels[3])\n            elif plot_type == \'mesh\':\n                if property_to_plot == \'psd\' or property_to_plot == \'fft2d\':\n                    mesh_x, mesh_y = np.fft.fftshift(mesh_x), np.fft.fftshift(mesh_y)\n                if stride:\n                    ax.plot_wireframe(mesh_x, mesh_y, np.transpose(z), rstride=stride,\n                                      cstride=stride)\n                else:\n                    ax.plot_wireframe(mesh_x, mesh_y, np.transpose(z), rstride=25,\n                                      cstride=25)\n                ax.set_zlabel(labels[3])\n            elif plot_type == \'default\' or plot_type == \'image\':\n                ax.imshow(z, extent=[min(y), max(y), min(x), max(x)], aspect=1)\n            else:\n                ValueError(\'Unrecognised plot type\')\n\n            ax.set_title(labels[0])\n            ax.set_xlabel(labels[1])\n            ax.set_ylabel(labels[2])\n            return ax\n\n        #######################################################################\n        # 1D plots\n        #######################################################################\n\n        elif property_to_plot in types1d:\n            if not ax:\n                # noinspection PyUnboundLocalVariable\n                ax = fig.add_subplot(111)\n\n            if property_to_plot == \'histogram\' or property_to_plot == \'hist\':\n                # do all plotting in this loop for 1D plots\n                labels = [\'Histogram of surface heights\', \'height\', \'counts\']\n                ax.hist(self.profile.flatten(), 100)\n\n            elif property_to_plot == \'fft1d\':\n                if self.dimensions == 1:\n                    labels = [\'FFt of surface\', \'frequency\', \'|F(x)|\']\n\n                    if type(self.fft) is bool:\n                        self.get_fft()\n                    x = np.fft.fftfreq(self.shape[0], self.grid_spacing)\n                    y = np.abs(self.fft / self.shape[0])\n                    # line plot for 1d surfaces\n                    ax.plot(x, y)\n                    ax.xlim(0, max(x))\n                else:\n                    labels = [\'Scatter of frequency magnitudes\',\n                              \'frequency\', \'|F(x)|\']\n                    u = np.fft.fftfreq(self.shape[0], self.grid_spacing)\n                    v = np.fft.fftfreq(self.shape[1], self.grid_spacing)\n                    u_mesh, v_mesh = np.meshgrid(u, v)\n                    frequencies = u_mesh + v_mesh\n                    if type(self.fft) is bool:\n                        self.get_fft()\n                    mags = np.abs(self.fft)\n                    # scatter plot for 2d frequencies\n                    ax.scatter(frequencies.flatten(), mags.flatten(), 0.5, None, \'x\')\n                    ax.set_xlim(0, max(frequencies.flatten()))\n                    ax.set_ylim(0, max(mags.flatten()))\n            elif property_to_plot == \'qq\':\n\n                labels = [\'Probability plot\', \'Theoretical quantities\',\n                          \'Ordered values\']\n                if dist:\n                    probplot(self.profile.flatten(), dist=dist, fit=True,\n                             plot=ax)\n                else:\n                    probplot(self.profile.flatten(), fit=True, plot=ax)\n            else:\n                raise ValueError(f"Property to plot {property_to_plot}, not recognised.")\n\n            ax.set_title(labels[0])\n            ax.set_xlabel(labels[1])\n            ax.set_ylabel(labels[2])\n            return ax\n        #######################################################################\n        #######################################################################\n\n    def __array__(self):\n        return np.asarray(self.profile)\n\n    @abc.abstractmethod\n    def __repr__(self):\n        return "Surface(profile=" + self.profile.__repr__() + ", grid_spacing=" + self.grid_spacing.__repr__() + ")"\n\n    def get_points_from_extent(self, extent=None, grid_spacing=None, shape=None):\n        """\n        Gets the grid points from the extent and the grid spacing\n\n        Returns\n        -------\n        mesh_y, mesh_x : np.ndarray\n            arrays of the grid points (result from mesh grid)\n        """\n        if extent is None and grid_spacing is None and shape is None:\n            if self.grid_spacing is None or self.extent is None:\n                raise AttributeError(\'Grid points cannot be found until the surface is fully defined, the grid spacing \'\n                                     \'and extent must be findable.\')\n\n            # I know this looks stupid, using arrange will give the wrong number of elements because of rounding error\n            x = np.linspace(0, self.grid_spacing*(self.shape[1]-1), self.shape[1])\n            y = np.linspace(0, self.grid_spacing*(self.shape[0]-1), self.shape[0])\n\n            mesh_x, mesh_y = np.meshgrid(x, y)\n\n        else:\n            dum = Surface(grid_spacing=grid_spacing, shape=shape, extent=extent)\n            try:\n                mesh_y, mesh_x = dum.get_points_from_extent()\n            except AttributeError:\n                raise ValueError(\'Exactly two parameters must be supplied\')\n\n        return mesh_y, mesh_x\n\n    def mesh(self, depth, method=\'grid\', parameters=None):\n        """\n        Returns a Mesh object for the surface\n\n        Equivalent to Mesh(surface)\n\n        Parameters\n        ----------\n\n        # TODO\n        """\n        pass\n        # raise NotImplementedError("No mesh yet, Sorry!")\n        # if not self.is_discrete:\n        #     raise ValueError("Surface must be discrete before meshing")\n\n    def interpolate(self, y_points: np.ndarray, x_points: np.ndarray, mode: str = \'nearest\',\n                    remake_interpolator: bool = False):\n        """\n        Easy memoized interpolation on surface objects\n\n        Parameters\n        ----------\n        y_points: np.ndarray\n            N by M array of x points, in the same units as the grid spacing\n        x_points: np.ndarray\n            N by M array of y points, in the same units as the grid spacing\n        mode: str {\'nearest\', \'linear\', \'cubic\'}, optional (\'nearest\')\n            The mode of the interpolation\n        remake_interpolator: bool, optional (False)\n            If True the interpolator function will be remade, otherwise the existing one will be used, if no\n            interpolator function is found it will be made automatically\n\n        Returns\n        -------\n        sub_profile: np.ndarray\n            The surface heights at the grid points requested, same shape as x_points and y_points\n        """\n        assert (x_points.shape == y_points.shape)\n\n        if mode == \'nearest\':\n            x_index = np.mod(np.array((x_points+self.grid_spacing/2) / self.grid_spacing, dtype=\'int32\').flatten(),\n                             self.shape[1])\n            y_index = np.mod(np.array((y_points+self.grid_spacing/2) / self.grid_spacing, dtype=\'int32\').flatten(),\n                             self.shape[0])\n            return np.reshape(self.profile[y_index, x_index], newshape=x_points.shape)\n        elif mode == \'linear\':\n            if remake_interpolator or self._inter_func is None or self._inter_func.degrees != (1, 1):\n                x0 = np.arange(0, self.extent[0], self.grid_spacing)\n                y0 = np.arange(0, self.extent[1], self.grid_spacing)\n                self._inter_func = scipy.interpolate.RectBivariateSpline(x0, y0, self.profile, kx=1, ky=1)\n        elif mode == \'cubic\':\n            if remake_interpolator or self._inter_func is None or self._inter_func.degrees != (3, 3):\n                x0 = np.arange(0, self.extent[0], self.grid_spacing)\n                y0 = np.arange(0, self.extent[1], self.grid_spacing)\n                self._inter_func = scipy.interpolate.RectBivariateSpline(x0, y0, self.profile, kx=3, ky=3)\n        else:\n            raise ValueError(f\'{mode} is not a recognised mode for the interpolation function\')\n\n        return self._inter_func(x_points, y_points, grid=False)\n\n\nclass Surface(_Surface):\n    r""" Object for reading, manipulating and plotting surfaces\n\n        The Surface class contains methods for setting properties,\n        examining measures of roughness and descriptions of surfaces, plotting,\n        fixing and editing surfaces.\n\n        Parameters\n        ----------\n        profile: np.ndarray, optional (None)\n            The height profile of the surface, the units should be the same as used for the grid spacing parameter\n        grid_spacing: float, optional (None)\n            The distance between the grid points in the surface profile\n        shape: tuple, optional (None)\n            The number of grid points in the surface in each direction, should not be set if a profile is given\n        extent: tuple, optional (None)\n            The total extent of the surface in the same units as the grid spacing, either this or the grid spacing can\n            be set if a profile is given (either as the profile argument or from a file)\n        file_name: str, optional (None)\n            The full path including the file extension to a supported file type, supported types are .txt, .csv, .al3d,\n            .mat\n        csv_delimiter: str, optional (None)\n            The delimiter used in the .csv or .txt file, only used if the file name is given and the file is a .txt or\n            .csv file\n        csv_dialect: {csv.Dialect, str), optional (\'sniff\')\n            The dialect used to read the csv file, only used if a file is supplied and the file is a csv file, defaults\n            to \'sniff\' meaning that the csv. sniffer will be used.\n        csv_sniffer_n_bytes: int, optional (2048)\n            The number of bytes used by the csv sniffer, only used if \'sniff\' is given as the dialect and a csv file is\n            given as the file name\n        mat_profile_name: str, optional (\'profile\')\n            The name of the profile variable in the .mat file, only used if the file_name is given and the file is a\n            .mat file\n        mat_grid_spacing_name: str, optional (None)\n            The name of the grid_spacing variable in the .mat file, only used if the file_name is given and the file is\n            a .mat file. If unset the grid_spacing property is not read from the file.\n\n        See Also\n        --------\n        ACF\n        roughness\n\n        Notes\n        -----\n        Roughness functions are aliased from the functions provided in the surface\n        module\n\n        Examples\n        --------\n        Making a surface from a numpy array:\n\n        >>> import slippy.surface as s\n        >>> import numpy as np\n        >>> profile = np.random.rand(10,10)\n        >>> my_surface = s.Surface(profile = profile, grid_spacing = 1)\n\n        Making a surface from a csv file:\n\n        >>> my_surface = s.Surface(file_name=\'surface.csv\', grid_spacing = 1)\n\n        Note that variations on csv files can be handled by passing a CSV dialect object from the csv package, this can\n        also be automatically detected by passing \'sniff\' as the dialect.\n\n        Making a surface from an alicona file:\n\n        >>> path = r\'path\\to\\alicona\\file\'\n        >>> my_surface = s.Surface(file_name=path+r\'\\dem.al3d\')\n\n        This will extract the surface profile and grid spacing from the .al3d file. More parameters can be extracted by\n        using the alicona_read function.\n\n        Making a surface from a matlab file:\n\n        >>> my_surface = s.Surface(file_name=\'saved profiles.mat\', grid_spacing = 1)\n\n        If the profile parameter in the matlab file is not called \'profile\' this can be set:\n\n        >>> my_surface = s.Surface(file_name=\'saved profiles.mat\', mat_profile_name=\'profile_b\', grid_spacing = 1)\n        """\n\n    def rotate(self, radians):\n        raise NotImplementedError("Cannot rotate this surface")\n\n    surface_type = \'Experimental\'\n\n    def __init__(self, profile: typing.Optional[np.ndarray] = None, grid_spacing: typing.Optional[float] = None,\n                 shape: typing.Optional[tuple] = None, extent: typing.Optional[tuple] = None,\n                 file_name: typing.Optional[str] = None,\n                 mat_profile_name: typing.Optional[str] = None, mat_grid_spacing_name: typing.Optional[str] = None,\n                 csv_delimiter: str = None, csv_dialect: typing.Union[csv.Dialect, str] = \'sniff\',\n                 csv_sniffer_n_bytes: int = 2048):\n\n        if profile is not None or file_name is not None:\n            if shape is not None:\n                raise ValueError("The shape cannot be set if the profile is also set, please set either the "\n                                 "grid_spacing or the extent only")\n            if grid_spacing is not None and extent is not None:\n                raise ValueError("Either the grid_spacing or the extent should be set with a profile, not both")\n            self.profile = profile\n\n        if file_name is not None:\n            if profile is not None:\n                raise ValueError("The profile and a file name cannot be set")\n            file_ext = os.path.splitext(file_name)[1]\n            if file_ext == \'.mat\':\n                self.read_mat(file_name, mat_profile_name, mat_grid_spacing_name)\n            elif file_ext == \'.al3d\':\n                self.read_al3d(file_name)\n            elif file_ext == \'.txt\' or file_ext == \'.csv\':\n                self.read_csv(file_name, delimiter=csv_delimiter, dialect=csv_dialect, sniff_bytes=csv_sniffer_n_bytes)\n            else:\n                raise ValueError(f"File extension not recognised: {file_ext}")\n            # read file replace profile\n\n        super().__init__(grid_spacing=grid_spacing, extent=extent, shape=shape, is_discrete=True)\n\n    def read_al3d(self, file_name: str, return_data: bool = False):\n        """\n        Reads an alicona al3d file and sets the profile and grid_spacing property of the surface\n\n        Parameters\n        ----------\n        file_name: str\n            The full path including the extension of the .al3d file\n        return_data: bool, optional (False)\n            If True the data from the al3d file is returned as a dict\n\n        Returns\n        -------\n        data: dict\n            data read from the al3d file, only returned if return_data is set to True\n        """\n        from .alicona import alicona_read\n        data = alicona_read(file_name)\n        self.profile = data[\'DepthData\']\n        self.grid_spacing = data[\'Header\'][\'PixelSizeXMeter\']\n        if return_data:\n            return data\n\n    def read_csv(self, file_name: str, delimiter: str = None, return_profile: bool = False,\n                 dialect: typing.Union[csv.Dialect, str] = \'sniff\', sniff_bytes: int = 2048):\n        """\n        Read a profile from a csv or txt file, header lines are automatically skipped\n\n        Parameters\n        ----------\n        file_name: str\n            The full path to the .txt or .csv file including the file extension\n        delimiter: str, optional (None)\n            The delimiter used in by csv reader\n        return_profile: bool, optional (False)\n            If true the profile will be returned\n        dialect: {csv.Dialect, str}, optional (\'sniff\')\n            A csv dialect object or \'sniff\' if the dialect is to be found by the csv sniffer\n        sniff_bytes: int, optional (2048)\n            The number of bytes read from the file for the csv.Sniffer, only used if the delimiter is \'sniff\'\n        """\n\n        with open(file_name) as file:\n            if delimiter is not None:\n                reader = csv.reader(file, delimiter=delimiter)\n            else:\n                if dialect == \'sniff\':\n                    dialect = csv.Sniffer().sniff(file.read(sniff_bytes))\n                    file.seek(0)\n                reader = csv.reader(file, dialect=dialect)\n            profile = []\n            for row in reader:\n                if row:\n                    if type(row[0]) is float:\n                        profile.append(row)\n                    else:\n                        if len(row) == 1:\n                            try:\n                                row = [float(x) for x in row[0].split()\n                                       if not x == \'\']\n                                profile.append(row)\n                            except ValueError:\n                                pass\n                        else:\n                            try:\n                                row = [float(x) for x in row if not x == \'\']\n                                profile.append(row)\n                            except ValueError:\n                                pass\n        if return_profile:\n            return np.array(profile, dtype=float)\n        self.profile = profile\n\n    def read_mat(self, path: str, profile_name: str = \'profile\', grid_spacing_name: str = None):\n        """ Reads .mat files as surfaces\n\n        Parameters\n        ----------\n        path : str\n            full path including file name to a .mat file\n        profile_name : srt, optional (\'profile\')\n            The name of the profile variable in the .mat file\n        grid_spacing_name : str, optional (None)\n            The name of the grid_spacing variable in the .mat file, if set to none the grid spacing variable is not set\n\n        Notes\n        -----\n        This method will search the .mat file for the given keys. If no keys\n        are given, and the .mat file contains variables called grid_spacing or\n        profile these are set as the relevant attributes. Otherwise, if the\n        .mat file only contains one variable this is set as the profile.\n        If none of the above are true, or if the given keys are not found\n        an error is raised\n\n        """\n        if profile_name is None:\n            profile_name = \'profile\'\n\n        from scipy.io import loadmat\n        # load file\n        mat = loadmat(path)\n        keys = [key for key in mat if not key.startswith(\'_\')]\n\n        if grid_spacing_name is not None:\n            try:\n                self.grid_spacing = mat[grid_spacing_name]\n            except KeyError:\n                msg = ("Name {} not found in .mat file,".format(grid_spacing_name) +\n                       " names found were: ".join(keys))\n                raise ValueError(msg)\n\n        try:\n            self.profile = mat[profile_name]\n        except KeyError:\n            msg = ("Name {} not found in .mat file,".format(profile_name) +\n                   " names found were: ".join(keys))\n            raise ValueError(msg)\n\n    def fill_holes(self, hole_value=\'auto\', mk_copy=False, remove_boarder=True,\n                   b_thresh=0.99):\n        """ Replaces specified values with filler\n\n        Removes boarder then uses biharmonic equations algorithm to fill holes\n\n        Parameters\n        ----------\n        hole_value: {\'auto\' or float}\n            The value to be replaced, \'auto\' replaces all -inf, inf and nan\n            values\n        mk_copy : bool\n            if set to true a new surface object will be returned with the holes\n            filled otherwise the profile property of the current surface is\n            updated\n        remove_boarder : bool\n            Defaults to true, removes the boarder from the image until the\n            first row and column that have\n        b_thresh : float\n            (0>, <=1) If the boarder is removed, the removal will continue until the row\n            or column to be removed contains at least this proportion of real values\n\n        Returns\n        -------\n        If mk_copy is true a new surface object with holes filled else resets\n        profile property of the instance and returns nothing\n\n        See Also\n        --------\n        skimage.restoration.inpaint.inpaint_biharmonic\n\n        Notes\n        -----\n        When alicona images are imported the invalid pixel value is\n        automatically set to nan so this will work in auto mode\n\n        Holes are filled with bi harmonic equations\n\n        Examples\n        --------\n\n        >>> import slippy.surface as s\n        >>> # make a dummy profile\n        >>> x=np.arange(12, dtype=float)\n        >>> X,_=np.meshgrid(x,x)\n        >>> # pad with nan values\n        >>> X2=np.pad(X,2,\'constant\', constant_values=float(\'nan\'))\n        >>> # add hole to centre\n        >>> X2[6,6]=float(\'nan\')\n        >>> # make surface\n        >>> my_surface=s.Surface(profile=X2)\n        >>> my_surface.fill_holes()\n        >>> my_surface.profile[6,6]\n        6.0\n        """\n        from skimage.restoration import inpaint\n\n        profile = self.profile\n\n        if hole_value == \'auto\':\n            holes = np.logical_or(np.isnan(profile), np.isinf(profile))\n        else:\n            holes = profile == hole_value\n        if sum(sum(holes)) == 0:\n            warnings.warn(\'No holes detected\')\n\n        profile[holes] = 0\n\n        if remove_boarder:\n            # find rows\n            good = [False] * 4\n\n            start_r = 0\n            end_r = None  # len(profile)\n            start_c = 0\n            end_c = None  # len(profile[0])\n\n            # iterate ove removing cols and rows if they have too many holes\n            while not all(good):\n                if np.mean(holes[start_r, start_c:end_c]) > b_thresh:\n                    start_r += 1\n                else:\n                    good[0] = True\n\n                if np.mean(holes[-1 if end_r is None else end_r - 1, start_c:end_c]) > b_thresh:\n                    end_r = -1 if end_r is None else end_r - 1\n                else:\n                    good[1] = True\n\n                if np.mean(holes[start_r:end_r, start_c]) > b_thresh:\n                    start_c += 1\n                else:\n                    good[2] = True\n\n                if np.mean(holes[start_r:end_r, -1 if end_c is None else end_c - 1]) > b_thresh:\n                    end_c = -1 if end_c is None else end_c - 1\n                else:\n                    good[3] = True\n\n            # add back in if they are ok\n            while any(good):\n                if start_r > 0 and not np.mean(holes[start_r - 1, start_c:end_c]) > b_thresh:\n                    start_r -= 1\n                else:\n                    good[0] = False\n\n                if end_r is not None and not np.mean(holes[end_r, start_c:end_c]) > b_thresh:\n                    end_r = end_r + 1 if end_r + 1 < 0 else None\n                else:\n                    good[1] = False\n\n                if start_c > 0 and not np.mean(holes[start_r:end_r, start_c - 1]) > b_thresh:\n                    start_c -= 1\n                else:\n                    good[2] = False\n\n                if end_c is not None and not np.mean(holes[start_r:end_r, end_c]) > b_thresh:\n                    end_c = end_c + 1 if end_c + 1 < 0 else None\n                else:\n                    good[3] = False\n\n            profile = profile[start_r:end_r, start_c:end_c]\n            holes = holes[start_r:end_r, start_c:end_c]\n\n        profile_out = inpaint.inpaint_biharmonic(profile, holes,\n                                                 multichannel=False)\n\n        if mk_copy:\n            new_surf = Surface(profile=profile_out, grid_spacing=self.grid_spacing)\n            return new_surf\n        else:\n            self.profile = profile_out\n\n    def __repr__(self):\n        string = \'\'\n        if self.profile is not None:\n            string += \'profile = \' + repr(self.profile) + \', \'\n        elif self.shape is not None:\n            string += \'shape = \' + repr(self.shape) + \', \'\n        if self.grid_spacing is not None:\n            string += \'grid_spacing = \' + repr(self.grid_spacing) + \', \'\n        if self.material is not None:\n            string += \'material = \' + repr(self.material) + \', \'\n        if self.mask is not None:\n            string += \'mask = \' + repr(self.mask) + \', \'\n        string = string[:-2]\n\n        return \'Surface(\' + string + \')\'\n\n\nclass _AnalyticalSurface(_Surface):\n    """\n    A abstract base class for analytical surfaces, to extend the height and __repr__ methods must be overwritten\n    """\n    _total_shift: tuple = (0, 0)\n    _total_rotation: float = 0\n    is_analytic = True\n    _analytic_subclass_registry = []\n    is_discrete = False\n\n    def __init__(self, generate: bool = False, rotation: Number = None,\n                 shift: typing.Union[str, tuple] = None,\n                 grid_spacing: float = None, extent: tuple = None, shape: tuple = None):\n        super().__init__(grid_spacing=grid_spacing, extent=extent, shape=shape)\n        if rotation is not None:\n            self.rotate(rotation)\n\n        self.shift(shift)\n\n        if generate:\n            self.discretise()\n\n    def discretise(self):\n        if self.is_discrete:\n            msg = (\'Surface is already discrete this will overwrite surface\'\n                   \' profile\')\n            warnings.warn(msg)\n        if self.grid_spacing is None:\n            msg = \'A grid spacing must be provided before discretisation\'\n            raise AttributeError(msg)\n\n        if self.extent is None:\n            msg = \'The extent or the shape of the surface must be set before discretisation\'\n            raise AttributeError(msg)\n        if self.size > 10E7:\n            warnings.warn(\'surface contains over 10^7 points calculations will\'\n                          \' be slow, consider splitting surface for analysis\')\n\n        x_mesh, y_mesh = self.get_points_from_extent()\n        self.is_discrete = True\n        self.profile = self.height(x_mesh, y_mesh)\n\n    @abc.abstractmethod\n    def _height(self, x_mesh, y_mesh):\n        pass\n\n    def height(self, x_mesh: typing.Union[np.ndarray, Number], y_mesh: typing.Union[np.ndarray, Number]) -> np.ndarray:\n        """ Find the height of the surface at specified points\n\n        Parameters\n        ----------\n        x_mesh: np.ndarray\n            An n by m array of x co-ordinates\n        y_mesh: np.ndarray\n            An n by m array of y co-ordinates\n\n        Returns\n        -------\n        height: np.ndarray\n            An n by m array of surface heights\n\n        Notes\n        -----\n        If a shift and rotation are specified, the rotation is applied first about the origin, the shift is then applied\n\n        Examples\n        --------\n        >>>import slippy.surface as s\n        >>>my_surf = s.PyramidSurface((1,1,1))\n        >>>my_surf.height(0,0)\n        0\n        """\n\n        x = x_mesh * np.cos(self._total_rotation) - y_mesh * np.sin(self._total_rotation)\n        y = y_mesh * np.cos(self._total_rotation) + x_mesh * np.sin(self._total_rotation)\n        x_shift, y_shift = self._total_shift\n        x += x_shift * np.cos(self._total_rotation) - y_shift * np.sin(self._total_rotation)\n        y += y_shift * np.cos(self._total_rotation) + x_shift * np.sin(self._total_rotation)\n\n        return self._height(x, y)\n\n    def _repr_helper(self):\n        string = \'\'\n        if self._total_shift[0] or self._total_shift[1]:\n            string += \', shift = \' + repr(self._total_shift)\n        if self._total_rotation:\n            string += \', rotation = \' + repr(self._total_rotation)\n        if self.is_discrete:\n            string += \', generate = True\'\n        if self.grid_spacing:\n            string += f\', grid_spacing = {self.grid_spacing}\'\n        if self.extent:\n            string += f\', extent = {self.extent}\'\n        return string\n\n    @classmethod\n    def __init_subclass__(cls, is_abstract=False, **kwargs):\n        super().__init_subclass__(**kwargs)\n        if not is_abstract:\n            _AnalyticalSurface._analytic_subclass_registry.append(cls)\n\n    @abc.abstractmethod\n    def __repr__(self):\n        pass\n\n    def rotate(self, radians: Number):\n        self._total_rotation += radians\n\n    def shift(self, shift: tuple = None):\n        """ Translate the profile of the surface\n\n        Parameters\n        ----------\n        shift: tuple, optional (None)\n            The distance to move the surface profile in the x and y directions, defaults to moving the origin of the\n            profile to the centre\n        """\n\n        if shift is None:\n            if self.extent is None:\n                return\n            else:\n                shift = tuple(ex / -2 for ex in self.extent)\n\n        if len(shift) != 2:\n            raise ValueError("Shift tuple should be length 2")\n        self._total_shift = tuple([cs + s for cs, s in zip(self._total_shift, shift)])\n\n    def __add__(self, other):\n        if isinstance(other, Number):\n            self_copy = copy.copy(self)\n            if self.profile is not None:\n                self_copy.profile = self.profile + other\n            self_copy.height = lambda x_mesh, y_mesh: self.height(x_mesh, y_mesh) + other\n            self_copy.surface_type = \'Combination\'\n            return self_copy\n\n        if isinstance(other, _AnalyticalSurface):\n            return SurfaceCombination(self, other)\n\n        if isinstance(other, Surface):\n            if not self.is_discrete:\n                self_copy = copy.copy(self)\n                self_copy.extent = other.extent\n                self_copy.grid_spacing = other.grid_spacing\n                self_copy.shape = other.shape\n                self_copy.discretise()\n                return other + self_copy\n\n        return super().__add__(other)\n\n    def __sub__(self, other):\n        if isinstance(other, Number):\n            self_copy = copy.copy(self)\n            if self.profile is not None:\n                self_copy.profile = self.profile - other\n            self_copy.height = lambda x_mesh, y_mesh: self.height(x_mesh, y_mesh) - other\n            self_copy.surface_type = \'Combination\'\n            return self_copy\n\n        if isinstance(other, _AnalyticalSurface):\n            return SurfaceCombination(self, other, \'-\')\n\n        return super().__sub__(other)\n\n    def __mul__(self, other):\n        if isinstance(other, Number):\n            self_copy = copy.copy(self)\n            if self.profile is not None:\n                self_copy.profile = self.profile * other\n            self_copy.height = lambda x_mesh, y_mesh: self.height(x_mesh, y_mesh)*other\n            return self_copy\n        else:\n            raise NotImplementedError(f"Multiplication between analytical surfaces and {type(other)} not implemented")\n\n    def __div__(self, other):\n        if isinstance(other, Number):\n            return self * (1.0/other)\n        else:\n            raise NotImplementedError(f"Division between analytical surfaces and {type(other)} not implemented")\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return False\n\n        if self.is_discrete and other.is_discrete:\n            return super().__eq__(other)\n\n        return self.__dict__ == other.__dict__\n\n    def show(self, property_to_plot=\'profile\', plot_type=\'default\', ax=False, *, dist=None, stride=None, n_pts=100,\n             **figure_kwargs):\n        if self.is_discrete:\n            return super().show(property_to_plot=property_to_plot, plot_type=plot_type, ax=ax, dist=dist, stride=stride,\n                                **figure_kwargs)\n\n        old_props = self.fft, self.psd, self.acf\n\n        if self.grid_spacing is not None and self.shape is not None:\n            set_gs = False\n            profile = self.height(*self.get_points_from_extent())\n        elif self.extent is not None:\n            set_gs = True\n            gs = min(self.extent) / n_pts\n            profile = self.height(*self.get_points_from_extent(extent=self.extent, grid_spacing=gs))\n            self._shape = tuple([int(sz / gs) for sz in self.extent])\n            self._grid_spacing = gs\n        else:\n            raise AttributeError(\'The extent and grid spacing of the surface should be set before the surface can be \'\n                                 \'shown\')\n        self._profile = profile\n        try:\n            return super().show(property_to_plot=property_to_plot, plot_type=plot_type, ax=ax, dist=dist,\n                                stride=stride, **figure_kwargs)\n        finally:\n            self._profile = None\n            self.fft, self.psd, self.acf = old_props\n            if set_gs:\n                self._grid_spacing = None\n                self._shape = None\n\n\nclass SurfaceCombination(_AnalyticalSurface):\n    surface_type = \'Analytical Combination\'\n\n    def __init__(self, surface_1: _AnalyticalSurface, surface_2: _AnalyticalSurface, mode: str = \'+\'):\n        """A class for containing additions or subtractions of analytical surfaces\n\n        Parameters\n        ----------\n        surface_1: _AnalyticalSurface\n            The first surface\n        surface_2: _AnalyticalSurface\n            The second surface\n        mode: str {\'+\', \'-\'}\n            The combination mode\n\n        """\n        if surface_1.extent is not None and surface_2.extent is not None and surface_1.extent != surface_2.extent:\n            raise ValueError(\'Surfaces have different extents, cannot add\')\n        if surface_1.grid_spacing is not None and surface_2.grid_spacing is not None \\\n           and surface_1.grid_spacing != surface_2.grid_spacing:\n            raise ValueError(\'Surfaces have different extents, cannot add\')\n        new_extent = surface_1.extent if surface_1.extent is not None else surface_2.extent\n        new_gs = surface_1.grid_spacing if surface_1.grid_spacing is not None else surface_2.grid_spacing\n\n        super().__init__(grid_spacing=new_gs, extent=new_extent, shift=(0, 0))\n\n        self.mode = mode\n        self.surfaces = (surface_1, surface_2)\n        if self.mode == \'+\':\n            self._height = lambda x_mesh, y_mesh: surface_1.height(x_mesh, y_mesh) + surface_2.height(x_mesh, y_mesh)\n        elif self.mode == \'-\':\n            self._height = lambda x_mesh, y_mesh: surface_1.height(x_mesh, y_mesh) - surface_2.height(x_mesh, y_mesh)\n\n    def __repr__(self):\n        return (\'SurfaceCombination(surface_1=\' + repr(self.surfaces[0]) + \', surface_2=\' + repr(self.surfaces[1]) +\n                f\', mode=\\\'{self.mode}\\\'\')\n\n    def _height(self, x_mesh, y_mesh):\n        """This will be overwritten on init"""\n        pass\n\n\nclass RollingSurface(_Surface):\n    moving_surface = True\n    _initialised = False\n\n    def __init__(self, roughness: _Surface, static_profile: _Surface,\n                 interpolation_mode="nearest"):\n        super().__init__(grid_spacing=static_profile.grid_spacing,\n                         extent=None, shape=static_profile.shape)\n        self._roughness_surface = roughness\n        self._static_profile = static_profile\n        self.current_shift = np.array([0.0, 0.0])\n        self._interpolation_mode = interpolation_mode\n        self.is_discrete = True\n        self._initialised = True\n\n    @property\n    def profile(self):\n        if not self._initialised:\n            return None\n        y, x = self.convert_coordinates(*self._static_profile.get_points_from_extent())\n        return (self._static_profile.profile +\n                self._roughness_surface.interpolate(y, x, self._interpolation_mode))\n\n    @profile.setter\n    def profile(self, value):\n        raise ValueError("The profile of a rolling surface cannot be set")\n\n    def max_shape(self):\n        return self._roughness_surface.shape\n\n    def wear(self, name: str, x_pts: np.ndarray, y_pts: np.ndarray, depth: np.ndarray):\n        y_pts, x_pts = self.convert_coordinates(y_pts, x_pts)\n        self._roughness_surface.wear(name, x_pts, y_pts, depth)\n\n    def interpolate(self, y_points: np.ndarray, x_points: np.ndarray, mode: str = \'nearest\',\n                    remake_interpolator: bool = False):\n        y, x = self.convert_coordinates(y_points, x_points)\n        return (self._static_profile.interpolate(y_points, x_points, mode, remake_interpolator) +\n                self._roughness_surface.interpolate(y, x, mode, remake_interpolator))\n\n    def convert_coordinates(self, y_coord, x_coord):\n        """Converts coordinates from the static profile to the roughness profile"""\n        return (np.remainder(y_coord + self.current_shift[0], self._roughness_surface.extent[0]),\n                np.remainder(x_coord + self.current_shift[1], self._roughness_surface.extent[1]))\n\n    def shift(self, delta_y, delta_x):\n        self.current_shift += np.array([delta_y, delta_x])\n\n    def __repr__(self):\n        return (f"RollingSurface({self._roughness_surface.__repr__()}, "\n                f"{self._static_profile.__repr__()}, )")\n', 'is_package': False},
    'slippy.surface._johnson_utils': {'source': '"""\nutilities used by slippy.surface\njohnson fit by moments\njohnson fit by quantiles\njohnson sl distribution\n"""\n\nimport math\nimport typing\nimport warnings\n\nimport numpy as np\nimport scipy.stats\n\n__all__ = [\'_johnsonsl\', \'_fit_johnson_by_moments\', \'_fit_johnson_by_quantiles\']\n\n\ndef sl_distribution_fit(mean, sd, root_beta_1, omega, return_rv):\n    dist_type = 1  # log normal\n    if root_beta_1 < 0:\n        xlam = -1\n    else:\n        xlam = 1\n    u = xlam * mean\n    delta = 1 / math.sqrt(math.log(omega))\n    gamma = 0.5 * delta * math.log(omega * (omega - 1) / (sd ** 2))\n    xi = u - math.exp((0.5 / delta - gamma) / delta)\n    if return_rv:\n        return _johnsonsl(gamma, delta, scale=xlam, loc=xi)\n    else:\n        return dist_type, xi, xlam, gamma, delta\n\n\ndef _johnsonsl(a, b, loc=0, scale=1):\n    sq = np.log(b / scale) * b ** 2\n\n    lin = np.log(b / scale) * (2 * a * b - 2 * b ** 2 * np.log(scale))\n\n    scale_log = np.exp((lin / sq) / (-2))\n\n    a_log = 1 / b\n\n    return scipy.stats.lognorm(a_log, loc=loc, scale=scale_log)\n\n\ndef _fit_johnson_by_moments(mean: float, sd: float, root_beta_1: float, beta_2: float, return_rv=True) \\\n        -> typing.Union[scipy.stats.rv_continuous, typing.Tuple[int, float, float, float, float]]:\n    """\n    Fits a johnson family distribution to the specified moments\n\n    Parameters\n    ----------\n    mean : float\n        The mean of the distribution\n    sd : float\n        The population standard deviation\n    root_beta_1 : float\n        The skew of the distribution\n    beta_2 : float\n        The kurtosis of the distribution (not normalised)\n    return_rv: bool, optional (True)\n        If False the descriptive parameters found in the reference will be returned, else a scipy.stats.rv_continuous\n        object fitted to the desired parameter will be returned\n\n    Returns\n    -------\n    rv: scipy.stats.rv_continuous\n        fitted distribution\n\n    Notes\n    -----\n    If return_rv is set to False the following will be returned:\n\n    DistType : {1 - log normal johnson Sl, 2 - unbounded johnson Su, 3 bounded\n                johnson Sb, 4 - normal, 5 - Boundary johnson St}\n        integer, a number corresponding to the type of distribution that has\n        been fitted\n    xi, xlam, gamma, delta : scalar, shape parameters of the fitted\n        distribution, xi is epsilon, xlam is lambda\n\n    When a normal distribution is fitted (type 4) the delta is set to 1/sd and\n    gamma is set to mean/sigma, xi and xlam are arbitrarily set to 0.\n\n    When a boundary johnson curve is fitted (type 5, St) the return parameters\n    have different meanings. xi and xlam are set to the two values at which\n    ordinates occur and delta to the proportion of values at xlam, gamma is\n    set arbitrarily to 0.\n\n    See Also\n    -------\n    scipy.stats.johnsonsu\n    scipy.stats.johnsonsb\n    scipy.stats.johnsonsl\n\n    Notes\n    -----\n    Copied from algorithm 99.3 in:\n    applied statistics, 1976 vol 25 no 2\n    accessible here:\n    https://www.jstor.org/stable/pdf/2346692.pdf\n    also in c as part of the R supdists package here:\n    https://cran.r-project.org/web/packages/SuppDists/index.html\n\n    changes from the original functionality are noted by #CHANGE\n\n    Examples\n    --------\n\n    >>>my_scipy_rv=_fit_johnson_by_moments(10,5,1,2)\n    returns a scipy rv with a mean of 10, a standard deviation of 5, a skew of\n    1 and a kurtosis of 2\n    """\n\n    tolerance = 0.01\n\n    beta_1 = root_beta_1 ** 2\n\n    xlam = 0\n    gamma = 0\n    delta = 0\n\n    if sd < 0:\n        raise ValueError("Standard deviation must be grater than or equal to 0")  # error code 1\n    elif sd == 0:\n        xi = mean\n        dist_type = 5  # ST distribution\n        if return_rv:\n            raise NotImplementedError("ST distributions are not implemented")\n        else:\n            return dist_type, xi, xlam, gamma, delta\n\n    if beta_2 >= 0:\n        if beta_2 < beta_1 + 1 - tolerance:\n            raise ValueError("beta 2 must be greater than or equal to beta_1+1")  # error code 2\n        if beta_2 <= (beta_1 + tolerance + 1):\n            dist_type = 5  # ST distribution\n            y = 0.5 + 0.5 * math.sqrt(1 - 4 / (beta_1 + 4))\n            if root_beta_1 > 0:\n                y = 1 - y\n            x = sd / math.sqrt(y * (1 - y))\n            xi = mean - y * x\n            xlam = xi + x\n            delta = y\n            if return_rv:\n                raise NotImplementedError("ST distributions are not implemented")\n            return dist_type, xi, xlam, gamma, delta\n\n    if abs(root_beta_1) < tolerance and abs(beta_2 - 3) < tolerance:\n        dist_type = 4  # Normal\n        xi = mean\n        xlam = sd\n        delta = 1.0\n        gamma = 0.0  # CHANGE from hill, in line with R package\n        if return_rv:\n            return scipy.stats.norm(mean, sd)\n        else:\n            return dist_type, xi, xlam, gamma, delta\n\n    # 80\n    # find critical beta_2 (lies on log normal line)\n    x = 0.5 * beta_1 + 1\n    y = root_beta_1 * math.sqrt(0.25 * beta_1 + 1)\n    omega = (x + y) ** (1 / 3) + (x - y) ** (1 / 3) - 1\n    beta_2_lognormal = omega * omega * (3 + omega * (2 + omega)) - 3\n\n    if beta_2 < 0:\n        beta_2 = beta_2_lognormal\n\n    # if x is 0 log normal, positive - bounded, negative - unbounded\n    x = beta_2_lognormal - beta_2\n\n    if abs(x) < tolerance:\n        return sl_distribution_fit(mean, sd, root_beta_1, omega, return_rv)\n\n    def get_moments(g, d, max_it=500, tol_outer=1e-5, tol_inner=1e-8):\n        """\n        Evaluates the first 6 moments of a johnson distribution using goodwin\'s\n        method (SB only)\n\n        Parameters\n        ----------\n            g : scalar,\n                shape parameter\n            d : scalar,\n                shape parameter\n            max_it : int\n                maximum number of iterations used for fitting\n            tol_outer : float\n                The tolerance of the outer loop\n            tol_inner : float\n                The tolerance for the inner loop\n\n        Returns\n        -------\n        moments : list of the first 6 moments\n\n        Notes\n        -----\n        Copied from algorithm 99.3 in\n        applied statistics, 1976 vol 25 no 2\n        accessible here:\n            https://www.jstor.org/stable/pdf/2346692.pdf\n\n        See also\n        --------\n        sb_fit : fits bounded johnson distributions\n        fit_johnson_by_moments : fits johnson family distributions by moments\n        """\n\n        moments = 6 * [1]\n        b = 6 * [0]\n        c = 6 * [0]\n\n        w = g / d\n\n        # trial value of h\n\n        if w > 80:\n            raise ValueError("Some value too high, failed to converge")\n        e = math.exp(w) + 1\n        r = math.sqrt(2) / d\n        h = 0.75\n        if d < 3:\n            h = 0.25 * d\n        k = 0\n        h *= 2\n        while any([abs(A - C) / A > tol_outer for A, C in zip(moments, c)]):\n            k += 1\n            if k > max_it:\n                raise StopIteration("Moment finding failed to converge O")\n            if k > 1:\n                c = list(moments)\n\n            # no convergence yet try smaller h\n\n            h *= 0.5\n            t = w\n            u = t\n            y = h ** 2\n            x = 2 * y\n            moments[0] = 1 / e\n\n            for i in range(1, 6):\n                moments[i] = moments[i - 1] / e\n\n            v = y\n            f = r * h\n            m = 0\n\n            # inner loop to evaluate infinite series\n            while any([abs(A - B) / A > tol_inner for A, B in zip(moments, b)]):\n                m += 1\n                if m > max_it:\n                    raise StopIteration("Moment finding failed to converge I")\n                b = list(moments)\n                u = u - f\n                z = math.exp(u) + 1\n                t = t + f\n                el = t > 23.7\n                if not el:\n                    s = math.exp(t) + 1\n                p = math.exp(-v)\n                q = p\n                for i in range(1, 7):\n                    moment = moments[i - 1]\n                    moment_a = moment\n\n                    p = p / z\n                    if p == 0:\n                        break\n                    moment_a = moment_a + p\n                    if not el:\n                        q = q / s\n                        moment_a = moment_a + q\n                        el = q == 0\n                    moments[i - 1] = moment_a\n                # 100\n                y = y + x\n                v = v + y\n\n                if any([moment == 0 for moment in moments]):\n                    raise ValueError("for some reason having zero moments"\n                                     " is not allowed, you naughty boy")\n            # end of inner loop\n            v = 1 / math.sqrt(math.pi) * h\n            moments = [moment * v for moment in moments]\n            # don\'t need to check all non zero here, just checked!\n        # end of outer loop\n        return moments\n\n    def sb_fit(mean, sd, root_beta_1, beta_2, tolerance, max_it=1000):\n        dist_type = 3\n\n        beta_1 = root_beta_1 ** 2\n        neg = root_beta_1 < 0\n\n        # get d as first estimate of delta\n\n        e = beta_1 + 1\n        u = 1 / 3\n        x = 0.5 * beta_1 + 1\n        y = abs(root_beta_1) * math.sqrt(0.25 * beta_1 + 1)\n        w = (x + y) ** u + (x - y) ** u - 1\n        f = w ** 2 * (3 + w * (2 + w)) - 3\n        e = (beta_2 - e) / (f - e)\n        if abs(root_beta_1) < tolerance:\n            f = 2\n        else:\n            d = 1 / math.sqrt(math.log(w))\n            if d >= 0.04:\n                f = 2 - 8.5245 / (d * (d * (d - 2.163) + 11.346))\n            else:\n                f = 1.25 * d\n        f = e * f + 1  # 20\n\n        if f < 1.8:\n            d = 0.8 * (f - 1)\n        else:\n            d = (0.626 * f - 0.408) * (3 - f) ** (-0.479)\n\n        # get g as a first estimate of gamma\n\n        g = 0  # 30\n        if beta_1 > tolerance ** 2:\n            if d <= 1:\n                g = (0.7466 * d ** 1.7973 + 0.5955) * beta_1 ** 0.485\n            else:\n                if d <= 2.5:\n                    u = 0.0623\n                    y = 0.5291\n                else:\n                    u = 0.0124\n                    y = 0.5291\n                g = beta_1 ** (u * d + y) * (0.9281 + d * (1.0614 * d - 0.7077))\n\n        # main iterations start here\n        m = 0\n\n        u = float(\'inf\')\n        y = float(\'inf\')\n\n        dd = [0] * 4\n        deriv = [0] * 4\n\n        while abs(u) > tolerance ** 2 or abs(y) > tolerance ** 2:\n            m += 1\n            if m > max_it:\n                raise ValueError(\'solution failed to converge error greater than\'\n                                 \' the specified tolerance may be present\')\n\n            # get first six moments\n            moments = get_moments(g, d)\n            s = moments[0] ** 2\n            h2 = moments[1] - s\n            if h2 <= 0:\n                raise ValueError("Solution failed to converge")\n            t = math.sqrt(h2)\n            h2a = t * h2\n            h2b = h2 ** 2\n            h3 = moments[2] - moments[0] * (3 * moments[1] - 2 * s)\n            rbet = h3 / h2a\n            h4 = moments[3] - moments[0] * (4 * moments[2]\n                                            - moments[0] * (6 * moments[1] - 3 * s))\n            bet2 = h4 / h2b\n            w = g * d\n            u = d ** 2\n\n            # get derivatives\n\n            for j in range(1, 3):\n                for k in range(1, 5):\n                    t = k\n                    if not j == 1:\n                        s = ((w - t) * (moments[k - 1] - moments[k]) + (t + 1) *\n                             (moments[k] - moments[k + 1])) / u\n                    else:\n                        s = moments[k] - moments[k - 1]\n                    dd[k - 1] = t * s / d\n                t = 2 * moments[0] * dd[0]\n                s = moments[0] * dd[1]\n                y = dd[1] - t\n                deriv[j - 1] = (dd[2] - 3 * (s + moments[1] * dd[0] - t * moments[0]\n                                             ) * -1.5 * h3 * y / h2) / h2a\n                deriv[j + 1] = (dd[3] - 4 * (dd[2] * moments[0] + dd[0] * moments[2]) + 6 *\n                                (moments[1] * t + moments[0] * (s - t * moments[0]))\n                                - 2 * h4 * y / h2) / h2b\n\n            t = 1 / (deriv[0] * deriv[3] - deriv[1] * deriv[2])\n            u = (deriv[3] * (rbet - abs(root_beta_1)) - deriv[1] * (bet2 - beta_2)) * t\n            y = (deriv[0] * (bet2 - beta_2) - deriv[2] * (rbet - abs(root_beta_1))) * t\n\n            # new estimates for G and D\n\n            g = g - u\n            if beta_1 == 0 or g < 0:\n                g = 0\n            d = d - y\n\n        # end of iteration\n\n        delta = d\n        xlam = sd / math.sqrt(h2)\n        if neg:\n            gamma = -g\n            moments[0] = 1 - moments[0]\n        else:\n            gamma = g\n        xi = mean - xlam * moments[0]\n\n        return dist_type, xi, xlam, gamma, delta\n\n    def su_fit(mean, sd, root_beat_1, beat_2, tollerance):\n        dist_type = 2\n\n        beta_1 = root_beta_1 ** 2\n        b3 = beta_2 - 3\n\n        # first estimate of e**(delta**(-2))\n\n        w = math.sqrt(math.sqrt(2.0 * beta_2 - 2.8 * beta_1 - 2.0) - 1.0)\n        if abs(root_beta_1) < tollerance:\n            # symmetrical case results known\n            y = 0\n        else:\n            z = float(\'inf\')\n            # johnson iterations\n            while abs(beta_1 - z) > tollerance:\n                w1 = w + 1\n                wm1 = w - 1\n                z = w1 * b3\n                v = w * (6 + w * (3 + w))\n                a = 8 * (wm1 * (3 + w * (7 + v)) - z)\n                b = 16 * (wm1 * (6 + v) - b3)\n                m = (math.sqrt(a ** 2 - 2 * b * (wm1 * (3 + w * (9 + w * (10 + v))) - 2 * w1 * z)) - a) / b\n                z = m * wm1 * (4 * (w + 2) * m + 3 * w1 ** 2) ** 2 / (2 * (2 * m + w1) ** 3)\n                v = w ** 2\n                w = math.sqrt(math.sqrt(1 - 2 * (1.5 - beta_2 + (beta_1 * (\n                        beta_2 - 1.5 - v * (1 + 0.5 * v))) / z)) - 1)\n            y = math.log(math.sqrt(m / w) + math.sqrt(m / w + 1))\n            if root_beta_1 > 0:\n                y *= -1\n        x = math.sqrt(1 / math.log(w))\n        delta = x\n        gamma = y * x\n        y = math.exp(y)\n        z = y ** 2\n        x = sd / math.sqrt(0.5 * (w - 1) * (0.5 * w * (z + 1 / z) + 1))\n        xlam = x\n        xi = mean + xlam * np.exp(delta ** -2 / 2) * np.sinh(gamma / delta)\n\n        return dist_type, xi, xlam, gamma, delta\n\n    if x > 0:\n        try:\n            dist_type, xi, xlam, gamma, delta = sb_fit(mean, sd, root_beta_1,\n                                                       beta_2, tolerance)\n        except TypeError:\n            warnings.warn("SB fit iterations failed returning SL distribution")\n            print(omega)\n            return sl_distribution_fit(mean, sd, root_beta_1, omega, return_rv)\n\n        if return_rv:\n            return scipy.stats.johnsonsb(gamma, delta, scale=xlam, loc=xi)\n        else:\n            return dist_type, xi, xlam, gamma, delta\n    else:\n        dist_type, xi, xlam, gamma, delta = su_fit(mean, sd, root_beta_1,\n                                                   beta_2, tolerance)\n        if return_rv:\n            return scipy.stats.johnsonsu(gamma, delta, scale=xlam, loc=xi)\n        else:\n            return dist_type, xi, xlam, gamma, delta\n\n\ndef _fit_johnson_by_quantiles(quantiles):\n    """\n    Fits a johnson family distribution based on the supplied quartiles\n\n    quantiles relate to normal quantiles of -1.5, -0.5, 0.5, 1.5\n    => 0.067, 0.309, 0.691, 0.933 (roughly)\n\n    Parameters\n    ----------\n\n    quantiles : array like 4 elements\n        The quartiles to be fitted to\n\n    Returns\n    -------\n\n    dist : scipy.stats._distn_infrastructure.rv_frozen\n        A scipy rv object of the fitted distribution\n\n    See Also\n    --------\n\n    References\n    ----------\n\n    Examples\n    --------\n\n    """\n\n    m = quantiles[3] - quantiles[2]\n    n = quantiles[1] - quantiles[0]\n    p = quantiles[2] - quantiles[1]\n    q0 = (quantiles[1] + quantiles[2]) * 0.5\n\n    mp = m / p\n    nop = n / p\n\n    tol = 1e-4\n\n    if mp * nop < 1 - tol:\n        # bounded\n        pm = p / m\n        pn = p / n\n        delta = 0.5 / np.arccosh(0.5 * np.sqrt((1 + pm) * (1 + pn)))\n        gamma = delta * np.arcsinh((pn - pm) * np.sqrt((1 + pm) * (1 + pn) - 4) / (2 * (pm * pn - 1)))\n        xlam = p * np.sqrt(((1 + pm) * (1 + pn) - 2) ** 2 - 4) / (pm * pn - 1)\n        xi = q0 - 0.5 * xlam + p * (pn - pm) / (2 * (pm * pn - 1))\n        dist = scipy.stats.johnsonsb(gamma, delta, loc=xi, scale=xlam)\n\n    elif mp * nop > 1 + tol:\n        # unbounded\n        delta = 1 / np.arccosh(0.5 * (mp + nop))\n        gamma = delta * np.arcsinh((nop - mp) / (2 * np.sqrt(mp * nop - 1)))\n        xlam = 2 * p * np.sqrt(mp * nop - 1) / ((mp + nop - 2) * np.sqrt(mp + nop + 2))\n        xi = q0 + p * (nop - mp) / (2 * (mp + nop - 2))\n        dist = scipy.stats.johnsonsu(gamma, delta, loc=xi, scale=xlam)\n\n    elif abs(mp - 1) > tol:\n        # lognormal\n        delta = 1 / np.log(mp)\n        gamma = delta * np.log(abs(mp - 1) / (p * np.sqrt(mp)))\n        xlam = np.sign(mp - 1)\n        xi = q0 - 0.5 * p * (mp + 1) / (mp - 1)\n        dist = _johnsonsl(gamma, delta, loc=xi, scale=xlam)\n\n    else:\n        # normal\n        scale = 1 / m\n        loc = q0 * scale\n        dist = scipy.stats.norm(loc=loc, scale=scale)\n\n    return dist\n', 'is_package': False},
    'slippy.surface._johnsonsl': {'source': 'import scipy.stats\nfrom math import log, exp\n\n__all__ = [\'johnsonsl\']\n\n\n# noinspection PyMethodOverriding,PyPep8Naming\nclass johnsonsl_gen(scipy.stats.rv_continuous):\n    """A Johnson SL continuous random variable.\n    %(before_notes)s\n    See Also\n    --------\n    johnsonsu\n    johnsonsb\n    Notes\n    -----\n    The probability density function for `johnsonsl` is::\n        johnsonsl.pdf(x, a, b) = b * phi(a + b * log(x))\n    for ``0 < x < 1`` and ``a, b > 0``, and ``phi`` is the normal pdf.\n    %(example)s\n    """\n    def _argcheck(self, a, b):  # a is gamma b is delta\n        return a == a\n\n    def _pdf(self, x, a, b):\n        trm = scipy.stats.norm.pdf(a+b*log(x))\n        return x*trm\n\n    def _cdf(self, x, a, b):\n        return scipy.stats.norm.cdf(a+b*log(x))\n\n    def _ppf(self, q, a, b):\n        return exp((scipy.stats.norm.ppf(q)-a)/b)\n\n\njohnsonsl = johnsonsl_gen(a=0.0, b=1.0, name=\'johnsonsl\')\n', 'is_package': False},
    'slippy.surface.alicona': {'source': 'import numpy as np\nimport os\nimport sys\nfrom matplotlib.pyplot import imread\nimport re\n\n"""\ngeneral utils for surface\n"""\n\n__all__ = [\'alicona_read\']\n\n\ndef alicona_read(full_path: str):\n    r"""\n    Reads .al3d and associated files made by alicona measurement machines\n\n    Will look for texture and icon images automatically, reads tags and depth data at a minimum from the al3d file.\n\n    Parameters\n    ----------\n    full_path : str\n        The full path including extension to an al3d file\n\n    Returns\n    -------\n    data : dict\n        Actual keys depend on the data found:\n        - \'DepthData\' : Array of depth data with nan in place of invalid values\n        - \'TextureData\' : Array of texture data or image of the surface\n        - \'Header\' : Dict of tags read from the header\n        - \'Icon\' : Array of icon image data\n\n    Notes\n    -----\n    If the file name in full_path ends with (#) or # where # is an integer this function will look first for texture (#)\n    or texture # etc. otherwise just texture will be found\n\n    This is a port of the matlab function from the Alicona file format reader (al3D) tool box\n\n    Copyright (c) 2016, Martin\n    All rights reserved.\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions are met:\n\n    \\* Redistributions of source code must retain the above copyright notice,\n    this list of conditions and the following disclaimer.\n\n    \\* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the\n    following disclaimer in the documentation and/or other materials provided with the distribution\n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,\n    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n    INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE\n    GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n    LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n    OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n    """\n\n    path, file_name = os.path.split(full_path)\n    name, ext = file_name.split(\'.\')\n    try:\n        number_tag = re.findall(r\'\\(\\d*\\)\\Z\', name)[-1][1:-1]\n    except IndexError:\n        try:\n            number_tag = re.findall(r\'\\s\\d*\\Z\', name)[-1][1:]\n        except IndexError:\n            number_tag = \'\'\n\n    data = dict()\n    tags = dict()\n\n    with open(full_path, \'rb\') as file:\n        # read the header\n\n        line = file.readline()\n        tags[\'Type\'] = line[:line.find(0)].decode(sys.stdout.encoding)\n\n        line = file.readline()\n        tags[\'Version\'] = int(bytearray([byte for byte in line[20:-1] if\n                                         byte != 0]).decode(sys.stdout.encoding))\n\n        line = file.readline()\n        tags[\'TagCount\'] = int(bytearray([byte for byte in line[20:-1] if\n                                          byte != 0]).decode(sys.stdout.encoding))\n\n        for tag_num in range(tags[\'TagCount\']):\n            line = file.readline()\n            tag_name = bytearray([byte for byte in line[0:20] if byte != 0]\n                                 ).decode(sys.stdout.encoding)\n            tv_str = bytearray([byte for byte in line[20:-1] if byte != 0]\n                               ).decode(sys.stdout.encoding)\n            try:\n                tag_value = int(tv_str)\n            except ValueError:\n                try:\n                    tag_value = float(tv_str)\n                except ValueError:\n                    tag_value = tv_str\n            tags[tag_name] = tag_value\n\n        line = file.readline()\n        tags[\'Comment\'] = bytearray([byte for byte in line[20:-1] if byte != 0]\n                                    ).decode(sys.stdout.encoding)\n\n        data[\'Header\'] = tags\n\n        # read the icon data\n\n        if tags[\'IconOffset\'] > 0:\n            file.seek(tags[\'IconOffset\'])\n            icon = np.zeros([152, 150, 3], dtype=\'uint8\')\n            for i in range(3):\n                icon[:, :, i] = np.reshape(np.array(file.read(22800), dtype=\'uint8\'), (152, 150))\n            data[\'Icon\'] = icon\n        else:\n            try:\n                icon = imread(path + os.path.sep + "icon" + number_tag + ".bmp")\n                data[\'Icon\'] = icon\n            except FileNotFoundError:\n                try:\n                    icon = imread(path + os.path.sep + "icon.bmp")\n                    data[\'Icon\'] = icon\n                except FileNotFoundError:\n                    pass\n\n        # read the depth data\n        rows = int(tags[\'Rows\'])\n\n        if tags[\'DepthImageOffset\'] > 0:\n\n            if tags[\'TextureImageOffset\'] == 0:\n                cols = (file.seek(0, 2) - tags[\'DepthImageOffset\']) / (4 * rows)\n            else:\n                cols = (tags[\'TextureImageOffset\'] - - tags[\'DepthImageOffset\']\n                        ) / (4 * rows)\n\n            cols = int(round(cols))\n\n            file.seek(tags[\'DepthImageOffset\'])\n\n            depth_data = np.array(np.frombuffer(file.read(rows * cols * 4),\n                                                np.float32))\n            depth_data[depth_data == tags[\'InvalidPixelValue\']] = float(\'nan\')\n            data[\'DepthData\'] = np.reshape(depth_data, (rows, cols))[:, :tags[\'Cols\']]\n\n        # read the texture data\n\n        if tags[\'TextureImageOffset\'] > 0:\n\n            if \'TexturePtr\' in tags:\n                if tags[\'TexturePtr\'] == \'0;1;2\':\n                    num_planes = 4\n                else:\n                    num_planes = 1\n            elif \'NumberOfPlanes\' in tags:\n                num_planes = tags[\'NumberOfPlanes\']\n            else:\n                msg = ("The file format may have been updated please ensure this"\n                       " version is up to date then contact the developers")\n                raise NotImplementedError(msg)\n\n            cols = int((file.seek(0, 2) - tags[\'TextureImageOffset\']) / (num_planes * rows))\n\n            file.seek(tags[\'TextureImageOffset\'])\n\n            texture_data = np.zeros([cols, rows, num_planes], dtype=\'uint8\')\n\n            for plane in range(num_planes):\n                texture_data[:, :, plane] = np.reshape(np.array(file.read(cols * rows)), (cols, rows))\n\n            texture_data = texture_data[:tags[\'Cols\'], :, :]\n\n            if num_planes == 4:\n                data[\'TextureData\'] = texture_data[:, :, 0:3]\n                data[\'QualityMap\'] = texture_data[:, :, -1]\n            else:\n                data[\'TextureData\'] = texture_data[:, :, 0]\n\n        else:\n            # check if there is a texture image in the current dir\n            try:\n                data[\'TextureData\'] = imread(path + os.path.sep +\n                                             "texture" + number_tag + ".bmp")\n            except FileNotFoundError:\n                try:\n                    tex = imread(path + os.path.sep + "texture.bmp")\n                    data[\'TextureData\'] = tex\n                except FileNotFoundError:\n                    pass\n    return data\n\n\nif __name__ == \'__main__\':\n    file_name_t = "D:\\\\Downloads\\\\Alicona_data\\\\Surface Profile Data\\\\dem.al3d"\n    from matplotlib.pyplot import imshow\n\n    data_t = alicona_read(file_name_t)\n\n    imshow(data_t[\'DepthData\'])\n', 'is_package': False},
    'slippy.surface.johnsondists': {'source': 'import scipy.stats\nimport numpy as np\nfrom math import log, exp\nimport scipy.special as sc\n\n__all__ = [\'JohnsonSLGen\', \'johnsonsl\']\n\n\n_norm_pdf_C = np.sqrt(2 * np.pi)\n_norm_pdf_logC = np.log(_norm_pdf_C)\n\n\ndef _norm_pdf(x):\n    return np.exp(-x ** 2 / 2.0) / _norm_pdf_C\n\n\ndef _norm_cdf(x):\n    return sc.ndtr(x)\n\n\ndef _norm_ppf(q):\n    return sc.ndtri(q)\n\n\n# noinspection PyMethodOverriding\nclass JohnsonSLGen(scipy.stats.rv_continuous):\n    """A Johnson SL continuous random variable.\n    %(before_notes)s\n    See Also\n    --------\n    johnsonsu\n    Notes\n    -----\n    The probability density function for `johnsonsb` is::\n        johnsonsb.pdf(x, a, b) = b / (x*(1-x)) * phi(a + b * log(x/(1-x)))\n    for ``0 < x < 1`` and ``a, b > 0``, and ``phi`` is the normal pdf.\n    %(example)s\n    """\n\n    def _argcheck(self, a, b):  # a is gamma b is delta\n        return  # array of 1s where aregs are ok and 0 where not ok\n\n    def _pdf(self, x, a, b):\n        trm = _norm_pdf(a + b * log(x))\n        return b * trm\n\n    def _cdf(self, x, a, b):\n        return _norm_cdf(a + b * log(x))\n\n    def _ppf(self, q, a, b):\n        return exp((_norm_ppf(q) - a) / b)\n\n\njohnsonsl = JohnsonSLGen(a=0.0, b=1.0, name=\'johnsonsl\')\n', 'is_package': False},
    'slippy.surface.read_tst_file': {'source': 'import struct\n\n__all__ = [\'read_tst_file\']\n\n\ndef read_tst_file(filename):\n    """Reads a .tst file from a bruker UMT machine\n\n    Parameters\n    ----------\n    filename : str\n        The full path to the .tst file including extension\n\n    Returns\n    -------\n    data : dict\n        The full data including all metadata from the .tst file\n\n    Notes\n    -----\n    The structure of data can be a little confusing at the top level it is a\n    dict with two keys: one for the metadata that applies to the entire file\n    and one for the data from each run of the script.\n\n    The metadata is stored in another dict while the data for each run are in a\n    list with the same order as they were run in.\n\n    This structure is kept all the way though every time something is ordered a\n    list is used other wise a dictionary is used.\n\n    To access data from the first run:\n    >>>first_run=data[\'runs\'][0]\n\n    To access data from the second step in that run:\n    >>>second_step=first_run[\'steps\'][1]\n\n    To get the numerical data from that step:\n    >>>num_data=second_step[\'data\']\n\n    This doesn\'t need to be split:\n    >>>num_data=data[\'runs\'][0][\'steps\'][1][\'data\']\n\n    Gives the same result.\n\n    num_data is a dict of lists with keys of the results recorded:\n    >>>num_data[\'Fx\']\n    Gives the force results in the x direction\n    """\n    data = dict()\n    with open(filename, \'rb\') as file:\n        metadata = dict()\n        while True:\n            number, name, value = split_line(file)\n            if name is None:\n                break\n            metadata[name] = value\n\n            if name == \'channelsarray\':\n                channels = []\n                for i in range(value):\n                    channels.append(read_channel(file))\n                metadata[\'channels\'] = channels  # no other names can have # in\n        # meta data for the whole file has been read\n        data[\'metadata\'] = metadata\n        # next the data for each run is read\n        n_runs = metadata[\'runs\']\n        run_data = []\n        for run in range(n_runs):\n            run_data.append(read_run(file, metadata))\n        data[\'runs\'] = run_data\n    return data\n\n\ndef read_run(file, file_metadata):\n    """\n    Reads a \'run\' of a script\n    """\n    # first read the run meta data\n    run_data = dict()\n    number, name, value = split_line(file)\n    metadata = dict()\n    if name != \'run\':\n        raise ValueError("This is not a run")\n    metadata[name] = value\n    file.readline()  # one empty line before run starts\n    while True:\n        number, name, value = split_line(file)\n        if name is None:\n            break\n        metadata[name] = value\n    # all the metadata for the run has been read in\n    run_data[\'metadata\'] = metadata\n\n    # then read each step\n    n_steps = file_metadata[\'steps\']\n\n    steps = []\n    for i in range(n_steps):\n        steps.append(read_step(file, file_metadata, metadata))\n    run_data[\'steps\'] = steps\n    return run_data\n\n\ndef read_step(file, file_metadata, run_metadata):\n    """ reads a step of the test"""\n    number, name, value = split_line(file)\n    metadata = dict()\n    if name is None:  # for steps other than the first there is 2 lines of stars\n        number, name, value = split_line(file)\n    if name != \'test\':\n        raise ValueError("This is not a run")\n    metadata[name] = value\n    while True:\n        number, name, value = split_line(file)\n        if name is None:\n            break\n        metadata[name] = value\n\n    while True:\n        number, name, value = split_line(file)\n        if name is None:\n            break\n        metadata[name] = value\n\n    if metadata[\'samples\']:\n        step_data = read_data(file, file_metadata, run_metadata, metadata)\n    else:\n        step_data = None\n    return {\'metadata\': metadata, \'data\': step_data}\n\n\ndef read_data(file, file_metadata, run_metadata, step_metadata):\n    """ reads the data from the file """\n    channels = file_metadata[\'channels\']\n    samples = step_metadata[\'samples\']\n    chan_lens = [c[\'lengthinbytes\'] for c in channels]\n    chan_names = [c[\'name\'] for c in channels]\n    data = {cn: [] for cn in chan_names}\n    for sample in range(int(samples)):\n        for name, chan_len in zip(chan_names, chan_lens):\n            data[name].append(struct.unpack(\'d\', file.read(chan_len))[0])\n        file.read(1)\n    return data\n\n\ndef read_channel(file):\n    channel_data = dict()\n    name = \'\'\n    while name != \'type\':\n        number, name, value = split_line(file)\n        channel_data[name] = value\n    return channel_data\n\n\ndef split_line(file):\n    try:\n        line = file.readline()\n        line_str = line.decode()\n    except UnicodeDecodeError:\n        print(line)\n        raise ValueError("could not decode above")\n    number, *rest = line_str.split(\'#\')[1:]\n    rest = \'\'.join(rest)\n    number = number.strip(\' \')\n    name, value = rest.split(\'$\')[0:2]\n    name = name.strip(\' \')\n    value = value.strip(\' \')\n\n    if name.strip(\'*\') == \'\':\n        name = None\n    else:\n        name = name.lower()\n    if value == \'\':\n        value = None\n    elif number in [\'28\', \'31\']:\n        value = int(value)\n    elif number in [\'33\', \'37\', \'38\']:\n        value = float(value)\n    number = int(number)\n    return number, name, value\n\n\nif __name__ == \'__main__\':\n    import numpy as np\n\n    filename_1 = r"I:\\UMT\\Mike\\17May2019\\running in-1.tst"\n    data_1 = read_tst_file(filename_1)\n    mean_mu = np.mean(np.abs(data_1[\'runs\'][0][\'steps\'][1][\'data\'][\'Fx\'])) / 10\n', 'is_package': False},
    'slippy.surface.roughness_funcs': {'source': 'import numpy as np\nimport itertools\nfrom slippy.surface.ACF_class import ACF\nimport scipy.signal\nimport scipy.optimize\nimport scipy.special\nimport typing\nfrom collections.abc import Sequence\nfrom numbers import Number\nfrom slippy.core import _SurfaceABC\n\n__all__ = [\'roughness\', \'subtract_polynomial\', \'get_mat_vr\',\n           \'get_height_of_mat_vr\', \'get_summit_curvatures\',\n           \'find_summits\', \'low_pass_filter\']\n\n\n# noinspection PyTypeChecker\ndef _check_surface(surface, grid_spacing):\n    if isinstance(surface, _SurfaceABC):\n        p = np.asarray(surface)\n        if grid_spacing is None or grid_spacing == float(\'inf\'):\n            gs = surface.grid_spacing\n            return p, gs\n        else:\n            return np.asarray(surface), grid_spacing\n    else:\n        if grid_spacing is None:\n            return np.asarray(surface), None\n        return np.asarray(surface), float(grid_spacing)\n\n\ndef roughness(profile_in: {np.ndarray, _SurfaceABC}, parameter_name: {str, typing.Sequence[str]},\n              grid_spacing: typing.Optional[float] = None,\n              mask: typing.Optional[typing.Union[np.ndarray, float]] = None,\n              curved_surface: bool = False, no_flattening: bool = False,\n              filter_cut_off: typing.Optional[float] = None,\n              four_nearest: bool = False) -> {float, list}:\n    r"""Find 3d surface roughness parameters\n\n    Calculates and returns common surface roughness parameters also known\n    as birmingham parameters\n\n    Parameters\n    ----------\n    profile_in : array like or Surface\n        The surface profile or surface object to be used\n    parameter_name : str or Sequence[str]\n        The name of the surface roughness parameter to be returned see notes\n        for descriptions of each\n    grid_spacing : float optional (None)\n        The distance between adjacent grid points in the surface\n        only required for some parameters, see notes\n    mask : array-like same shape as profile or float (None)\n        If an array, the array is used as a mask for the profile, it must be\n        the same shape as the profile, if a float or list of floats is given,\n        those values are excluded from the calculation. If None, no mask is\n        used. Limited applicability, see notes\n    curved_surface : bool optional (False)\n        True if the measurement surface was curved, in this case a 2nd order\n        polynomial is subtracted other wise a 1st order polynomial is\n        subtracted before the measurement\n    no_flattening : bool optional (False)\n        If true, flattening will be skipped, no polynomial will be subtracted\n        before calculation of parameters, used for periodic surfaces or to\n        save time\n    filter_cut_off: float, optional (None)\n        The cut off frequency of the low pass filter applied to the surface before finding summits, only used for\n        parameters which need summits, if not set no low pass filter is applied\n    four_nearest: bool, optional (False)\n        If true any point that is higher than it\'s 4 nearest neighbours will be\n        counted as a summit, otherwise a point must be higher than it\'s 8\n        nearest neighbours to be a summit. Only used if summit descriptions\n        are required, passed to find_summits.\n\n    Returns\n    -------\n    out : float or list[float]\n        The requested parameters\n\n    See Also\n    --------\n    Surface : a helper class with useful surface analysis functionality\n    subtract_polynomial\n    find_summits\n    get_mat_vr\n    get_summit_curvatures\n\n    Notes\n    -----\n\n    Before calculation the least squares plane is subtracted if a periodic surface is used this can be prevented by\n    setting the no_flattening key word to true. If a curved surface is used a bi quadratic polynomial is fitted and\n    removed before analysis as described in the above text.\n\n    If a list of valid parameter names is given this method will return a list of parameter values.\n\n    If a parameter based on summit descriptions is needed the following key words can be set to refine what counts as a\n    summit, see find_summits for more information. This is only used to find summits, calculations of curvature are run\n    on the unfiltered profile:\n\n    - filter_cut_off (default None)\n    - and\n    - four_nearest (default False)\n\n    Descriptions of each of the surface roughness parameters are given below:\n\n    Amplitude parameters:\n\n    - Sq   - RMS deviation of surface height \\*\n    - Sz   - Ten point height (based on definition of summits) \\*\\-\n    - Ssk  - Skew of the surface (3rd moment) \\*\n    - Sku  - Kurtosis of the surface (4th moment) \\*\n    - Sv   - Lowest valley in the sample \\*\n\n    Spatial parameters:\n\n    - Sds  - Summit density*-, see note above on definition of summit\n    - Str  - Texture aspect ratio defined using the aacf\n    - Std  - Texture direction\n    - Sal  - Fastest decay auto correlation length \\+\n\n    hybrid parameters:\n\n    - Sdelq- RMS slope \\+\n    - Ssc  - Mean summit curvature, see note above on definition of summit \\*\\+\n    - Sdr  - Developed interfacial area ratio \\+\n\n    functional parameters:\n\n    - Sbi  - Bearing index \\*\n    - Sci  - Core fluid retention index \\*\n    - Svi  - Valley fluid retention index \\*\n\n    non \'core\' parameters (implemented):\n\n    - Sa   - Mean amplitude of surface \\*\n    - Stp  - Surface bearing ratio \\*\n    - Smr  - Material volume ratio of the surface \\*\n    - Svr  - Void volume ratio of the surface, as for previous \\*\n\n    non \'core\' parameters (not implemented):\n\n    - Sk   - Core roughness depth\n    - Spk  - Reduced summit height\n    - Svk  - Reduced valley depth\n    - Sr1  - Upper bearing area\n    - Sr2  - Lower bearing area\n\n    \\* masking supported\n\n    \\+ requires grid_spacing\n\n    \\- requires grid spacing only if filtering is used for summit definition\n\n    Summit parameters only support masking if low pass filtering is not\n    required\n\n    Parameter names are not case sensitive\n\n    Examples\n    --------\n\n\n    References\n    ----------\n\n    Stout, K., Sullivan, P., Dong, W., Mainsah, E., Luo, N., Mathia,\n    T., & Zahouani, H. (1993).\n    The development of methods for the characterisation of roughness in\n    three dimensions. EUR(Luxembourg), 358.\n    Retrieved from http://cat.inist.fr/?aModele=afficheN&cpsidt=49475\n    chapter 12\n    """\n    profile, grid_spacing = _check_surface(profile_in, grid_spacing)\n\n    needs_gs = [\'scc\', \'sdr\', \'sal\']\n    no_mask = [\'sdr\', \'str\', \'sal\']\n\n    if mask is not None:\n        if type(mask) is float:\n            if np.isnan(mask):\n                mask = ~np.isnan(profile)\n            else:\n                mask = ~profile == mask\n        else:\n            mask = np.asarray(mask, dtype=bool)\n            if not mask.shape == profile.shape:\n                msg = ("profile and mask shapes do not match: profile is"\n                       "{profile.shape}, mask is {mask.shape}".format(**locals()))\n                raise TypeError(msg)\n\n    # subtract polynomial\n    if curved_surface:\n        order = 2\n    else:\n        order = 1\n\n    if no_flattening:\n        eta = profile\n    else:\n        eta, _ = subtract_polynomial(profile, order, mask=mask)\n\n    if mask is None:\n        eta_masked = eta\n    else:\n        eta_masked = eta[mask]\n\n    # recursive call to allow lists of parameters to be found at once\n    if not isinstance(parameter_name, str):\n        if not isinstance(parameter_name, Sequence):\n            raise ValueError("Parameter name must be a string or a sequence of strings")\n        out = []\n        for par_name in parameter_name:\n            out.append(roughness(eta, par_name, grid_spacing=grid_spacing,\n                                 mask=mask, no_flattening=True,\n                                 filter_cut_off=filter_cut_off,\n                                 four_nearest=four_nearest))\n        return out\n    else:\n        try:\n            # noinspection PyUnresolvedReferences\n            parameter_name = parameter_name.lower()\n        except AttributeError:\n            msg = "Parameters must be strings or list of strings"\n            raise ValueError(msg)\n\n    if parameter_name in needs_gs and grid_spacing is None:\n        raise ValueError("Grid spacing required for {}".format(parameter_name))\n\n    if parameter_name in no_mask and mask is not None:\n        raise ValueError("Masking not supported for {}".format(parameter_name))\n\n    # return parameter of interest\n    num_pts_m = eta_masked.size\n\n    if grid_spacing is not None:\n        global_size = [grid_spacing * dim for dim in profile.shape]\n        gs2 = grid_spacing ** 2\n        p_area_m = num_pts_m * gs2\n        p_area_t = eta.size * gs2\n    else:\n        gs2 = None\n        p_area_m = None\n        p_area_t = None\n\n    if parameter_name == \'sq\':  # root mean square checked\n        out = np.sqrt(np.mean(eta_masked ** 2))\n\n    elif parameter_name == \'sa\':  # mean amplitude checked\n        out = np.mean(np.abs(eta_masked))\n\n    elif parameter_name == \'ssk\':  # skewness checked\n        sq = np.sqrt(np.mean(eta_masked ** 2))\n        out = np.mean(eta_masked ** 3) / sq ** 3\n\n    elif parameter_name == \'sku\':  # kurtosis checked\n        sq = np.sqrt(np.mean(eta_masked ** 2))\n        out = np.mean(eta_masked ** 4) / sq ** 4\n\n    elif parameter_name == \'sv\':\n        out = np.min(eta_masked)\n\n    elif parameter_name in [\'sds\', \'sz\', \'ssc\']:  # all that require summits\n        # summits is logical array of summit locations\n        summits = find_summits(eta, grid_spacing, mask, four_nearest,\n                               filter_cut_off)\n        if parameter_name == \'sds\':  # summit density\n            out = np.sum(summits) / num_pts_m\n        elif parameter_name == \'sz\':\n            valleys = find_summits(-1 * eta, grid_spacing, mask, four_nearest,\n                                   filter_cut_off)\n            summit_heights = eta[summits]\n            valley_heights = eta[valleys]\n            summit_heights = np.sort(summit_heights, axis=None)\n            valley_heights = np.sort(valley_heights, axis=None)\n            out = np.abs(valley_heights[:5]) + np.abs(summit_heights[-5:]) / 5\n        else:  # ssc mean summit curvature\n            out = np.mean(get_summit_curvatures(eta, summits, grid_spacing))\n\n    elif parameter_name == \'sdr\':  # developed interfacial area ratio\n        # ratio between actual surface area and projected or apparent\n        # surface area\n        i_areas = [0.25 * (((gs2 + (eta[x, y] - eta[x, y + 1]) ** 2) ** 0.5 +\n                            (gs2 + (eta[x + 1, y + 1] - eta[x + 1, y]) ** 2) ** 0.5) *\n                           ((gs2 + (eta[x, y] - eta[x + 1, y]) ** 2) ** 0.5 +\n                            (gs2 + (eta[x, y + 1] - eta[x + 1, y + 1]) ** 2) ** 0.5))\n                   for x in range(eta.shape[0] - 1)\n                   for y in range(eta.shape[1] - 1)]\n        i_area = sum(i_areas)\n        out = (i_area - p_area_t) / i_area\n\n    elif parameter_name == \'stp\':\n        # bearing area curve\n        eta_rel = eta_masked / np.sqrt(np.mean(eta_masked ** 2))\n        heights = np.linspace(min(eta_rel), max(eta_rel), 100)\n        ratios = [np.sum(eta_masked < height) / p_area_m for height in heights]\n        out = [heights, ratios]\n\n    elif parameter_name == \'sbi\':  # bearing index\n        index = int(eta_masked.size / 20)\n        sq = np.sqrt(np.mean(eta_masked ** 2))\n        out = sq / np.sort(eta_masked)[index]\n\n    elif parameter_name == \'sci\':  # core fluid retention index\n        sq = np.sqrt(np.mean(eta_masked ** 2))\n        eta_m_sorted = np.sort(eta_masked)\n        index = int(eta_masked.size * 0.05)\n        h005 = eta_m_sorted[index]\n        index = int(eta_masked * 0.8)\n        h08 = eta_m_sorted[index]\n\n        v005 = get_mat_vr(h005, eta, void=True, mask=mask)\n        v08 = get_mat_vr(h08, eta, void=True, mask=mask)\n\n        out = (v005 - v08) / p_area_m / sq\n\n    elif parameter_name == \'svi\':  # valley fluid retention index\n        sq = np.sqrt(np.mean(eta_masked ** 2))\n        index = int(eta_masked.size * 0.8)\n        h08 = np.sort(eta_masked)[index]\n        v08 = get_mat_vr(h08, eta, void=True, mask=mask)\n        out = v08 / p_area_m / sq\n\n    elif parameter_name == \'str\':  # surface texture ratio\n\n        # noinspection PyTypeChecker\n        acf = np.asarray(ACF(eta))\n\n        x = np.arange(eta.shape[0] / -2, eta.shape[0] / 2)\n        y = np.arange(eta.shape[1] / -2, eta.shape[1] / 2)\n        x_mesh, y_mesh = np.meshgrid(x, y)\n        distance_to_centre = np.sqrt(x_mesh ** 2 + y_mesh ** 2)\n        min_dist = min(distance_to_centre[acf < 0.2]) - 0.5\n        max_dist = max(distance_to_centre[acf > 0.2]) + 0.5\n\n        out = min_dist / max_dist\n\n    elif parameter_name == \'std\':  # surface texture direction\n        fft = np.fft.fft2(eta)\n\n        apsd = fft * np.conj(fft) / p_area_t\n        x = np.arange(eta.shape[0] / -2, eta.shape[0] / 2)\n        y = np.arange(eta.shape[1] / -2, eta.shape[1] / 2)\n        i, j = np.unravel_index(apsd.argmax(), apsd.shape)\n        beta = np.arctan(i / j)\n\n        if beta < (np.pi / 2):\n            out = -1 * beta\n        else:\n            out = np.pi - beta\n\n    elif parameter_name == \'sal\':  # fastest decaying auto correlation length\n        # shortest distance from center of ACF to point where R<0.2\n        # noinspection PyTypeChecker\n        acf = np.asarray(ACF(eta))\n\n        x = grid_spacing * np.arange(eta.shape[0] / -2,\n                                     eta.shape[0] / 2)\n        y = grid_spacing * np.arange(eta.shape[1] / -2,\n                                     eta.shape[1] / 2)\n        x_mesh, y_mesh = np.meshgrid(x, y)\n\n        distance_to_centre = np.sqrt(x_mesh ** 2 + y_mesh ** 2)\n\n        out = min(distance_to_centre[acf < 0.2])\n\n    else:\n\n        msg = \'Parameter name not recognised\'\n        raise ValueError(msg)\n\n    return out\n\n\ndef get_height_of_mat_vr(ratio: float, profile: np.ndarray, void=False, mask=None,\n                         accuracy=0.001):\n    """Finds the cut off height of a specified material or void volume ratio\n\n    Parameters\n    ----------\n    ratio : float {from 0 to 1}\n        the target material or void volume ratio\n    profile : array-like\n        The surface profile to be used in the calculation\n    void : bool optional (False)\n        If set to true the height for the void volume ratio will be calculated\n        otherwise the height for the material volume ratio will be calculated\n    mask : array-like (bool) same shape as profile or float (defaults to None)\n        If an array, the array is used as a mask for the profile, must be the\n        same shape as the profile, if a float is given, values which match are\n        excluded from the calculation\n    accuracy : float optional (0.0001)\n        The threshold value to stop iterations\n\n\n    Returns\n    -------\n    height : float\n        the height at which the input surface has the specified material or\n        void ratio\n\n    See also\n    --------\n    get_mat_vr\n    roughness\n    subtract_polynomial\n\n    Notes\n    -----\n    This function should not be used without first flattening the surface using\n    subtract_polynomial\n\n    This function uses a simplified algorithm assuming that each point in the\n    surface can be modeled as a column of material.\n\n    Examples\n    --------\n\n    """\n\n    p = np.asarray(profile)\n\n    if mask is not None:\n        if type(mask) is float:\n            if np.isnan(mask):\n                mask = ~np.isnan(p)\n            else:\n                mask = ~p == mask\n        else:\n            mask = np.asarray(mask, dtype=bool)\n            if not mask.shape == p.shape:\n                msg = ("profile and mask shapes do not match: profile is"\n                       "{p.shape}, mask is {mask.shape}".format(**locals()))\n                raise TypeError(msg)\n\n        p = p[~mask]\n    else:\n        p = p.flatten()\n\n    min_h = min(p)\n    max_h = max(p)\n\n    if void:\n        first_guess = min_h + ratio * (max_h - min_h)\n    else:\n        first_guess = max_h - ratio * (max_h - min_h)\n\n    output = scipy.optimize.minimize(lambda h: (get_mat_vr(h, p, void) - ratio) ** 2, first_guess,\n                                     bounds=(min_h, max_h), tol=accuracy)\n\n    height = output.x[0]\n\n    return height\n\n\ndef get_mat_vr(height: float, profile: np.ndarray, void: bool = False, mask: {float, np.ndarray}=None,\n               ratio=True, grid_spacing=None):\n    """ Finds the material or void volume ratio\n\n    Finds the material or void volume for a given plane height, uses an\n    approximation (that each point is a column of material)\n\n    Parameters\n    ----------\n    profile : 2D array-like or Surface object\n        The surface profile to be used in the calculation\n    height : float\n        The height of the cut off plane\n    void : bool optional (False)\n        If set to true the void volume will be calculated otherwise the\n        material volume is calculated\n    mask : array-like (bool) same shape as profile or float (defaults to None)\n        If an array, the array is used as a mask for the profile, must be the\n        same shape as the profile, if a float is given, values which match are\n        excluded from the calculation\n    ratio : bool optional (True)\n        If true the material or void ratio will be returned, if false the\n        absolute value will be returned, this requires the grid_spacing\n        keyword to be set\n    grid_spacing : float\n        The distance between adjacent grid points in the surface\n\n\n    Returns\n    -------\n    out : float\n        The requested output parameter\n\n    See also\n    --------\n    get_height_of_mat_vr\n    roughness\n    subtract_polynomial\n\n    Notes\n    -----\n    This function should not be used without first flattening the surface using\n    subtract_polynomial\n\n    This function uses a simplified algorithm assuming that each point in the\n    surface can be modeled as a column of material.\n\n\n    Examples\n    --------\n\n\n    """\n\n    p, grid_spacing = _check_surface(profile, grid_spacing)\n\n    if not grid_spacing and not ratio:\n        msg = ("Grid spacing keyword or property of input surface must be set "\n               "for absolute results, see Surface.set_grid_spacing if you are"\n               " using surface objects")\n        raise ValueError(msg)\n\n    if mask is not None:\n        if type(mask) is float:\n            if np.isnan(mask):\n                mask = ~np.isnan(p)\n            else:\n                mask = ~p == mask\n        else:\n            mask = np.asarray(mask, dtype=bool)\n            if not mask.shape == p.shape:\n                msg = ("profile and mask shapes do not match: profile is"\n                       "{p.shape}, mask is {mask.shape}".format(**locals()))\n                raise TypeError(msg)\n\n        p = p[~mask]\n    else:\n        p = p.flatten()\n\n    max_height = max(p)\n    min_height = min(p)\n\n    n_pts = p.size\n    total_vol = n_pts * (max_height - min_height)\n    max_m = sum(p - min_height)\n\n    material = sum(p - height) * (p > height)\n    if void:\n        all_above = (max_height - height) * n_pts\n        void_out = all_above - material  # void not below height\n        void = total_vol - max_m - void_out\n        if ratio:\n            out = void / (total_vol - max_m)\n        else:\n            out = void * grid_spacing ** 3\n    else:\n        if ratio:\n            out = material / max_m\n        else:\n            out = material * grid_spacing ** 3\n    return out\n\n\ndef get_summit_curvatures(profile: np.ndarray, summits: typing.Optional[np.ndarray] = None, grid_spacing: float = None,\n                          mask: typing.Optional[typing.Union[np.ndarray, float]] = None,\n                          filter_cut_off: typing.Optional[float] = None, four_nearest: bool = False):\n    """ find the curvatures of the summits\n\n    Parameters\n    ----------\n    profile: N by M array-like or Surface object\n        The surface profile for analysis\n    summits: N by M array (optional)\n        A bool array True at the location of the summits, if not supplied the\n        summits are found using find_summits first, see notes\n    grid_spacing: float optional (False)\n        The distance between points on the grid of the surface profile. Required\n        only if the filter_cut_off is set and profile is not a surface object\n    mask: array-like (bool)N by M or float optional (None)\n        If an array, the array is used as a mask for the profile, must be the\n        same shape as the profile, if a float is given, values which match are\n        excluded from the calculation\n    filter_cut_off: float, optional (None)\n        The cutoff frequency of the low pass filter that is applied before finding summits\n    four_nearest: bool, optional (False)\n        If true a summit is found if it is higher than it\'s four nearest neighbours, else it must be higher than it\'s\n        eight nearest neighbours\n    Returns\n    -------\n    curves : array\n        Array of summit curvatures of size sum(summits.flatten())\n\n    Other parameters\n    ----------------\n    four_nearest : bool optional (False)\n        If true any point that is higher than it\'s 4 nearest neighbours will be\n        counted as a summit, otherwise a point must be higher than it\'s 8\n        nearest neighbours to be a summit. Only used is summits are not given.\n    filter_cut_off : float optional (None)\n        If given the surface will be low pass filtered before finding summits.\n        Only used if summits are not given\n\n    See also\n    --------\n    find_summits\n    roughness\n\n    Notes\n    -----\n    If the summits parameter is not set, any key word arguments that can be\n    passed to find_summits can be passed through this function.\n\n    Examples\n    --------\n\n    """\n    profile, grid_spacing = _check_surface(profile, grid_spacing)\n\n    gs2 = grid_spacing ** 2\n\n    if summits is None:\n        summits = find_summits(profile, filter_cut_off=filter_cut_off,\n                               grid_spacing=grid_spacing,\n                               four_nearest=four_nearest, mask=mask)\n    verts = np.transpose(np.nonzero(summits))\n    curves = [-0.5 * (profile[vert[0] - 1, vert[1]] + profile[vert[0] + 1, vert[1]] +\n                      profile[vert[0], vert[1] - 1] + profile[vert[0], vert[1] + 1]\n                      - 4 * profile[vert[0], vert[1]]) / gs2 for vert in verts]\n    return curves\n\n\ndef find_summits(profile, grid_spacing: float = None, mask: typing.Union[np.ndarray, float] = None,\n                 four_nearest=False, filter_cut_off=None):\n    """ Finds high points after low pass filtering\n\n    Parameters\n    ----------\n    profile : N by M array-like\n        The surface profile for analysis\n    grid_spacing : float, optional (None)\n        The distance between points on the grid of the surface profile. required\n        only if the filter_cut_off is set\n    mask : array-like (bool) N by M or float optional (None)\n        If an array, the array is used as a mask for the profile, must be the\n        same shape as the profile, if a float is given, values which match are\n        excluded from the calculation\n    four_nearest : bool optional (False)\n        If true any point that is higher than it\'s 4 nearest neighbours will be\n        counted as a summit, otherwise a point must be higher than it\'s 8\n        nearest neighbours to be a summit\n    filter_cut_off : float optional (None)\n        If given the surface will be low pass filtered before finding summits\n\n    Returns\n    -------\n    summits : N by M bool array\n        True at location of summits\n\n    See Also\n    --------\n\n\n    Notes\n    -----\n\n\n    Examples\n    --------\n\n    """\n    profile, grid_spacing = _check_surface(profile, grid_spacing)\n\n    if mask is not None:\n        if type(mask) is float:\n            if np.isnan(mask):\n                mask = ~np.isnan(profile)\n            else:\n                mask = ~profile == mask\n        else:\n            mask = np.asarray(mask, dtype=bool)\n            if not mask.shape == profile.shape:\n                msg = ("profile and mask shapes do not match: profile is"\n                       "{profile.shape}, mask is {mask.shape}".format(**locals()))\n                raise TypeError(msg)\n\n        profile[mask] = float(\'nan\')\n\n    if filter_cut_off is not None:\n        filtered_profile = low_pass_filter(profile, filter_cut_off, grid_spacing)\n    else:\n        filtered_profile = profile\n    summits = np.ones(profile[1:-1, 1:-1].shape, dtype=bool)\n    if four_nearest:\n        x = [-1, +1, 0, 0]\n        y = [0, 0, -1, +1]\n    else:\n        x = [-1, +1, 0, 0, -1, -1, +1, +1]\n        y = [0, 0, -1, +1, -1, +1, -1, +1]\n\n    for i in range(len(x)):\n        summits = np.logical_and(summits, (filtered_profile[1:-1, 1:-1] > filtered_profile[1 + x[i]:-1 + x[i] or None,\n                                           1 + y[i]:-1 + y[i] or None]))\n\n    # pad summits with False to make same size as original\n    summits = np.pad(summits, 1, \'constant\', constant_values=False)\n    return summits\n\n\ndef low_pass_filter(profile: typing.Union[_SurfaceABC, np.ndarray], cut_off_freq: float, grid_spacing: float = None):\n    """2d low pass FIR filter with specified cut off frequency\n\n    Parameters\n    ----------\n    profile : N by M array-like or Surface\n        The Surface object or profile to be filtered\n    cut_off_freq : Float\n        The cut off frequency of the filter in the same units as the\n        grid_spacing of the profile\n    grid_spacing : float optional (None)\n        The distance between adjacent points of the grid of the surface profile\n        not required if the grid spacing of the Surface object is set, always\n        required when an array-like profile is used\n\n    Returns\n    -------\n    filtered_profile : N by M array\n        The filtered surface profile\n\n    See Also\n    --------\n    Surface\n\n    Notes\n    -----\n\n\n    Examples\n    --------\n\n\n    References\n    ----------\n\n    """\n    profile, grid_spacing = _check_surface(profile, grid_spacing)\n\n    if grid_spacing is None:\n        msg = "Grid spacing must be set"\n        raise ValueError(msg)\n\n    sz = profile.shape\n    x = np.arange(1, sz[0] + 1)\n    y = np.arange(1, sz[1] + 1)\n    x_mesh, y_mesh = np.meshgrid(x, y)\n    distance_to_centre = np.sqrt(x_mesh ** 2 + y_mesh ** 2)\n    ws = 2 * np.pi / grid_spacing\n    wc = cut_off_freq * 2 * np.pi\n    h = (wc / ws) * scipy.special.j1(2 * np.pi * (wc / ws) * distance_to_centre) / distance_to_centre\n    filtered_profile = scipy.signal.convolve2d(profile, h, \'same\')\n\n    return filtered_profile\n\n\ndef subtract_polynomial(profile: np.ndarray, order: int = 1,\n                        mask: typing.Optional[typing.Union[np.ndarray, float]] = None):\n    """ Flattens the surface by fitting and subtracting a polynomial\n\n    Fits a polynomial to the surface the subtracts it from the surface, to\n    remove slope or curve from imaging machines\n\n    Parameters\n    ----------\n\n    profile : array-like or Surface\n        The surface or profile to be used\n    order : int\n        The order of the polynomial to be fitted\n    mask : np.ndarray (dtype=bool) or float, optional (None)\n        If an array, the array is used as a mask for the profile, must be the same shape as the profile, if a float or\n        list of floats is given, those values are excluded from the calculation, if None all the values are included in\n        the calculation\n\n    Returns\n    -------\n    adjusted : array\n        The flattened profile\n    coefs : array\n        The coefficients of the polynomial\n\n    Examples\n    --------\n    Subtract a quadratic polynomial from the profile of my_surface the result\n    is returned but the profile property of the surface is not updated\n\n    >>> import slippy.surface as s\n    >>> import numpy as np\n    >>> profile = np.random.rand(10,10)\n    >>> flat_profile, coefs = subtract_polynomial(profile, 2)\n\n        Subtract a plane of best fit from profile and return the result\n\n    >>> flat_profile, coefs = subtract_polynomial(profile, 1)\n\n    Subtract the profile from the surface ignoring nan height values\n\n    >>> flat_profile, coefs = subtract_polynomial(profile_2, 1, mask=float(\'nan\'))\n\n    Subtract a polynomial from the surface ignoring a 5 deep boarder\n\n    >>> mask=np.zeros_like(profile, dtype=bool)\n    >>> mask[5:-5,5:-5]=True\n    >>> flat_profile, coefs = subtract_polynomial(profile_2, 1, mask=mask)\n\n    See Also\n    --------\n    roughness\n    numpy.linalg.lstsq\n\n    Notes\n    -----\n    Polynomials of any integer order are supported.\n\n    """\n\n    profile = np.asarray(profile)\n    x = np.arange(profile.shape[1], dtype=float)\n    y = np.arange(profile.shape[0], dtype=float)\n    x_mesh_full, y_mesh_full = np.meshgrid(x, y)\n    z_full = profile\n\n    if mask is not None:\n        if isinstance(mask, Number):\n            if np.isnan(mask):\n                mask = ~np.isnan(profile)\n            else:\n                mask = ~(profile == mask)\n        else:\n            mask = np.asarray(mask, dtype=bool)\n            if not mask.shape == profile.shape:\n                msg = ("profile and mask shapes do not match: profile is"\n                       "{profile.shape}, mask is {mask.shape}".format(**locals()))\n                raise TypeError(msg)\n        z_masked = z_full[mask]\n        x_masked = x_mesh_full[mask]\n        y_masked = y_mesh_full[mask]\n\n    else:\n        z_masked = z_full.flatten()\n        x_masked = x_mesh_full.flatten()\n        y_masked = y_mesh_full.flatten()\n\n    # fit polynomial\n    n_cols = (order + 1) ** 2\n    g = np.zeros((z_masked.size, n_cols))\n    ij = itertools.product(range(order + 1), range(order + 1))\n\n    for k, (i, j) in enumerate(ij):\n        g[:, k] = x_masked ** i * y_masked ** j\n\n    try:\n        coefs, _, _, _ = np.linalg.lstsq(g, z_masked, rcond=None)\n\n    except np.linalg.LinAlgError:\n        msg = ("np.linalg.lstsq failed to converge, it is likely that there are Nan or inf values in the profile these"\n               " should be masked, see the documentation for this function for more details")\n        raise ValueError(msg)\n\n    if any(np.isnan(coefs)) or any(np.isinf(coefs)):\n        msg = ("Could not fit polynomial to surface. The surface likely contains nan or inf values, these should be "\n               "masked before fitting, for more information see the documentation of this function")\n        raise ValueError(msg)\n\n    poly = np.zeros_like(profile)\n    # must reset to iterate again\n    ij = itertools.product(range(order + 1), range(order + 1))\n\n    for a, (i, j) in zip(coefs, ij):\n        poly += a * x_mesh_full ** i * y_mesh_full ** j\n    poly = poly.reshape(profile.shape)\n    adjusted = profile - poly\n\n    if mask is not None:\n        adjusted[~mask] = profile[~mask]\n\n    return adjusted, coefs\n', 'is_package': False},
    'slippy.surface.tests.test_Surface': {'source': '"""\nTests for the surface class\n\ntests for fft, psd and acf are done in test for frequency and random surface\nclasses\n\nroughness functions are tested in more detail in their own tests\n\n"""\nimport numpy as np\nimport numpy.testing as npt\n\nimport slippy.surface as surface\n\n\ndef test_assurface():\n    profile = np.random.normal(size=[10, 10])\n    ms = surface.assurface(profile, grid_spacing=0.1)\n    npt.assert_equal(ms.profile, profile)\n    npt.assert_equal(ms.extent, (1, 1))\n\n\ndef test_roughness():\n    profile = np.random.normal(size=[500, 500])\n    my_surface = surface.assurface(profile, 1)\n    actual = my_surface.roughness([\'sq\', \'ssk\', \'sku\'])\n    expected = [1, 0, 3]\n    npt.assert_allclose(actual, expected, rtol=1e-2, atol=0.01)\n\n\ndef test_fill_holes():\n    pads = [2,\n            [[0, 2], [2, 0]],\n            [[0, 0], [0, 0]],\n            [[2, 1], [1, 3]],\n            [[0, 0], [3, 3]]]\n    x = np.arange(12, dtype=float)\n    y = np.arange(12, dtype=float)\n    x_mesh, y_mesh = np.meshgrid(x, y)\n    for pad in pads:\n        x_mesh_pad = np.pad(x_mesh, pad, \'constant\', constant_values=float(\'nan\'))\n        x_mesh_pad[6, 6] = float(\'nan\')\n        my_surface = surface.Surface(profile=x_mesh_pad)\n        my_surface.fill_holes()\n        npt.assert_array_almost_equal(x_mesh, my_surface.profile)\n\n\ndef test_mask():\n    profile = np.zeros((10, 10))\n    positions = [0, 1, 2, 3]\n    values = [float(\'nan\'), float(\'inf\'), float(\'-inf\'), 1.1]\n\n    for i in range(len(values)):\n        profile[positions[i]] = values[i]\n        my_surface = surface.Surface(profile=profile)\n        my_surface.mask = values[i]\n        assert my_surface.mask[positions[i]].all()\n        assert np.sum(my_surface.mask.flatten()) == 10\n\n\ndef test_combinations():\n    x = np.arange(12, dtype=float)\n    y = np.arange(12, dtype=float)\n    x_mesh, y_mesh = np.meshgrid(x, y)\n    zeros = np.zeros_like(x_mesh)\n\n    my_surface = surface.Surface(profile=x_mesh)\n    combination = np.array(my_surface + my_surface)\n    npt.assert_array_equal(combination, x_mesh + x_mesh)\n\n    combination = np.array(my_surface - my_surface)\n    npt.assert_array_equal(combination, zeros)\n\n    x2 = np.arange(0, 12, 2, dtype=float)\n    y2 = np.arange(0, 12, 2, dtype=float)\n    x_mesh_2, y_mesh_2 = np.meshgrid(x2, y2)\n\n    surf_2 = surface.Surface(profile=y_mesh_2)\n\n    my_surface.grid_spacing = 1\n    surf_2.grid_spacing = 2\n\n    # note that due to the definition of the extent the final row and column are not defined\n    comb = np.array(my_surface + surf_2)\n    npt.assert_array_almost_equal(comb[:-1, :-1], (x_mesh + y_mesh)[:-1, :-1])\n\n    comb = np.array(my_surface - surf_2)\n    npt.assert_array_almost_equal(comb[:-1, :-1], (x_mesh - y_mesh)[:-1, :-1])\n\n    surf_3 = surface.Surface(profile=y_mesh)\n\n    comb = my_surface + surf_3\n    npt.assert_array_almost_equal(np.array(comb), x_mesh + y_mesh)\n    assert comb.grid_spacing == float(1)\n\n    comb = my_surface - surf_3\n    npt.assert_array_almost_equal(np.array(comb), x_mesh - y_mesh)\n    assert comb.grid_spacing == float(1)\n\n    surf_3.grid_spacing = 2\n\n    assert np.max(np.asarray(np.round(my_surface + surf_3), dtype=int)) == 16\n\n\ndef test_dimensions():\n    # setting grid spacing with a profile\n    profile = np.random.normal(size=[10, 10])\n    ms = surface.Surface(profile=profile)\n    npt.assert_equal(ms.shape, (10, 10))\n    ms.grid_spacing = 0.1\n    npt.assert_allclose(ms.extent, [1, 1])\n    assert ms.is_discrete is True\n\n    # deleting\n\n    del ms.profile\n\n    assert ms.is_discrete is False\n    assert ms.profile is None\n    assert ms.extent is None\n    assert ms.shape is None\n    assert ms.size is None\n    assert ms.grid_spacing is None\n\n    ms.extent = [10, 11]\n\n    assert ms.profile is None\n    npt.assert_allclose(ms.extent, [10, 11])\n    assert ms.shape is None\n    assert ms.size is None\n    assert ms.grid_spacing is None\n\n    ms.grid_spacing = 1\n\n    assert ms.profile is None\n    npt.assert_allclose(ms.extent, [10, 11])\n    assert ms.shape == (10, 11)\n    assert ms.size == 110\n    assert ms.grid_spacing == float(1)\n\n    del ms.shape\n    assert ms.shape is None\n    assert ms.size is None\n\n    del ms.extent\n    assert ms.extent is None\n    assert ms.grid_spacing is None\n\n    ms.extent = [10, 11]\n    assert ms.profile is None\n    npt.assert_allclose(ms.extent, [10, 11])\n    ms.grid_spacing = 1\n    assert ms.shape == (10, 11)\n    assert ms.size == 110\n\n    del ms.grid_spacing\n    assert ms.extent is None\n    assert ms.grid_spacing is None\n    assert ms.shape is None\n    assert ms.size is None\n\n    ms.shape = [5, 10]\n    assert ms.size == 50\n\n    ms.extent = [50, 100]\n    assert ms.grid_spacing == 10\n\n    del ms.grid_spacing\n    ms.profile = profile\n    extent = [10, 9]\n\n    def set_extent():\n        ms.extent = extent\n\n    npt.assert_raises(ValueError, set_extent)\n\n\ndef test_array():\n    profile = np.random.normal(size=[10, 10])\n    ms = surface.Surface(profile=profile)\n    # noinspection PyTypeChecker\n    npt.assert_array_equal(profile, np.asarray(ms))\n\n    ms.profile = [[1, 2], [2, 1]]\n    assert type(ms.profile) is np.ndarray\n', 'is_package': False},
    'slippy.surface.tests.test_johnson_utils': {'source': '"""\nJohnson utils tests\n"""\nimport numpy as np\nimport numpy.testing as npt\nfrom scipy.stats._continuous_distns import _norm_cdf\n\nimport slippy.surface._johnson_utils as j_util\n\n# precision of tests\ndecimal = 1e-5\n\n# noinspection SpellCheckingInspection\nfit_params = [[\'norm\', (0, 1, 0, 3)],\n              [\'johnsonsb\', (5, 2, np.sqrt(2), 4)],\n              [\'johnsonsu\', (0, 2, 1, 6)],\n              [False, (5, 2, np.sqrt(2), 3)],\n              [\'lognorm\', (5, 2, np.sqrt(2), -4)]]\n\n\ndef test_johnson_fit():\n    for params in fit_params:\n        if type(params[0]) is str:\n            my_dist = j_util._fit_johnson_by_moments(*params[1])\n            # noinspection SpellCheckingInspection\n            moments = list(my_dist.stats(\'mvsk\'))\n            moments[1] = np.sqrt(moments[1])\n            moments[3] = moments[3] + 3\n            # noinspection SpellCheckingInspection\n            if params[0] == \'lognorm\':\n                npt.assert_allclose(moments[:-1], params[1:][0][:-1], decimal, atol=0.01,\n                                    err_msg=f"Johnson fitting by moments failed for {params[0]}")\n                npt.assert_equal(my_dist.dist.name, params[0],\n                                 err_msg=f"Johnson fitting by moments failed for {params[0]}")\n            else:\n                npt.assert_allclose(moments, params[1:][0], decimal, atol=0.01,\n                                    err_msg=f"Johnson fitting by moments failed for {params[0]}")\n                npt.assert_equal(my_dist.dist.name, params[0],\n                                 err_msg=f"Johnson fitting by moments failed for {params[0]}")\n\n        else:\n            npt.assert_raises(NotImplementedError,\n                              j_util._fit_johnson_by_moments, *params[1])\n\n\ndef test_johnson_quantile_fit():\n    quantile_pts = np.array(_norm_cdf([-1.5, -0.5, 0.5, 1.5]))\n    test_quantiles = [[1, 1.2, 1.4, 10],\n                      [1, 1.2, 1.4, 3],\n                      [-2, -1, 1, 2]]\n\n    for quantiles_in in test_quantiles:\n        dist = j_util._fit_johnson_by_quantiles(quantiles_in)\n        quantiles_out = dist.ppf(quantile_pts)\n        npt.assert_allclose(quantiles_in, quantiles_out, decimal,\n                            err_msg=f\'Fitting johnson distribution by quartiles failed for test \'\n                                    f\'quartiles {quantiles_in}\')\n\n\nif __name__ == \'__main__\':\n    test_johnson_fit()\n    test_johnson_quantile_fit()\n', 'is_package': False},
    'slippy.surface.tests.test_random_filter': {'source': "import numpy as np\nimport numpy.testing as npt\n\nimport slippy.surface as S\n\n\ndef test_random_filter():\n    np.random.seed(0)\n    sigma = 2\n    target_acf = S.ACF('exp', sigma, 0.1, 0.2)\n    lin_trans_surface = S.RandomFilterSurface(target_acf=target_acf, grid_spacing=0.01)\n    lin_trans_surface.linear_transform(filter_shape=(20, 10), gtol=1e-5, symmetric=True)\n    my_realisation = lin_trans_surface.discretise([512, 512], periodic=True, create_new=True)\n    npt.assert_almost_equal(my_realisation.roughness('Sq'), sigma, 1)\n\n    target = lin_trans_surface.target_acf_array\n    my_realisation.get_acf()\n    actual = np.array(my_realisation.acf)\n    n, m = actual.shape\n    tn, tm = target.shape\n    actual_comparable = actual[n // 2:n // 2 + tn, m // 2:m // 2 + tm]\n    npt.assert_allclose(actual_comparable[0, :], target[0, :], 0.05, 0.2)\n    npt.assert_allclose(actual_comparable[:, 0], target[:, 0], 0.05, 0.2)\n", 'is_package': False},
    'slippy.surface.tests.test_roughness': {'source': '"""\ntesting for roughness functionality\n"""\n\nimport numpy as np\nimport numpy.testing as npt\nfrom pytest import raises as assert_raises\nimport slippy.surface as S\n\n\ndef test_fit_polynomial_masking():\n    a = np.arange(10)\n    b = np.arange(11)\n    mesh_a, mesh_b = np.meshgrid(a, b)\n\n    c = 1\n    ac = 0.2\n    bc = 0.3\n    abc = 1.4\n\n    profile = c + ac * mesh_a + bc * mesh_b + abc * mesh_a * mesh_b\n\n    flattened_profile, coefficients = S.subtract_polynomial(profile, 1)\n\n    npt.assert_allclose(coefficients, [c, bc, ac, abc])\n\n    profile[0, 0] = np.inf\n\n    assert_raises(ValueError, S.subtract_polynomial, profile, 1)\n\n    flattened_profile, coefficients = S.subtract_polynomial(profile, 1, mask=np.inf)\n\n    npt.assert_allclose(coefficients, [c, bc, ac, abc])\n\n    profile[0, 0] = 1\n\n    mask = np.logical_or(profile > 100, profile < 5)\n\n    flattened_profile, coefficients = S.subtract_polynomial(profile, 1, mask=mask)\n\n    npt.assert_allclose(coefficients, [c, bc, ac, abc])\n', 'is_package': False},
}

class EmbeddedModuleFinderLoader(importlib.abc.MetaPathFinder, importlib.abc.Loader):
    def find_spec(self, fullname, path=None, target=None):
        spec = MODULE_SPECS.get(fullname)
        if spec is None:
            return None
        return importlib.machinery.ModuleSpec(fullname, self, is_package=spec['is_package'])

    def create_module(self, spec):
        return None

    def exec_module(self, module):
        spec = MODULE_SPECS[module.__name__]
        module.__file__ = f"<embedded {module.__name__}>"
        if spec['is_package']:
            module.__path__ = []
        exec(compile(spec['source'], module.__file__, "exec"), module.__dict__)

sys.meta_path.insert(0, EmbeddedModuleFinderLoader())

import types as _types
try:
    import scipy.misc as _scipy_misc
except ImportError:
    _scipy_misc = _types.ModuleType('scipy.misc')
    sys.modules['scipy.misc'] = _scipy_misc
if not hasattr(_scipy_misc, 'derivative'):
    def _embedded_derivative(func, x0, dx=1e-6, n=1, args=(), order=3):
        if n != 1:
            raise NotImplementedError("Embedded derivative only supports first derivatives")
        if order not in (3, 5, 7):
            raise ValueError('Order must be 3, 5, or 7 for embedded derivative')
        if order == 3:
            offsets = (-1, 1)
            coeffs = (-1, 1)
            denom = 2
        elif order == 5:
            offsets = (-2, -1, 1, 2)
            coeffs = (1, -8, 8, -1)
            denom = 12
        else:
            offsets = (-3, -2, -1, 1, 2, 3)
            coeffs = (-1, 9, -45, 45, -9, 1)
            denom = 60
        total = 0.0
        for offset, coeff in zip(offsets, coeffs):
            total += coeff * func(x0 + offset * dx, *args)
        return total / (denom * dx)
    _scipy_misc.derivative = _embedded_derivative
import numpy as np
if not hasattr(np, 'product'):
    np.product = np.prod

import matplotlib.pyplot as plt
import slippy
import slippy.surface as S
import slippy.contact as C


def solve_line_contact(line_load, plot=False, verbose=True):
    slippy.CUDA = False
    slippy.material_names.clear()
    radius = 0.01905
    rolling_speed = 4.0
    line_length = 1.0  # assumed axial length for per-unit load calculations
    youngs_modulus = 200e9
    p_ratio = 0.3
    grid_size = 65
    eta_0 = 0.096
    roelands_p_0 = 1 / 5.1e-9
    roelands_z = 0.68
    hertz_result = C.hertz_full([radius, float('inf')], [float('inf'), float('inf')],
                                [youngs_modulus, youngs_modulus], [p_ratio, p_ratio], line_load, line=True)
    hertz_pressure = hertz_result['max_pressure']
    hertz_a = hertz_result['contact_radii'][0]
    hertz_deflection = hertz_result.get('total_deflection', (hertz_result['contact_radii'][0] ** 2) / (2 * radius))
    hertz_pressure_function = hertz_result['pressure_f']
    extent = (hertz_a * 6, line_length)
    ball = S.RoundSurface((radius, float('inf'), radius), shape=(grid_size, grid_size),
                          extent=extent, generate=True)
    flat = S.FlatSurface(shape=(grid_size, grid_size), extent=extent, generate=True)
    steel = C.Elastic('steel', {'E': youngs_modulus, 'v': p_ratio})
    ball.material = steel
    flat.material = steel
    oil = C.Lubricant('oil')
    oil.add_sub_model('nd_viscosity', C.lubricant_models.nd_roelands(eta_0, roelands_p_0, hertz_pressure, roelands_z))
    oil.add_sub_model('nd_density', C.lubricant_models.nd_dowson_higginson(hertz_pressure))
    model = C.ContactModel('line_contact_mixed_lubrication', ball, flat, oil)
    reynolds = C.UnifiedReynoldsSolver(time_step=0, grid_spacing=ball.grid_spacing,
                                       hertzian_pressure=hertz_pressure,
                                       radius_in_rolling_direction=radius,
                                       hertzian_half_width=hertz_a,
                                       dimentional_viscosity=eta_0,
                                       dimentional_density=872,
                                       sweep_direction='backward')
    X, Y = ball.get_points_from_extent()
    X = X + ball._total_shift[0]
    Y = Y + ball._total_shift[1]
    x_line = X[:, X.shape[1] // 2]
    hertz_pressure_line = hertz_pressure_function(x_line)
    hertzian_pressure_dist = np.tile(hertz_pressure_line[:, None], (1, X.shape[1]))
    step = C.IterSemiSystem('main', reynolds, rolling_speed, 1, no_time=True, normal_load=line_load,
                           initial_guess=[hertz_deflection, hertzian_pressure_dist],
                           relaxation_factor=0.005, max_it_interference=5000,
                           rtol_interference=1e-5, rtol_pressure=1e-3,
                           max_it_pressure=500)
    step._rtol_pressure = 1e-3
    step._rtol_interference = 1e-5
    step._max_it_pressure = 2000
    model.add_step(step)
    model.data_check()
    state = model.solve()
    total_load = state.get('total_normal_load', 0.0)
    if verbose:
        print(f"Simulated line load input: {line_load:.3f} N/m, resulting load: {total_load:.3f} N")
        print(f"Solver convergence flag: {state.get('converged', 'unknown')}")
    if plot:
        X_nd = X[:, X.shape[1] // 2] / hertz_a
        nd_pressure = state['nd_pressure'][:, state['nd_pressure'].shape[1] // 2]
        nd_gap = state['gap'][:, state['gap'].shape[1] // 2] / hertz_a
        fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)
        ax[0].plot(X_nd, nd_pressure, label='Lubricated pressure')
        ax[0].plot(X_nd, hertzian_pressure_dist[:, hertzian_pressure_dist.shape[1] // 2] / hertz_pressure,
                   label='Hertz pressure')
        ax[0].set_ylabel('Non-dimensional pressure')
        ax[0].legend()
        ax[0].set_title('Line contact non-dimensional pressure')
        ax[1].plot(X_nd, nd_gap)
        ax[1].set_xlabel('Non-dimensional length')
        ax[1].set_ylabel('Non-dimensional film thickness')
        ax[1].set_title('Line contact non-dimensional film thickness')
        fig.tight_layout()
        plt.show()
    return {
        'state': state,
        'X': X,
        'hertzian_pressure_dist': hertzian_pressure_dist,
        'hertz_pressure': hertz_pressure,
        'hertz_a': hertz_a,
        'line_load': line_load,
        'total_load': total_load,
    }

def main():
    target_load = 800.0
    tolerance = 1e-1
    guesses = [target_load * 0.5, target_load * 1.5]
    results = []
    for guess in guesses:
        result = solve_line_contact(guess, plot=False, verbose=True)
        results.append(result)
    for _ in range(6):
        err0 = results[-2]['total_load'] - target_load
        err1 = results[-1]['total_load'] - target_load
        if abs(err1) < tolerance:
            final_result = results[-1]
            break
        if err1 == err0:
            new_guess = results[-1]['line_load'] * 1.05
        else:
            new_guess = results[-1]['line_load'] - err1 * (results[-1]['line_load'] - results[-2]['line_load']) / (err1 - err0)
        new_guess = max(new_guess, 1e-3)
        result = solve_line_contact(new_guess, plot=False, verbose=True)
        results.append(result)
    else:
        final_result = results[-1]
    print(f"Target load: {target_load:.3f} N, achieved load: {final_result['total_load']:.3f} N")
    solve_line_contact(final_result['line_load'], plot=True, verbose=False)
    return final_result['state']

if __name__ == '__main__':
    main()